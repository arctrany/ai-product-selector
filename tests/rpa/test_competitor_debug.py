#!/usr/bin/env python3
"""
è·Ÿå–åº—é“ºæŠ“å–è°ƒè¯•æµ‹è¯•

ä¸“é—¨ç”¨äºè°ƒè¯•ç”¨æˆ·æåˆ°çš„ä¸¤ä¸ªé—®é¢˜URLï¼š
1. https://www.ozon.ru/product/144042159 - è·Ÿå–ä¿¡æ¯é”™è¯¯
2. https://www.ozon.ru/product/2369901364 - æœ‰æµ®å±‚å±•å¼€åŒºåŸŸä½†æ²¡æœ‰å±•å¼€

è¿™ä¸ªæµ‹è¯•ä¼šè¯¦ç»†åˆ†æé¡µé¢ç»“æ„ï¼Œæ‰¾å‡ºé—®é¢˜æ‰€åœ¨
"""

import logging
import sys
import os
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from common.scrapers.global_browser_singleton import get_global_browser_service
from common.scrapers.competitor_scraper import CompetitorScraper
from common.config.ozon_selectors_config import get_ozon_selectors_config

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

def debug_competitor_extraction(url: str, description: str):
    """è°ƒè¯•è·Ÿå–åº—é“ºæå–"""
    print(f"\n{'='*80}")
    print(f"ğŸ§ª è°ƒè¯•æµ‹è¯•ï¼š{description}")
    print(f"ğŸ“ æµ‹è¯•URL: {url}")
    print(f"{'='*80}")

    browser_service = None
    try:
        # ä½¿ç”¨å…¨å±€æµè§ˆå™¨æœåŠ¡
        browser_service = get_global_browser_service()

        # å¯¼èˆªåˆ°é¡µé¢
        success = browser_service.navigate_to_sync(url)
        if not success:
            print(f"âŒ é¡µé¢å¯¼èˆªå¤±è´¥: {url}")
            return

        # è·å–é¡µé¢å¯¹è±¡
        page = browser_service.browser_service.browser_driver.get_page()

        # ç­‰å¾…é¡µé¢åŠ è½½
        time.sleep(3)

        # åˆå§‹åŒ–è·Ÿå–æŠ“å–å™¨
        competitor_scraper = CompetitorScraper()

        print("ğŸ” ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥è·Ÿå–åŒºåŸŸæ˜¯å¦å­˜åœ¨...")

        # è·å–é€‰æ‹©å™¨é…ç½®
        selectors_config = get_ozon_selectors_config()
        precise_selector = selectors_config.precise_competitor_selector

        print(f"ğŸ¯ ä½¿ç”¨ç²¾ç¡®è·Ÿå–åŒºåŸŸé€‰æ‹©å™¨: {precise_selector}")

        # æ£€æŸ¥è·Ÿå–åŒºåŸŸ
        competitor_element = page.query_selector_sync(precise_selector)
        if competitor_element:
            is_visible = page.is_visible_sync(precise_selector)
            text_content = page.text_content_sync(precise_selector)
            print(f"âœ… æ‰¾åˆ°è·Ÿå–åŒºåŸŸï¼Œå¯è§æ€§: {is_visible}")
            print(f"ğŸ“ è·Ÿå–åŒºåŸŸæ–‡æœ¬: {text_content[:100] if text_content else 'N/A'}")

            if is_visible:
                print("ğŸ” ç¬¬äºŒæ­¥ï¼šå°è¯•æ‰“å¼€è·Ÿå–æµ®å±‚...")
                result = competitor_scraper.open_competitor_popup(page)
                print(f"ğŸ“Š æµ®å±‚æ‰“å¼€ç»“æœ: {result}")

                if result.get('popup_opened'):
                    print("ğŸ” ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥å±•å¼€æŒ‰é’®...")

                    # ä½¿ç”¨è·Ÿå–æŠ“å–å™¨çš„å±•å¼€åŠŸèƒ½
                    print("ğŸ” ç¬¬ä¸‰æ­¥ï¼šå°è¯•å±•å¼€è·Ÿå–åº—é“ºåˆ—è¡¨...")
                    expand_success = competitor_scraper.expand_competitor_list_if_needed(page)

                    if expand_success:
                        print("âœ… å±•å¼€æ“ä½œå®Œæˆ")
                    else:
                        print("âš ï¸ å±•å¼€æ“ä½œå¤±è´¥ï¼Œä½†ç»§ç»­æå–å½“å‰æ˜¾ç¤ºçš„å†…å®¹")

                    print("ğŸ” ç¬¬å››æ­¥ï¼šæå–è·Ÿå–åº—é“ºä¿¡æ¯...")

                    # è·å–é¡µé¢å†…å®¹
                    page_content = browser_service.evaluate_sync("() => document.documentElement.outerHTML")

                    # æå–è·Ÿå–åº—é“ºä¿¡æ¯
                    competitors = competitor_scraper.extract_competitors_from_content(page_content, max_competitors=10)

                    print(f"ğŸ“Š æå–ç»“æœï¼šæ‰¾åˆ° {len(competitors)} ä¸ªè·Ÿå–åº—é“º")
                    for i, comp in enumerate(competitors):
                        print(f"   {i+1}. {comp.get('store_name', 'N/A')} - {comp.get('price', 'N/A')}â‚½ (ID: {comp.get('store_id', 'N/A')})")

                else:
                    print("âŒ è·Ÿå–æµ®å±‚æœªèƒ½æ‰“å¼€")
            else:
                print("âš ï¸ è·Ÿå–åŒºåŸŸå­˜åœ¨ä½†ä¸å¯è§")
        else:
            print("âŒ æœªæ‰¾åˆ°è·Ÿå–åŒºåŸŸ")

            # å°è¯•æŸ¥æ‰¾é¡µé¢ä¸­æ‰€æœ‰å¯èƒ½çš„è·Ÿå–ç›¸å…³å…ƒç´ 
            print("ğŸ” æœç´¢é¡µé¢ä¸­æ‰€æœ‰å¯èƒ½çš„è·Ÿå–å…ƒç´ ...")

            # æœç´¢åŒ…å«è·Ÿå–å…³é”®è¯çš„å…ƒç´ 
            competitor_keywords = selectors_config.competitor_keywords
            for keyword in competitor_keywords[:3]:  # åªæ£€æŸ¥å‰3ä¸ªå…³é”®è¯
                try:
                    elements = page.query_selector_all_sync(f"text={keyword}")
                    if elements:
                        print(f"âœ… æ‰¾åˆ°åŒ…å« '{keyword}' çš„ {len(elements)} ä¸ªå…ƒç´ ")
                        for elem in elements[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                            text = elem.text_content()
                            print(f"   ğŸ“ å…ƒç´ æ–‡æœ¬: {text[:50]}...")
                except:
                    pass

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

    finally:
        if browser_service:
            browser_service.close()

def test_competitor_extraction_144042159():
    """æµ‹è¯•URL 144042159 çš„è·Ÿå–ä¿¡æ¯æå–"""
    debug_competitor_extraction(
        "https://www.ozon.ru/product/144042159",
        "è·Ÿå–ä¿¡æ¯é”™è¯¯çš„å•†å“"
    )

def test_competitor_extraction_2369901364():
    """æµ‹è¯•URL 2369901364 çš„è·Ÿå–ä¿¡æ¯æå–"""
    debug_competitor_extraction(
        "https://www.ozon.ru/product/2369901364",
        "æœ‰æµ®å±‚å±•å¼€åŒºåŸŸä½†æ²¡æœ‰å±•å¼€çš„å•†å“"
    )

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""

    # æµ‹è¯•URLåˆ—è¡¨
    test_urls = [
        ("https://www.ozon.ru/product/144042159", "è·Ÿå–ä¿¡æ¯é”™è¯¯çš„å•†å“"),
        ("https://www.ozon.ru/product/2369901364", "æœ‰æµ®å±‚å±•å¼€åŒºåŸŸä½†æ²¡æœ‰å±•å¼€çš„å•†å“")
    ]

    for url, description in test_urls:
        debug_competitor_extraction(url, description)
        print("\n" + "="*80 + "\n")

if __name__ == "__main__":
    main()
