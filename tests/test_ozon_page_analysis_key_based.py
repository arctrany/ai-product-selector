#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OZONå•†å“é¡µé¢åˆ†æžå™¨ - åŸºäºŽKeyåŒ¹é…çš„é‡å†™ç‰ˆæœ¬
é‡ç‚¹ï¼šä»¥keyä½œä¸ºåŒ¹é…è§„åˆ™ï¼Œè€Œä¸æ˜¯æ•°å€¼
"""

import asyncio
import json
import re
import time
import sys
import os
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Any, Tuple
from concurrent.futures import ThreadPoolExecutor

# å¯¼å…¥é¡¹ç›®æ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

try:
    from playweight.logger_config import get_logger
    from playweight.engine import BrowserService
except ImportError:
    # å¦‚æžœå¯¼å…¥å¤±è´¥ï¼Œæä¾›ç®€å•çš„æ›¿ä»£å®žçŽ°
    def get_logger(debug_mode=True):
        import logging
        logging.basicConfig(level=logging.INFO)
        return logging.getLogger(__name__)
    
    class BrowserService:
        def __init__(self, debug_port=9222, headless=False):
            self.debug_port = debug_port
            self.headless = headless
        
        async def init_browser(self):
            print("âš ï¸ BrowserService not available, using mock implementation")
            return False
        
        async def get_page(self):
            return None

# ç”¨æˆ·æä¾›çš„é¢„æœŸæ•°æ®ç»“æž„ - ä½œä¸ºéªŒè¯æ ‡å‡†
seefar_data_tuples = [
    ("sku", "SKU", "2423301080"),
    ("sales_quantity_30days", "è¿‘30å¤©é”€é‡", 6),
    ("sales_amount_30days", "è¿‘30å¤©é”€å”®é¢", "18 538 â‚½"),
    ("gross_profit_margin", "æ¯›åˆ©çŽ‡", "50%"),
    ("return_cancel_rate", "é€€è´§å–æ¶ˆçŽ‡", "0%"),
    ("exposure_count", "æ›å…‰é‡", 124),
    ("product_card_views", "äº§å“å¡æµè§ˆé‡", 238),
    ("add_to_cart_rate", "åŠ è´­çŽ‡", "4.62%"),
    ("advertising_cost_share", "å¹¿å‘Šè´¹ç”¨ä»½é¢", "0%"),
    ("brand", "å“ç‰Œ", "-"),
    ("seller", "å–å®¶", "ZONFANT"),
    ("delivery_type", "é…é€", "RFBS"),
    ("variant_count", "å˜ä½“æ•°", 3),
    ("competitor_count", "è·Ÿå–æ•°", 0),
    ("weight", "é‡é‡", "2500 g"),
    ("dimensions", "ä½“ç§¯", "550Ã—500Ã—100mm"),
    ("category", "ç±»ç›®", "åŽå¤‡ç®±åž«"),
    ("inventory", "åº“å­˜", "-"),
    ("listing_time", "ä¸Šæž¶æ—¶é—´", "2025-07-07(3 ä¸ªæœˆ)")
]

dianpeng_data_tuples = [
    ("sku", "sku", "2423301080"),
    ("brand", "å“ç‰Œ", "Ð±ÐµÐ· Ð±Ñ€ÐµÐ½Ð´Ð°"),
    ("category_level_1", "ä¸€çº§ç±»ç›®", "ÐÐ²Ñ‚Ð¾Ñ‚Ð¾Ð²Ð°Ñ€Ñ‹"),
    ("category_level_3", "ä¸‰çº§ç±»ç›®", "ÐšÐ¾Ð²Ñ€Ð¸Ðº Ð² Ð±Ð°Ð³Ð°Ð¶Ð½Ð¸Ðº"),
    ("product_code", "è´§å·", "CS95HBXD-2"),
    ("promotion_activity", "ä¿ƒé”€æ´»åŠ¨", "28å¤©å‚ä¸Ž28å¤©"),
    ("monthly_sales_amount", "æœˆé”€å”®é¢", "24711.102â‚½"),
    ("monthly_sales_quantity", "æœˆé”€é‡", 7),
    ("follow_count", "è¢«è·Ÿæ•°é‡", "N/A"),
    ("min_price", "æœ€ä½Žä»·", "N/A"),
    ("max_price", "æœ€é«˜ä»·", "N/A"),
    ("product_clicks", "å•†å“ç‚¹å‡»é‡", 253),
    ("cart_conversion_rate", "è´­ç‰©è½¦è½¬åŒ–çŽ‡", "4.74%"),
    ("total_impressions", "å•†å“å±•ç¤ºæ€»é‡", 1169),
    ("impression_conversion_rate", "å±•ç¤ºè½¬åŒ–çŽ‡", "0.598%"),
    ("transaction_rate", "æˆäº¤çŽ‡", "85.7% (é™¤åŽ»æœªå–æ¶ˆ/æœªé€€å›žçš„è®¢å•)"),
    ("commission_rates", "ä½£é‡‘è´¹çŽ‡", "ä»·æ ¼â‰¤1500å¢å¸ƒ:12.0%\nä»·æ ¼>1501å¢å¸ƒä»·æ ¼â‰¤5000å¢å¸ƒ:17.0%\nä»·æ ¼>5001å¢å¸ƒ:17.0%"),
    ("volume", "ä½“ç§¯", "27.5 å…¬å‡(é•¿xå®½xé«˜)"),
    ("average_price", "å¹³å‡ä»·æ ¼", "3530â‚½"),
    ("seller_type", "å–å®¶ç±»åž‹", "FBS"),
    ("turnover_dynamics", "å‘¨è½¬åŠ¨æ€", "254.6%"),
    ("product_creation_time", "å•†å“åˆ›å»ºæ—¶é—´", "07.07.2025 (å·²åˆ›å»º 106 å¤©)"),
    ("length", "é•¿åº¦", "550mm"),
    ("width", "å®½åº¦", "500mm"),
    ("height", "é«˜åº¦", "100mm"),
    ("weight", "é‡é‡", "2500g")
]

@dataclass
class ProductData:
    """å•†å“æ•°æ®æ¨¡åž‹ - åŸºäºŽkeyåŒ¹é…çš„ç»“æž„"""
    # åŸºç¡€ä¿¡æ¯
    sku: Optional[str] = None
    brand: Optional[str] = None
    category: Optional[str] = None
    
    # é”€å”®æ•°æ®
    sales_quantity_30days: Optional[Any] = None
    sales_amount_30days: Optional[str] = None
    monthly_sales_quantity: Optional[Any] = None
    monthly_sales_amount: Optional[str] = None
    
    # è½¬åŒ–çŽ‡æ•°æ®
    cart_conversion_rate: Optional[str] = None
    impression_conversion_rate: Optional[str] = None
    add_to_cart_rate: Optional[str] = None
    
    # å…¶ä»–æŒ‡æ ‡
    gross_profit_margin: Optional[str] = None
    return_cancel_rate: Optional[str] = None
    transaction_rate: Optional[str] = None
    
    # å•†å“å±žæ€§
    weight: Optional[str] = None
    dimensions: Optional[str] = None
    volume: Optional[str] = None
    
    # å–å®¶ä¿¡æ¯
    seller: Optional[str] = None
    seller_type: Optional[str] = None
    
    # å…¶ä»–å­—æ®µ
    extracted_fields: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.extracted_fields is None:
            self.extracted_fields = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        result = {}
        for k, v in asdict(self).items():
            if v is not None:
                result[k] = v
        return result
    
    def to_tuples(self, tuple_format: str = "seefar") -> List[Tuple[str, str, Any]]:
        """è½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼çš„tuples"""
        if tuple_format == "seefar":
            return self._to_seefar_tuples()
        elif tuple_format == "dianpeng":
            return self._to_dianpeng_tuples()
        else:
            raise ValueError(f"Unsupported tuple format: {tuple_format}")
    
    def _to_seefar_tuples(self) -> List[Tuple[str, str, Any]]:
        """è½¬æ¢ä¸ºseefaræ ¼å¼çš„tuples"""
        mapping = {
            "sku": ("sku", "SKU"),
            "sales_quantity_30days": ("sales_quantity_30days", "è¿‘30å¤©é”€é‡"),
            "sales_amount_30days": ("sales_amount_30days", "è¿‘30å¤©é”€å”®é¢"),
            "gross_profit_margin": ("gross_profit_margin", "æ¯›åˆ©çŽ‡"),
            "return_cancel_rate": ("return_cancel_rate", "é€€è´§å–æ¶ˆçŽ‡"),
            "add_to_cart_rate": ("add_to_cart_rate", "åŠ è´­çŽ‡"),
            "brand": ("brand", "å“ç‰Œ"),
            "seller": ("seller", "å–å®¶"),
            "weight": ("weight", "é‡é‡"),
            "dimensions": ("dimensions", "ä½“ç§¯"),
            "category": ("category", "ç±»ç›®"),
        }
        
        result = []
        data_dict = self.to_dict()
        
        for field_name, (eng_name, key_name) in mapping.items():
            if field_name in data_dict:
                result.append((eng_name, key_name, data_dict[field_name]))
        
        # æ·»åŠ extracted_fieldsä¸­çš„å…¶ä»–å­—æ®µ
        if self.extracted_fields:
            for key, value in self.extracted_fields.items():
                # å°è¯•æ˜ å°„åˆ°å·²çŸ¥å­—æ®µ
                found = False
                for field_name, (eng_name, key_name) in mapping.items():
                    if key == key_name:
                        found = True
                        break
                if not found:
                    # ç”Ÿæˆè‹±æ–‡å
                    eng_name = key.lower().replace(" ", "_").replace("ï¼ˆ", "_").replace("ï¼‰", "")
                    result.append((eng_name, key, value))
        
        return result
    
    def _to_dianpeng_tuples(self) -> List[Tuple[str, str, Any]]:
        """è½¬æ¢ä¸ºdianpengæ ¼å¼çš„tuples"""
        mapping = {
            "sku": ("sku", "sku"),
            "brand": ("brand", "å“ç‰Œ"),
            "monthly_sales_amount": ("monthly_sales_amount", "æœˆé”€å”®é¢"),
            "monthly_sales_quantity": ("monthly_sales_quantity", "æœˆé”€é‡"),
            "cart_conversion_rate": ("cart_conversion_rate", "è´­ç‰©è½¦è½¬åŒ–çŽ‡"),
            "impression_conversion_rate": ("impression_conversion_rate", "å±•ç¤ºè½¬åŒ–çŽ‡"),
            "transaction_rate": ("transaction_rate", "æˆäº¤çŽ‡"),
            "volume": ("volume", "ä½“ç§¯"),
            "seller_type": ("seller_type", "å–å®¶ç±»åž‹"),
            "weight": ("weight", "é‡é‡"),
        }
        
        result = []
        data_dict = self.to_dict()
        
        for field_name, (eng_name, key_name) in mapping.items():
            if field_name in data_dict:
                result.append((eng_name, key_name, data_dict[field_name]))
        
        # æ·»åŠ extracted_fieldsä¸­çš„å…¶ä»–å­—æ®µ
        if self.extracted_fields:
            for key, value in self.extracted_fields.items():
                # å°è¯•æ˜ å°„åˆ°å·²çŸ¥å­—æ®µ
                found = False
                for field_name, (eng_name, key_name) in mapping.items():
                    if key == key_name:
                        found = True
                        break
                if not found:
                    # ç”Ÿæˆè‹±æ–‡å
                    eng_name = key.lower().replace(" ", "_").replace("ï¼ˆ", "_").replace("ï¼‰", "")
                    result.append((eng_name, key, value))
        
        return result

@dataclass
class ExtractionResult:
    """æå–ç»“æžœæ¨¡åž‹"""
    success: bool
    product_data: Optional[ProductData] = None
    seefar_tuples: List[Tuple[str, str, Any]] = None
    dianpeng_tuples: List[Tuple[str, str, Any]] = None
    metadata: Dict[str, Any] = None
    performance_stats: Dict[str, float] = None
    
    def __post_init__(self):
        if self.seefar_tuples is None:
            self.seefar_tuples = []
        if self.dianpeng_tuples is None:
            self.dianpeng_tuples = []
        if self.metadata is None:
            self.metadata = {}
        if self.performance_stats is None:
            self.performance_stats = {}
    
    def to_json(self) -> str:
        """è½¬æ¢ä¸ºJSONæ ¼å¼"""
        return json.dumps({
            'success': self.success,
            'product_data': self.product_data.to_dict() if self.product_data else None,
            'seefar_tuples': self.seefar_tuples,
            'dianpeng_tuples': self.dianpeng_tuples,
            'metadata': self.metadata,
            'performance_stats': self.performance_stats
        }, ensure_ascii=False, indent=2)

class KeyBasedMatcher:
    """åŸºäºŽKeyåŒ¹é…çš„æ•°æ®æå–å™¨"""
    
    def __init__(self):
        # æž„å»ºåŸºäºŽkeyçš„åŒ¹é…æ¨¡å¼ - é‡ç‚¹ï¼šåŒ¹é…keyè€Œä¸æ˜¯æ•°å€¼
        self.key_patterns = self._build_key_patterns()
        self.compiled_patterns = self._compile_patterns()
    
    def _build_key_patterns(self) -> Dict[str, List[str]]:
        """æž„å»ºåŸºäºŽkeyçš„åŒ¹é…æ¨¡å¼"""
        patterns = {
            # SKUç›¸å…³
            "sku": [
                r"SKU[:\s]*([^\s\n]+)",
                r"sku[:\s]*([^\s\n]+)",
                r"å•†å“ç¼–ç [:\s]*([^\s\n]+)",
            ],
            
            # é”€é‡ç›¸å…³ - åŒ¹é…keyè€Œä¸æ˜¯å…·ä½“æ•°å€¼
            "è¿‘30å¤©é”€é‡": [
                r"è¿‘30å¤©é”€é‡[:\s]*([^\s\n]+)",
                r"30å¤©é”€é‡[:\s]*([^\s\n]+)",
            ],
            "æœˆé”€é‡": [
                r"æœˆé”€é‡[:\s]*([^\s\n]+)",
                r"æœˆé”€å”®é‡[:\s]*([^\s\n]+)",
            ],
            
            # é”€å”®é¢ç›¸å…³
            "è¿‘30å¤©é”€å”®é¢": [
                r"è¿‘30å¤©é”€å”®é¢[:\s]*([^\s\n]+(?:\s*â‚½)?)",
                r"30å¤©é”€å”®é¢[:\s]*([^\s\n]+(?:\s*â‚½)?)",
            ],
            "æœˆé”€å”®é¢": [
                r"æœˆé”€å”®é¢[:\s]*([^\s\n]+(?:\s*â‚½)?)",
            ],
            
            # è½¬åŒ–çŽ‡ç›¸å…³
            "æ¯›åˆ©çŽ‡": [
                r"æ¯›åˆ©çŽ‡[:\s]*([^\s\n]+%?)",
            ],
            "é€€è´§å–æ¶ˆçŽ‡": [
                r"é€€è´§å–æ¶ˆçŽ‡[:\s]*([^\s\n]+%?)",
                r"å–æ¶ˆçŽ‡[:\s]*([^\s\n]+%?)",
            ],
            "åŠ è´­çŽ‡": [
                r"åŠ è´­çŽ‡[:\s]*([^\s\n]+%?)",
            ],
            "è´­ç‰©è½¦è½¬åŒ–çŽ‡": [
                r"è´­ç‰©è½¦è½¬åŒ–çŽ‡[:\s]*([^\s\n]+%?)",
            ],
            "å±•ç¤ºè½¬åŒ–çŽ‡": [
                r"å±•ç¤ºè½¬åŒ–çŽ‡[:\s]*([^\s\n]+%?)",
            ],
            "æˆäº¤çŽ‡": [
                r"æˆäº¤çŽ‡[:\s]*([^ï¼ˆ\n]+(?:\([^)]*\))?)",
            ],
            
            # å“ç‰Œå’Œç±»ç›®
            "å“ç‰Œ": [
                r"å“ç‰Œ[:\s]*([^\s\n]+)",
            ],
            "ä¸€çº§ç±»ç›®": [
                r"ä¸€çº§ç±»ç›®[:\s]*([^\s\n]+)",
            ],
            "ä¸‰çº§ç±»ç›®": [
                r"ä¸‰çº§ç±»ç›®[:\s]*([^\s\n]+)",
            ],
            "ç±»ç›®": [
                r"ç±»ç›®[:\s]*([^\s\n]+)",
            ],
            
            # å•†å“å±žæ€§
            "é‡é‡": [
                r"é‡é‡[:\s]*([^\s\n]+(?:\s*g)?)",
            ],
            "ä½“ç§¯": [
                r"ä½“ç§¯[:\s]*([^ï¼ˆ\n]+(?:\([^)]*\))?)",
            ],
            "é•¿åº¦": [
                r"é•¿åº¦[:\s]*([^\s\n]+(?:mm)?)",
            ],
            "å®½åº¦": [
                r"å®½åº¦[:\s]*([^\s\n]+(?:mm)?)",
            ],
            "é«˜åº¦": [
                r"é«˜åº¦[:\s]*([^\s\n]+(?:mm)?)",
            ],
            
            # å–å®¶ä¿¡æ¯
            "å–å®¶": [
                r"å–å®¶[:\s]*([^\s\n]+)",
            ],
            "å–å®¶ç±»åž‹": [
                r"å–å®¶ç±»åž‹[:\s]*([^\s\n]+)",
            ],
            
            # å…¶ä»–æŒ‡æ ‡
            "è´§å·": [
                r"è´§å·[:\s]*([^\s\n]+)",
            ],
            "ä¿ƒé”€æ´»åŠ¨": [
                r"ä¿ƒé”€æ´»åŠ¨[:\s]*([^\s\n]+)",
            ],
            "è¢«è·Ÿæ•°é‡": [
                r"è¢«è·Ÿæ•°é‡[:\s]*([^\s\n]+)",
            ],
            "æœ€ä½Žä»·": [
                r"æœ€ä½Žä»·[:\s]*([^\s\n]+)",
            ],
            "æœ€é«˜ä»·": [
                r"æœ€é«˜ä»·[:\s]*([^\s\n]+)",
            ],
            "å•†å“ç‚¹å‡»é‡": [
                r"å•†å“ç‚¹å‡»é‡[:\s]*([^\s\n]+)",
            ],
            "å•†å“å±•ç¤ºæ€»é‡": [
                r"å•†å“å±•ç¤ºæ€»é‡[:\s]*([^\s\n]+)",
            ],
            "å¹³å‡ä»·æ ¼": [
                r"å¹³å‡ä»·æ ¼[:\s]*([^\s\n]+(?:\s*â‚½)?)",
            ],
            "å‘¨è½¬åŠ¨æ€": [
                r"å‘¨è½¬åŠ¨æ€[:\s]*([^\s\n]+%?)",
            ],
            "å•†å“åˆ›å»ºæ—¶é—´": [
                r"å•†å“åˆ›å»ºæ—¶é—´[:\s]*([^ï¼ˆ\n]+(?:\([^)]*\))?)",
            ],
            
            # ä½£é‡‘è´¹çŽ‡
            "ä½£é‡‘è´¹çŽ‡": [
                r"ä½£é‡‘è´¹çŽ‡[:\s]*([^ï¼š\n]+(?:ï¼š[^\n]*)?)",
            ],
        }
        
        return patterns
    
    def _compile_patterns(self) -> Dict[str, List[re.Pattern]]:
        """ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        compiled = {}
        for key, patterns in self.key_patterns.items():
            compiled[key] = [re.compile(pattern, re.IGNORECASE | re.MULTILINE) for pattern in patterns]
        return compiled
    
    def extract_data_from_text(self, text: str, source_name: str = "") -> Dict[str, str]:
        """ä»Žæ–‡æœ¬ä¸­æå–æ•°æ® - åŸºäºŽkeyåŒ¹é…"""
        print(f"\nðŸ” åŸºäºŽKeyåŒ¹é…æå–æ•°æ® - {source_name}")
        
        extracted_data = {}
        
        # å¹¶è¡Œå¤„ç†æ‰€æœ‰åŒ¹é…æ¨¡å¼
        def match_key_patterns(key_and_patterns):
            key, patterns = key_and_patterns
            for pattern in patterns:
                matches = pattern.findall(text)
                if matches:
                    # å–ç¬¬ä¸€ä¸ªåŒ¹é…ç»“æžœï¼Œå¹¶æ¸…ç†
                    value = matches[0].strip()
                    if value and value != "":
                        return key, value
            return key, None
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=8) as executor:
            results = list(executor.map(match_key_patterns, self.compiled_patterns.items()))
        
        # æ”¶é›†æœ‰æ•ˆç»“æžœ
        for key, value in results:
            if value is not None:
                extracted_data[key] = value
                print(f"   âœ… {key}: {value}")
        
        print(f"ðŸ“Š æå–åˆ° {len(extracted_data)} ä¸ªå­—æ®µ")
        return extracted_data
    
    def parse_commission_rates(self, text: str) -> Dict[str, str]:
        """è§£æžä½£é‡‘è´¹çŽ‡ä¿¡æ¯"""
        commission_data = {}
        
        # ä½£é‡‘è´¹çŽ‡çš„å…·ä½“æ¨¡å¼
        patterns = [
            (r"ä»·æ ¼â‰¤1500å¢å¸ƒ[:\s]*([^\n\r]+)", "ä½£é‡‘è´¹çŽ‡1500ä»¥ä¸‹"),
            (r"ä»·æ ¼>1501å¢å¸ƒä»·æ ¼â‰¤5000å¢å¸ƒ[:\s]*([^\n\r]+)", "ä½£é‡‘è´¹çŽ‡1501-5000"),
            (r"ä»·æ ¼>5001å¢å¸ƒ[:\s]*([^\n\r]+)", "ä½£é‡‘è´¹çŽ‡5001ä»¥ä¸Š"),
        ]
        
        for pattern, key in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                commission_data[key] = match.group(1).strip()
        
        return commission_data

class KeyBasedOzonAnalyzer:
    """åŸºäºŽKeyåŒ¹é…çš„OZONé¡µé¢åˆ†æžå™¨"""
    
    def __init__(self, debug_mode=True):
        self.debug_mode = debug_mode
        self.logger = get_logger(debug_mode)
        self.browser_service = None
        self.key_matcher = KeyBasedMatcher()
        self.performance_stats = {}
    
    async def analyze_product_page(self, url: str) -> Optional[ExtractionResult]:
        """åˆ†æžå•†å“é¡µé¢ - åŸºäºŽKeyåŒ¹é…"""
        start_time = time.time()
        
        try:
            print("ðŸš€ å¯åŠ¨åŸºäºŽKeyåŒ¹é…çš„OZONé¡µé¢åˆ†æž")
            
            # åˆå§‹åŒ–æµè§ˆå™¨æœåŠ¡
            print("ðŸŒ åˆå§‹åŒ–æµè§ˆå™¨æœåŠ¡...")
            init_start = time.time()
            self.browser_service = BrowserService(debug_port=9222, headless=False)
            
            if not await self.browser_service.init_browser():
                print("âŒ æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•")
                return await self._analyze_with_mock_data(url)
            
            self.performance_stats['browser_init_time'] = time.time() - init_start
            
            # èŽ·å–é¡µé¢å¹¶æå–æ•°æ®
            page_start = time.time()
            page = await self.browser_service.get_page()
            if not page:
                print("âŒ æ— æ³•èŽ·å–é¡µé¢å¯¹è±¡ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                return await self._analyze_with_mock_data(url)
            
            # è®¿é—®é¡µé¢
            try:
                await page.goto(url, timeout=30000)
            except Exception as e:
                print(f"âš ï¸ é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå°è¯•ç»§ç»­åˆ†æž: {str(e)}")
            
            # ç­‰å¾…é¡µé¢ç¨³å®š
            await asyncio.sleep(3)
            self.performance_stats['page_load_time'] = time.time() - page_start
            
            # æå–é¡µé¢æ•°æ®
            extraction_start = time.time()
            result = await self._extract_product_data_by_keys(page)
            self.performance_stats['data_extraction_time'] = time.time() - extraction_start
            
            # æ€»æ‰§è¡Œæ—¶é—´
            self.performance_stats['total_time'] = time.time() - start_time
            
            # åˆ›å»ºç»“æžœå¯¹è±¡
            extraction_result = ExtractionResult(
                success=True,
                product_data=result,
                seefar_tuples=result.to_tuples("seefar") if result else [],
                dianpeng_tuples=result.to_tuples("dianpeng") if result else [],
                metadata={
                    'url': url,
                    'title': await page.title() if page else "Unknown",
                    'extraction_timestamp': time.time(),
                    'analysis_method': 'key_based_matching'
                },
                performance_stats=self.performance_stats
            )
            
            return extraction_result
            
        except Exception as e:
            print(f"âŒ åˆ†æžè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            return ExtractionResult(success=False, metadata={'error': str(e)})
        finally:
            if self.browser_service:
                try:
                    await self.browser_service.close()
                except:
                    pass
    
    async def _analyze_with_mock_data(self, url: str) -> ExtractionResult:
        """ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œåˆ†æžæµ‹è¯•"""
        print("ðŸ§ª ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡ŒKeyåŒ¹é…æµ‹è¯•")
        
        # æ¨¡æ‹Ÿé¡µé¢æ–‡æœ¬æ•°æ®
        mock_text = """
        å•†å“ä¿¡æ¯é¡µé¢
        SKU: 2423301080
        å“ç‰Œ: ZONFANT
        è¿‘30å¤©é”€é‡: 6
        è¿‘30å¤©é”€å”®é¢: 18 538 â‚½
        æ¯›åˆ©çŽ‡: 50%
        é€€è´§å–æ¶ˆçŽ‡: 0%
        åŠ è´­çŽ‡: 4.62%
        å–å®¶: ZONFANT
        é‡é‡: 2500 g
        ä½“ç§¯: 550Ã—500Ã—100mm
        ç±»ç›®: åŽå¤‡ç®±åž«
        
        æœˆé”€é‡: 7
        æœˆé”€å”®é¢: 24711.102â‚½
        è´­ç‰©è½¦è½¬åŒ–çŽ‡: 4.74%
        å±•ç¤ºè½¬åŒ–çŽ‡: 0.598%
        æˆäº¤çŽ‡: 85.7% (é™¤åŽ»æœªå–æ¶ˆ/æœªé€€å›žçš„è®¢å•)
        å•†å“ç‚¹å‡»é‡: 253
        å•†å“å±•ç¤ºæ€»é‡: 1169
        å¹³å‡ä»·æ ¼: 3530â‚½
        å–å®¶ç±»åž‹: FBS
        å‘¨è½¬åŠ¨æ€: 254.6%
        å•†å“åˆ›å»ºæ—¶é—´: 07.07.2025 (å·²åˆ›å»º 106 å¤©)
        é•¿åº¦: 550mm
        å®½åº¦: 500mm
        é«˜åº¦: 100mm
        """
        
        # ä½¿ç”¨KeyåŒ¹é…å™¨æå–æ•°æ®
        extracted_data = self.key_matcher.extract_data_from_text(mock_text, "æ¨¡æ‹Ÿæ•°æ®")
        
        # åˆ›å»ºProductDataå¯¹è±¡
        product_data = ProductData()
        product_data.extracted_fields = extracted_data
        
        # æ˜ å°„åˆ°æ ‡å‡†å­—æ®µ
        if "SKU" in extracted_data:
            product_data.sku = extracted_data["SKU"]
        if "å“ç‰Œ" in extracted_data:
            product_data.brand = extracted_data["å“ç‰Œ"]
        if "è¿‘30å¤©é”€é‡" in extracted_data:
            product_data.sales_quantity_30days = extracted_data["è¿‘30å¤©é”€é‡"]
        if "è¿‘30å¤©é”€å”®é¢" in extracted_data:
            product_data.sales_amount_30days = extracted_data["è¿‘30å¤©é”€å”®é¢"]
        if "æœˆé”€é‡" in extracted_data:
            product_data.monthly_sales_quantity = extracted_data["æœˆé”€é‡"]
        if "æœˆé”€å”®é¢" in extracted_data:
            product_data.monthly_sales_amount = extracted_data["æœˆé”€å”®é¢"]
        if "è´­ç‰©è½¦è½¬åŒ–çŽ‡" in extracted_data:
            product_data.cart_conversion_rate = extracted_data["è´­ç‰©è½¦è½¬åŒ–çŽ‡"]
        if "å±•ç¤ºè½¬åŒ–çŽ‡" in extracted_data:
            product_data.impression_conversion_rate = extracted_data["å±•ç¤ºè½¬åŒ–çŽ‡"]
        if "åŠ è´­çŽ‡" in extracted_data:
            product_data.add_to_cart_rate = extracted_data["åŠ è´­çŽ‡"]
        if "æ¯›åˆ©çŽ‡" in extracted_data:
            product_data.gross_profit_margin = extracted_data["æ¯›åˆ©çŽ‡"]
        if "é€€è´§å–æ¶ˆçŽ‡" in extracted_data:
            product_data.return_cancel_rate = extracted_data["é€€è´§å–æ¶ˆçŽ‡"]
        if "æˆäº¤çŽ‡" in extracted_data:
            product_data.transaction_rate = extracted_data["æˆäº¤çŽ‡"]
        if "é‡é‡" in extracted_data:
            product_data.weight = extracted_data["é‡é‡"]
        if "ä½“ç§¯" in extracted_data:
            product_data.dimensions = extracted_data["ä½“ç§¯"]
        if "å–å®¶" in extracted_data:
            product_data.seller = extracted_data["å–å®¶"]
        if "å–å®¶ç±»åž‹" in extracted_data:
            product_data.seller_type = extracted_data["å–å®¶ç±»åž‹"]
        
        return ExtractionResult(
            success=True,
            product_data=product_data,
            seefar_tuples=product_data.to_tuples("seefar"),
            dianpeng_tuples=product_data.to_tuples("dianpeng"),
            metadata={
                'url': url,
                'title': "Mock Data Test",
                'extraction_timestamp': time.time(),
                'analysis_method': 'mock_key_based_matching'
            },
            performance_stats={'total_time': 0.1}
        )
    
    async def _extract_product_data_by_keys(self, page) -> Optional[ProductData]:
        """åŸºäºŽKeyä»Žé¡µé¢æå–äº§å“æ•°æ®"""
        print("\nðŸ“Š åŸºäºŽKeyæå–é¡µé¢æ•°æ®")
        
        # èŽ·å–é¡µé¢æ–‡æœ¬å†…å®¹
        try:
            # å°è¯•èŽ·å–å¤šä¸ªåŒºåŸŸçš„æ–‡æœ¬
            selectors = [
                'body',  # æ•´ä¸ªé¡µé¢
                '[data-widget]',  # æ‰€æœ‰widget
                '.product-info',  # äº§å“ä¿¡æ¯åŒºåŸŸ
                '.product-details',  # äº§å“è¯¦æƒ…
            ]
            
            all_text = ""
            for selector in selectors:
                try:
                    elements = await page.query_selector_all(selector)
                    for element in elements[:5]:  # é™åˆ¶æ•°é‡é¿å…è¿‡å¤š
                        text = await element.text_content()
                        if text:
                            all_text += text + "\n"
                except:
                    continue
            
            if not all_text.strip():
                print("âš ï¸ æœªèƒ½èŽ·å–é¡µé¢æ–‡æœ¬ï¼Œä½¿ç”¨é¡µé¢å†…å®¹")
                all_text = await page.content()
            
        except Exception as e:
            print(f"âš ï¸ èŽ·å–é¡µé¢å†…å®¹æ—¶å‡ºé”™: {str(e)}")
            return None
        
        # ä½¿ç”¨KeyåŒ¹é…å™¨æå–æ•°æ®
        extracted_data = self.key_matcher.extract_data_from_text(all_text, "é¡µé¢å†…å®¹")
        
        if not extracted_data:
            print("âŒ æœªæå–åˆ°ä»»ä½•æ•°æ®")
            return None
        
        # åˆ›å»ºProductDataå¯¹è±¡å¹¶æ˜ å°„å­—æ®µ
        product_data = ProductData()
        product_data.extracted_fields = extracted_data
        
        # æ˜ å°„åˆ°æ ‡å‡†å­—æ®µï¼ˆåŒä¸Šé¢çš„é€»è¾‘ï¼‰
        field_mapping = {
            "SKU": "sku",
            "sku": "sku", 
            "å“ç‰Œ": "brand",
            "è¿‘30å¤©é”€é‡": "sales_quantity_30days",
            "è¿‘30å¤©é”€å”®é¢": "sales_amount_30days",
            "æœˆé”€é‡": "monthly_sales_quantity",
            "æœˆé”€å”®é¢": "monthly_sales_amount",
            "è´­ç‰©è½¦è½¬åŒ–çŽ‡": "cart_conversion_rate",
            "å±•ç¤ºè½¬åŒ–çŽ‡": "impression_conversion_rate",
            "åŠ è´­çŽ‡": "add_to_cart_rate",
            "æ¯›åˆ©çŽ‡": "gross_profit_margin",
            "é€€è´§å–æ¶ˆçŽ‡": "return_cancel_rate",
            "æˆäº¤çŽ‡": "transaction_rate",
            "é‡é‡": "weight",
            "ä½“ç§¯": "dimensions",
            "å–å®¶": "seller",
            "å–å®¶ç±»åž‹": "seller_type",
        }
        
        for key, field in field_mapping.items():
            if key in extracted_data:
                setattr(product_data, field, extracted_data[key])
        
        return product_data

def test_key_based_matching():
    """æµ‹è¯•åŸºäºŽKeyçš„åŒ¹é…åŠŸèƒ½"""
    print("\n" + "="*80)
    print("ðŸ§ª æµ‹è¯•åŸºäºŽKeyçš„åŒ¹é…åŠŸèƒ½")
    print("="*80)
    
    matcher = KeyBasedMatcher()
    
    # æµ‹è¯•æ–‡æœ¬
    test_text = """
    å•†å“è¯¦æƒ…é¡µé¢
    SKU: 2423301080
    å“ç‰Œ: ZONFANT
    è¿‘30å¤©é”€é‡: 6
    è¿‘30å¤©é”€å”®é¢: 18 538 â‚½
    æ¯›åˆ©çŽ‡: 50%
    é€€è´§å–æ¶ˆçŽ‡: 0%
    åŠ è´­çŽ‡: 4.62%
    å–å®¶: ZONFANT
    é‡é‡: 2500 g
    ä½“ç§¯: 550Ã—500Ã—100mm
    ç±»ç›®: åŽå¤‡ç®±åž«
    åº“å­˜: -
    ä¸Šæž¶æ—¶é—´: 2025-07-07(3 ä¸ªæœˆ)
    
    sku: 2423301080
    å“ç‰Œ: Ð±ÐµÐ· Ð±Ñ€ÐµÐ½Ð´Ð°
    ä¸€çº§ç±»ç›®: ÐÐ²Ñ‚Ð¾Ñ‚Ð¾Ð²Ð°Ñ€Ñ‹
    ä¸‰çº§ç±»ç›®: ÐšÐ¾Ð²Ñ€Ð¸Ðº Ð² Ð±Ð°Ð³Ð°Ð¶Ð½Ð¸Ðº
    è´§å·: CS95HBXD-2
    ä¿ƒé”€æ´»åŠ¨: 28å¤©å‚ä¸Ž28å¤©
    æœˆé”€å”®é¢: 24711.102â‚½
    æœˆé”€é‡: 7
    è¢«è·Ÿæ•°é‡: N/A
    æœ€ä½Žä»·: N/A
    æœ€é«˜ä»·: N/A
    å•†å“ç‚¹å‡»é‡: 253
    è´­ç‰©è½¦è½¬åŒ–çŽ‡: 4.74%
    å•†å“å±•ç¤ºæ€»é‡: 1169
    å±•ç¤ºè½¬åŒ–çŽ‡: 0.598%
    æˆäº¤çŽ‡: 85.7% (é™¤åŽ»æœªå–æ¶ˆ/æœªé€€å›žçš„è®¢å•)
    ä½£é‡‘è´¹çŽ‡: ä»·æ ¼â‰¤1500å¢å¸ƒ:12.0%
    ä»·æ ¼>1501å¢å¸ƒä»·æ ¼â‰¤5000å¢å¸ƒ:17.0%
    ä»·æ ¼>5001å¢å¸ƒ:17.0%
    ä½“ç§¯: 27.5 å…¬å‡(é•¿xå®½xé«˜)
    å¹³å‡ä»·æ ¼: 3530â‚½
    å–å®¶ç±»åž‹: FBS
    å‘¨è½¬åŠ¨æ€: 254.6%
    å•†å“åˆ›å»ºæ—¶é—´: 07.07.2025 (å·²åˆ›å»º 106 å¤©)
    é•¿åº¦: 550mm
    å®½åº¦: 500mm
    é«˜åº¦: 100mm
    é‡é‡: 2500g
    """
    
    # æå–æ•°æ®
    extracted_data = matcher.extract_data_from_text(test_text, "æµ‹è¯•æ–‡æœ¬")
    
    print(f"\nðŸ“Š æå–ç»“æžœæ€»è§ˆ:")
    print(f"   æ€»å…±æå–åˆ° {len(extracted_data)} ä¸ªå­—æ®µ")
    
    # éªŒè¯å…³é”®å­—æ®µ
    key_fields_to_check = [
        ("SKU", "2423301080"),
        ("å“ç‰Œ", "ZONFANT"),
        ("è¿‘30å¤©é”€é‡", "6"),
        ("æœˆé”€é‡", "7"),
        ("è´­ç‰©è½¦è½¬åŒ–çŽ‡", "4.74%"),
        ("é‡é‡", "2500 g"),
    ]
    
    print(f"\nðŸ” å…³é”®å­—æ®µéªŒè¯:")
    all_correct = True
    for key, expected_value in key_fields_to_check:
        if key in extracted_data:
            actual_value = extracted_data[key]
            if actual_value == expected_value:
                print(f"   âœ… {key}: {actual_value} (æ­£ç¡®)")
            else:
                print(f"   âŒ {key}: æœŸæœ› '{expected_value}', å®žé™… '{actual_value}'")
                all_correct = False
        else:
            print(f"   âŒ {key}: æœªæ‰¾åˆ°")
            all_correct = False
    
    # æµ‹è¯•tupleè½¬æ¢
    print(f"\nðŸ”„ æµ‹è¯•Tupleè½¬æ¢:")
    product_data = ProductData()
    product_data.extracted_fields = extracted_data
    
    # æ˜ å°„éƒ¨åˆ†å­—æ®µç”¨äºŽæµ‹è¯•
    if "SKU" in extracted_data:
        product_data.sku = extracted_data["SKU"]
    if "å“ç‰Œ" in extracted_data:
        product_data.brand = extracted_data["å“ç‰Œ"]
    if "è¿‘30å¤©é”€é‡" in extracted_data:
        product_data.sales_quantity_30days = extracted_data["è¿‘30å¤©é”€é‡"]
    if "é‡é‡" in extracted_data:
        product_data.weight = extracted_data["é‡é‡"]
    
    seefar_tuples = product_data.to_tuples("seefar")
    dianpeng_tuples = product_data.to_tuples("dianpeng")
    
    print(f"   Seefaræ ¼å¼: {len(seefar_tuples)} ä¸ªtuples")
    for i, (eng_name, key_name, value) in enumerate(seefar_tuples[:5]):  # æ˜¾ç¤ºå‰5ä¸ª
        print(f"      {i+1}. ({eng_name}, {key_name}, {value})")
    
    print(f"   Dianpengæ ¼å¼: {len(dianpeng_tuples)} ä¸ªtuples")
    for i, (eng_name, key_name, value) in enumerate(dianpeng_tuples[:5]):  # æ˜¾ç¤ºå‰5ä¸ª
        print(f"      {i+1}. ({eng_name}, {key_name}, {value})")
    
    # æ€»ç»“
    if all_correct:
        print(f"\nðŸŽ‰ åŸºäºŽKeyçš„åŒ¹é…æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¼˜åŒ–åŒ¹é…è§„åˆ™")
    
    return all_correct, extracted_data

def compare_with_expected_tuples():
    """ä¸Žé¢„æœŸçš„tuplesè¿›è¡Œå¯¹æ¯”"""
    print("\n" + "="*80)
    print("ðŸ” ä¸Žé¢„æœŸç»“æžœå¯¹æ¯”æµ‹è¯•")
    print("="*80)
    
    # è¿è¡ŒåŸºç¡€æµ‹è¯•
    success, extracted_data = test_key_based_matching()
    
    if not success:
        print("âŒ åŸºç¡€æµ‹è¯•å¤±è´¥ï¼Œè·³è¿‡å¯¹æ¯”")
        return False
    
    # åˆ›å»ºProductDataå¹¶è½¬æ¢ä¸ºtuples
    product_data = ProductData()
    product_data.extracted_fields = extracted_data
    
    # æ˜ å°„å­—æ®µ
    field_mapping = {
        "SKU": "sku",
        "sku": "sku",
        "å“ç‰Œ": "brand", 
        "è¿‘30å¤©é”€é‡": "sales_quantity_30days",
        "è¿‘30å¤©é”€å”®é¢": "sales_amount_30days",
        "æœˆé”€é‡": "monthly_sales_quantity",
        "æœˆé”€å”®é¢": "monthly_sales_amount",
        "è´­ç‰©è½¦è½¬åŒ–çŽ‡": "cart_conversion_rate",
        "å±•ç¤ºè½¬åŒ–çŽ‡": "impression_conversion_rate",
        "åŠ è´­çŽ‡": "add_to_cart_rate",
        "æ¯›åˆ©çŽ‡": "gross_profit_margin",
        "é€€è´§å–æ¶ˆçŽ‡": "return_cancel_rate",
        "æˆäº¤çŽ‡": "transaction_rate",
        "é‡é‡": "weight",
        "ä½“ç§¯": "dimensions",
        "å–å®¶": "seller",
        "å–å®¶ç±»åž‹": "seller_type",
    }
    
    for key, field in field_mapping.items():
        if key in extracted_data:
            setattr(product_data, field, extracted_data[key])
    
    # è½¬æ¢ä¸ºtuples
    actual_seefar = product_data.to_tuples("seefar")
    actual_dianpeng = product_data.to_tuples("dianpeng")
    
    # ä¸Žé¢„æœŸç»“æžœå¯¹æ¯”
    print(f"\nðŸ“Š Seefaræ ¼å¼å¯¹æ¯”:")
    seefar_matches = 0
    for expected_tuple in seefar_data_tuples:
        eng_name, key_name, expected_value = expected_tuple
        
        # åœ¨å®žé™…ç»“æžœä¸­æŸ¥æ‰¾åŒ¹é…çš„tuple
        found = False
        for actual_tuple in actual_seefar:
            actual_eng, actual_key, actual_value = actual_tuple
            if actual_key == key_name:  # åŸºäºŽkeyåŒ¹é…
                found = True
                if str(actual_value) == str(expected_value):
                    print(f"   âœ… {key_name}: {actual_value} (å®Œå…¨åŒ¹é…)")
                    seefar_matches += 1
                else:
                    print(f"   âš ï¸ {key_name}: æœŸæœ› '{expected_value}', å®žé™… '{actual_value}' (keyåŒ¹é…ä½†å€¼ä¸åŒ)")
                break
        
        if not found:
            print(f"   âŒ {key_name}: æœªæ‰¾åˆ°")
    
    print(f"\nðŸ“Š Dianpengæ ¼å¼å¯¹æ¯”:")
    dianpeng_matches = 0
    for expected_tuple in dianpeng_data_tuples:
        eng_name, key_name, expected_value = expected_tuple
        
        # åœ¨å®žé™…ç»“æžœä¸­æŸ¥æ‰¾åŒ¹é…çš„tuple
        found = False
        for actual_tuple in actual_dianpeng:
            actual_eng, actual_key, actual_value = actual_tuple
            if actual_key == key_name:  # åŸºäºŽkeyåŒ¹é…
                found = True
                if str(actual_value) == str(expected_value):
                    print(f"   âœ… {key_name}: {actual_value} (å®Œå…¨åŒ¹é…)")
                    dianpeng_matches += 1
                else:
                    print(f"   âš ï¸ {key_name}: æœŸæœ› '{expected_value}', å®žé™… '{actual_value}' (keyåŒ¹é…ä½†å€¼ä¸åŒ)")
                break
        
        if not found:
            print(f"   âŒ {key_name}: æœªæ‰¾åˆ°")
    
    # æ€»ç»“
    seefar_total = len(seefar_data_tuples)
    dianpeng_total = len(dianpeng_data_tuples)
    
    print(f"\nðŸ“ˆ å¯¹æ¯”æ€»ç»“:")
    print(f"   Seefaræ ¼å¼: {seefar_matches}/{seefar_total} å®Œå…¨åŒ¹é… ({seefar_matches/seefar_total*100:.1f}%)")
    print(f"   Dianpengæ ¼å¼: {dianpeng_matches}/{dianpeng_total} å®Œå…¨åŒ¹é… ({dianpeng_matches/dianpeng_total*100:.1f}%)")
    
    overall_success = (seefar_matches/seefar_total >= 0.7) and (dianpeng_matches/dianpeng_total >= 0.7)
    
    if overall_success:
        print(f"\nðŸŽ‰ åŸºäºŽKeyåŒ¹é…çš„æµ‹è¯•æ•´ä½“æˆåŠŸï¼")
    else:
        print(f"\nâš ï¸ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–åŒ¹é…è§„åˆ™ä»¥æé«˜å‡†ç¡®çŽ‡")
    
    return overall_success

async def main():
    """ä¸»å‡½æ•° - JSONè¾“å‡ºç‰ˆæœ¬"""

    # æµ‹è¯•é…ç½®
    test_urls = [
        {
            "name": "æ±½è½¦åŽå¤‡ç®±åž«",
            "url": "https://www.ozon.ru/product/kovrik-v-bagazhnik-iskusstvennaya-kozha-1-sht-2423301080/"
        },
        {
            "name": "å¥¥è¿ªQ7åŽå¤‡ç®±åž«",
            "url": "https://www.ozon.ru/product/kovrik-v-bagazhnik-dlya-avtomobilya-audi-ku7-audi-q7-2019-s-bortikami-eva-eva-1587428977/?at=NOtw7LoQKcPR8R6xT2L292NCB3kyo3Ujkw1ANI2w91wK"
        },
        {
            "name": "æ‰«åœ°æœºå™¨äººé›†å°˜è¢‹",
            "url": "https://www.ozon.ru/product/meshok-pylesbornik-10-sht-dlya-robota-pylesosa-roborock-s7-maxv-ultra-q5-pro-plus-q7-q7-q7-max-q7-2359442375/?at=K8tZOKLYgSk0x5p5cNzxAPLt4JMOO9F8PznMoh19yvMg"
        },
        {
            "name": "å¤œè§†é©¾é©¶çœ¼é•œ",
            "url": "https://www.ozon.ru/product/marston-ochki-antifary-solntsezashchitnye-dlya-voditelya-dlya-nochnogo-vozhdeniya-1423522090/?at=ywtAZDYQvszQ0NEkcy566LAiLM29G5cVNwLpQTLQ0YX2"
        }
    ]

    # åˆå§‹åŒ–ç»“æžœç»“æž„
    final_result = {
        "test_info": {
            "test_name": "OZONå•†å“é¡µé¢åˆ†æž - åŸºäºŽKeyåŒ¹é…",
            "test_time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_products": len(test_urls),
            "analysis_method": "key_based_matching"
        },
        "products": [],
        "summary": {}
    }

    total_start_time = time.time()

    # æµ‹è¯•æ¯ä¸ªå•†å“
    for i, product_info in enumerate(test_urls, 1):
        product_name = product_info["name"]
        url = product_info["url"]

        analyzer = KeyBasedOzonAnalyzer(debug_mode=False)  # å…³é—­è°ƒè¯•è¾“å‡º
        result = await analyzer.analyze_product_page(url)

        product_result = {
            "product_index": i,
            "product_name": product_name,
            "url": url,
            "success": False,
            "data": {},
            "tuples": {},
            "performance": {},
            "error": None
        }

        if result and result.success:
            product_result["success"] = True

            # æå–å•†å“æ•°æ®
            if result.product_data:
                product_result["data"] = result.product_data.to_dict()

            # æå–tuplesæ•°æ® - ä½¿ç”¨è‹±æ–‡key
            product_result["tuples"] = {
                "seefar_format": {
                    t[0]: {"original_key": t[1], "value": t[2]}
                    for t in result.seefar_tuples
                },
                "dianpeng_format": {
                    t[0]: {"original_key": t[1], "value": t[2]}
                    for t in result.dianpeng_tuples
                }
            }

            # æ€§èƒ½ç»Ÿè®¡
            if result.performance_stats:
                product_result["performance"] = result.performance_stats

            # å…ƒæ•°æ®
            if result.metadata:
                product_result["metadata"] = result.metadata

        else:
            product_result["error"] = result.metadata.get('error') if result else 'Unknown error'

        final_result["products"].append(product_result)

    # ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡
    total_time = time.time() - total_start_time
    successful_tests = sum(1 for p in final_result["products"] if p["success"])
    failed_tests = len(test_urls) - successful_tests

    final_result["summary"] = {
        "total_tests": len(test_urls),
        "successful_tests": successful_tests,
        "failed_tests": failed_tests,
        "success_rate": round(successful_tests / len(test_urls) * 100, 1),
        "total_execution_time": round(total_time, 3),
        "average_time_per_product": round(total_time / len(test_urls), 3),
        "status": "success" if successful_tests == len(test_urls) else "partial" if successful_tests > 0 else "failed"
    }

    # æ·»åŠ è¯¦ç»†ç»Ÿè®¡
    if successful_tests > 0:
        successful_products = [p for p in final_result["products"] if p["success"]]

        # å­—æ®µç»Ÿè®¡
        field_counts = [len(p["data"]) for p in successful_products if p["data"]]
        seefar_counts = [len(p["tuples"]["seefar_format"]) for p in successful_products if p["tuples"]]
        dianpeng_counts = [len(p["tuples"]["dianpeng_format"]) for p in successful_products if p["tuples"]]

        final_result["summary"]["data_statistics"] = {
            "average_fields_extracted": round(sum(field_counts) / len(field_counts), 1) if field_counts else 0,
            "average_seefar_tuples": round(sum(seefar_counts) / len(seefar_counts), 1) if seefar_counts else 0,
            "average_dianpeng_tuples": round(sum(dianpeng_counts) / len(dianpeng_counts), 1) if dianpeng_counts else 0
        }

        # æ€§èƒ½ç»Ÿè®¡
        performance_times = []
        for p in successful_products:
            if p["performance"].get("total_time"):
                performance_times.append(p["performance"]["total_time"])

        if performance_times:
            final_result["summary"]["performance_statistics"] = {
                "min_time": round(min(performance_times), 3),
                "max_time": round(max(performance_times), 3),
                "average_time": round(sum(performance_times) / len(performance_times), 3)
            }

    # è¾“å‡ºJSONç»“æžœ
    print(json.dumps(final_result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    asyncio.run(main())