#!/usr/bin/env python3
"""
åˆ†æOZONé¡µé¢ç»“æ„çš„è„šæœ¬
"""

import asyncio
import sys
from pathlib import Path
import re
from bs4 import BeautifulSoup

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from apps.xuanping.common.scrapers.ozon_scraper import OzonScraper
from apps.xuanping.common.config import get_config

async def analyze_ozon_page_structure():
    """åˆ†æOZONé¡µé¢ç»“æ„"""
    print("ğŸ” åˆ†æOZONé¡µé¢ç»“æ„ - å•†å“ 1756017628")
    print("="*60)
    
    # è¯»å–ä¹‹å‰ä¿å­˜çš„é¡µé¢å†…å®¹
    try:
        with open('debug_page_content.html', 'r', encoding='utf-8') as f:
            page_content = f.read()
        print("âœ… æˆåŠŸè¯»å–é¡µé¢å†…å®¹")
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ°é¡µé¢å†…å®¹æ–‡ä»¶ï¼Œéœ€è¦å…ˆè¿è¡Œ debug_price_extraction.py")
        return
    
    # ä½¿ç”¨BeautifulSoupè§£æé¡µé¢
    soup = BeautifulSoup(page_content, 'html.parser')
    
    print(f"ğŸ“„ é¡µé¢æ€»é•¿åº¦: {len(page_content)} å­—ç¬¦")
    print(f"ğŸ“„ BeautifulSoupè§£æçš„å…ƒç´ æ•°é‡: {len(soup.find_all())}")
    
    # æŸ¥æ‰¾webPriceç»„ä»¶
    print("\nğŸ” æŸ¥æ‰¾webPriceç»„ä»¶:")
    web_price_elements = soup.find_all(attrs={"data-widget": "webPrice"})
    print(f"   æ‰¾åˆ° {len(web_price_elements)} ä¸ªwebPriceç»„ä»¶")
    
    for i, element in enumerate(web_price_elements):
        print(f"   ç»„ä»¶ {i+1}:")
        print(f"     ç±»å‹: {type(element)}")
        print(f"     æ ‡ç­¾å: {getattr(element, 'name', 'N/A')}")
        # è·å–å…ƒç´ çš„HTMLè¡¨ç¤º
        html_repr = str(element)[:200] + "..." if len(str(element)) > 200 else str(element)
        print(f"     HTML: {html_repr}")
        
        # æŸ¥æ‰¾ä»·æ ¼ç›¸å…³çš„å­å…ƒç´ 
        price_spans = element.find_all('span')
        print(f"     æ‰¾åˆ° {len(price_spans)} ä¸ªspanå…ƒç´ ")
        
        for j, span in enumerate(price_spans):
            text = span.get_text(strip=True)
            if 'â‚½' in text:
                print(f"       ä»·æ ¼span {j+1}: {text}")
                # æŸ¥çœ‹spançš„classå±æ€§
                class_attr = span.get('class', [])
                if class_attr:
                    print(f"         class: {class_attr}")
    
    # æŸ¥æ‰¾åŒ…å«ç‰¹å®šä»·æ ¼çš„å…ƒç´ 
    print("\nğŸ’° æŸ¥æ‰¾ç‰¹å®šä»·æ ¼å…ƒç´ :")
    target_prices = ['15949', '16952']
    
    for price in target_prices:
        # æŸ¥æ‰¾åŒ…å«ä»·æ ¼çš„å…ƒç´ 
        price_elements = soup.find_all(text=re.compile(price))
        print(f"   ä»·æ ¼ {price}:")
        print(f"     æ‰¾åˆ° {len(price_elements)} ä¸ªåŒ¹é…å…ƒç´ ")
        
        for element in price_elements:
            # è·å–çˆ¶å…ƒç´ 
            parent = element.parent if hasattr(element, 'parent') else None
            if parent:
                text = parent.get_text(strip=True)
                if 'â‚½' in text:
                    print(f"     çˆ¶å…ƒç´ æ–‡æœ¬: {text[:100]}{'...' if len(text) > 100 else ''}")
                    # æŸ¥çœ‹çˆ¶å…ƒç´ çš„æ ‡ç­¾å’Œå±æ€§
                    print(f"     æ ‡ç­¾: {getattr(parent, 'name', 'N/A')}")
                    # æŸ¥çœ‹çˆ¶å…ƒç´ çš„classå±æ€§
                    class_attr = parent.get('class', [])
                    if class_attr:
                        print(f"     class: {class_attr}")
                    # æŸ¥çœ‹çˆ¶å…ƒç´ çš„å…¶ä»–å±æ€§
                    attrs = {k: v for k, v in parent.attrs.items() if k != 'class'}
                    if attrs:
                        print(f"     å…¶ä»–å±æ€§: {attrs}")
    
    # æŸ¥æ‰¾ä»·æ ¼ç›¸å…³çš„class
    print("\nğŸ·ï¸ æŸ¥æ‰¾ä»·æ ¼ç›¸å…³çš„class:")
    price_classes = ['price', 'cost', 'b5v3', 'tsHeadline', 'tsBody']
    
    for class_pattern in price_classes:
        elements = soup.find_all(class_=re.compile(class_pattern, re.I))
        price_elements = [el for el in elements if 'â‚½' in el.get_text()]
        if price_elements:
            print(f"   åŒ…å«'{class_pattern}'çš„å…ƒç´ ä¸­ï¼Œæ‰¾åˆ° {len(price_elements)} ä¸ªåŒ…å«ä»·æ ¼çš„å…ƒç´ ")
            for element in price_elements[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                text = element.get_text(strip=True)
                class_attr = element.get('class', [])
                print(f"     æ–‡æœ¬: {text[:50]}{'...' if len(text) > 50 else ''}")
                print(f"     class: {class_attr}")
    
    # æŸ¥æ‰¾è·Ÿå–ç›¸å…³çš„å…ƒç´ 
    print("\nğŸ“Š æŸ¥æ‰¾è·Ÿå–ç›¸å…³å…ƒç´ :")
    competitor_keywords = ['pdp_t1', 'competitor', 'seller', 'offer']
    
    for keyword in competitor_keywords:
        elements = soup.find_all(class_=re.compile(keyword, re.I))
        print(f"   åŒ…å«'{keyword}'çš„å…ƒç´ : {len(elements)} ä¸ª")
        for element in elements[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
            text = element.get_text(strip=True)
            class_attr = element.get('class', [])
            print(f"     æ–‡æœ¬: {text[:50]}{'...' if len(text) > 50 else ''}")
            print(f"     class: {class_attr}")
    
    # åˆ†æç°æœ‰çš„é€‰æ‹©å™¨
    print("\nğŸ§° åˆ†æç°æœ‰é€‰æ‹©å™¨:")
    
    # ç°æœ‰çš„ä»·æ ¼é€‰æ‹©å™¨
    price_selectors = [
        "[data-widget='webPrice'] span",
        ".b5v3 span",
        "[class*='price'] span",
        "span:-soup-contains('â‚½')",
        "[class*='b5v3'] span",
        "[data-test-id*='price'] span"
    ]
    
    for selector in price_selectors:
        elements = soup.select(selector)
        price_elements = [el for el in elements if 'â‚½' in el.get_text()]
        print(f"   é€‰æ‹©å™¨ '{selector}': {len(elements)} ä¸ªå…ƒç´ , {len(price_elements)} ä¸ªåŒ…å«ä»·æ ¼")
        for element in price_elements[:2]:
            text = element.get_text(strip=True)
            print(f"     ä»·æ ¼: {text}")
    
    print("\nâœ… åˆ†æå®Œæˆ")

if __name__ == "__main__":
    asyncio.run(analyze_ozon_page_structure())