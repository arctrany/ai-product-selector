#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ€§èƒ½åŸºå‡†æµ‹è¯•

æµ‹è¯•é‡æ„å‰åçš„æ€§èƒ½å¯¹æ¯”ï¼Œç›‘æ§å…³é”®æŒ‡æ ‡ï¼š
1. æ—¶åºæ§åˆ¶æˆåŠŸç‡
2. æ•°æ®æŠ“å–æˆåŠŸç‡
3. å¹³å‡å“åº”æ—¶é—´
4. é”™è¯¯ç‡å’Œé‡è¯•æ¬¡æ•°
"""

import sys
import time
import unittest
from pathlib import Path
from typing import Dict, Any, List
from unittest.mock import Mock, MagicMock

from tests.rpa.base_scraper_test import BaseScraperTest
from common.utils.wait_utils import WaitUtils
from common.utils.scraping_utils import ScrapingUtils


class TestPerformanceBenchmark(BaseScraperTest):
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        super().setUp()
        self.performance_metrics = {
            'wait_utils': [],
            'scraping_utils': [],
            'timing_success_rate': [],
            'scraping_success_rate': []
        }
    
    def test_wait_utils_performance(self):
        """æµ‹è¯• WaitUtils æ€§èƒ½"""
        print("\n" + "="*80)
        print("ğŸ” æµ‹è¯• WaitUtils æ€§èƒ½")
        print("="*80)
        
        # åˆ›å»º Mock æµè§ˆå™¨æœåŠ¡
        mock_browser = MagicMock()
        mock_page = MagicMock()
        mock_browser.page = mock_page
        
        # æ¨¡æ‹Ÿå…ƒç´ æŸ¥æ‰¾
        mock_element = MagicMock()
        mock_element.is_visible.return_value = True
        mock_page.wait_for_selector.return_value = mock_element
        
        wait_utils = WaitUtils(mock_browser, self.logger)
        
        # æµ‹è¯•ç­‰å¾…å…ƒç´ å¯è§
        iterations = 10
        total_time = 0
        success_count = 0
        
        for i in range(iterations):
            start_time = time.time()
            try:
                result = wait_utils.wait_for_element_visible('.test-selector', timeout=1000)
                if result:
                    success_count += 1
                elapsed = time.time() - start_time
                total_time += elapsed
                self.performance_metrics['wait_utils'].append(elapsed)
            except Exception as e:
                self.logger.warning(f"ç­‰å¾…å…ƒç´ å¤±è´¥: {e}")
        
        avg_time = total_time / iterations
        success_rate = (success_count / iterations) * 100
        
        print(f"âœ… WaitUtils å¹³å‡å“åº”æ—¶é—´: {avg_time*1000:.2f}ms")
        print(f"âœ… æˆåŠŸç‡: {success_rate:.1f}%")
        
        self.performance_metrics['timing_success_rate'].append(success_rate)
        
        # æ€§èƒ½æ–­è¨€
        self.assertGreater(success_rate, 80, "æ—¶åºæ§åˆ¶æˆåŠŸç‡åº”å¤§äº80%")
        self.assertLess(avg_time, 0.5, "å¹³å‡å“åº”æ—¶é—´åº”å°äº500ms")
    
    def test_scraping_utils_performance(self):
        """æµ‹è¯• ScrapingUtils æ€§èƒ½"""
        print("\n" + "="*80)
        print("ğŸ” æµ‹è¯• ScrapingUtils æ€§èƒ½")
        print("="*80)
        
        scraping_utils = ScrapingUtils(self.logger)
        
        # æµ‹è¯•ä»·æ ¼æå–æ€§èƒ½
        test_prices = [
            "14\u2009482\u2009â‚½",
            "14 556 â‚½",
            "14,562â‚½",
            "â‚½14602",
            "14864 Ñ€ÑƒĞ±"
        ]
        
        iterations = 100
        total_time = 0
        success_count = 0
        
        for _ in range(iterations):
            for price_str in test_prices:
                start_time = time.time()
                try:
                    price = scraping_utils.extract_price(price_str)
                    if price and price > 0:
                        success_count += 1
                    elapsed = time.time() - start_time
                    total_time += elapsed
                    self.performance_metrics['scraping_utils'].append(elapsed)
                except Exception as e:
                    self.logger.warning(f"ä»·æ ¼æå–å¤±è´¥: {e}")
        
        total_operations = iterations * len(test_prices)
        avg_time = total_time / total_operations
        success_rate = (success_count / total_operations) * 100
        
        print(f"âœ… ScrapingUtils å¹³å‡å“åº”æ—¶é—´: {avg_time*1000:.2f}ms")
        print(f"âœ… æ•°æ®æå–æˆåŠŸç‡: {success_rate:.1f}%")
        
        self.performance_metrics['scraping_success_rate'].append(success_rate)
        
        # æ€§èƒ½æ–­è¨€
        self.assertGreater(success_rate, 95, "æ•°æ®æå–æˆåŠŸç‡åº”å¤§äº95%")
        self.assertLess(avg_time, 0.001, "å¹³å‡å“åº”æ—¶é—´åº”å°äº1ms")
    
    def test_price_validation_performance(self):
        """æµ‹è¯•ä»·æ ¼éªŒè¯æ€§èƒ½"""
        print("\n" + "="*80)
        print("ğŸ” æµ‹è¯•ä»·æ ¼éªŒè¯æ€§èƒ½")
        print("="*80)
        
        scraping_utils = ScrapingUtils(self.logger)
        
        test_cases = [
            (14482.0, True),
            (0, False),
            (-100, False),
            (None, False),
            (999999, True)
        ]
        
        iterations = 1000
        total_time = 0
        success_count = 0
        
        for _ in range(iterations):
            for price, expected in test_cases:
                start_time = time.time()
                try:
                    result = scraping_utils.validate_price(price)
                    if result == expected:
                        success_count += 1
                    elapsed = time.time() - start_time
                    total_time += elapsed
                except Exception as e:
                    self.logger.warning(f"ä»·æ ¼éªŒè¯å¤±è´¥: {e}")
        
        total_operations = iterations * len(test_cases)
        avg_time = total_time / total_operations
        success_rate = (success_count / total_operations) * 100
        
        print(f"âœ… ä»·æ ¼éªŒè¯å¹³å‡å“åº”æ—¶é—´: {avg_time*1000:.2f}ms")
        print(f"âœ… éªŒè¯å‡†ç¡®ç‡: {success_rate:.1f}%")
        
        # æ€§èƒ½æ–­è¨€
        self.assertEqual(success_rate, 100, "ä»·æ ¼éªŒè¯å‡†ç¡®ç‡åº”ä¸º100%")
        self.assertLess(avg_time, 0.0001, "å¹³å‡å“åº”æ—¶é—´åº”å°äº0.1ms")
    
    def test_text_cleaning_performance(self):
        """æµ‹è¯•æ–‡æœ¬æ¸…ç†æ€§èƒ½"""
        print("\n" + "="*80)
        print("ğŸ” æµ‹è¯•æ–‡æœ¬æ¸…ç†æ€§èƒ½")
        print("="*80)
        
        scraping_utils = ScrapingUtils(self.logger)
        
        test_texts = [
            "  Ğ¡Ñ‡Ğ°ÑÑ‚Ğ»Ğ¸Ğ²Ñ‹Ğ¹ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½  ",
            "\n\nGood and excellent 12\n",
            "\t\tNEW Ğ’Ğ¾ÑĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ñ\t\t",
            "   Original   quality   store   ",
            None
        ]
        
        iterations = 1000
        total_time = 0
        
        for _ in range(iterations):
            for text in test_texts:
                start_time = time.time()
                try:
                    cleaned = scraping_utils.clean_text(text)
                    elapsed = time.time() - start_time
                    total_time += elapsed
                except Exception as e:
                    self.logger.warning(f"æ–‡æœ¬æ¸…ç†å¤±è´¥: {e}")
        
        total_operations = iterations * len(test_texts)
        avg_time = total_time / total_operations
        
        print(f"âœ… æ–‡æœ¬æ¸…ç†å¹³å‡å“åº”æ—¶é—´: {avg_time*1000:.2f}ms")
        
        # æ€§èƒ½æ–­è¨€
        self.assertLess(avg_time, 0.0001, "å¹³å‡å“åº”æ—¶é—´åº”å°äº0.1ms")
    
    def tearDown(self):
        """æµ‹è¯•æ¸…ç†å¹¶è¾“å‡ºæ€§èƒ½æŠ¥å‘Š"""
        super().tearDown()
        self._print_performance_report()
    
    def _print_performance_report(self):
        """è¾“å‡ºæ€§èƒ½æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“Š æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        
        if self.performance_metrics['wait_utils']:
            avg_wait = sum(self.performance_metrics['wait_utils']) / len(self.performance_metrics['wait_utils'])
            print(f"â±ï¸  WaitUtils å¹³å‡å“åº”æ—¶é—´: {avg_wait*1000:.2f}ms")
        
        if self.performance_metrics['scraping_utils']:
            avg_scrape = sum(self.performance_metrics['scraping_utils']) / len(self.performance_metrics['scraping_utils'])
            print(f"â±ï¸  ScrapingUtils å¹³å‡å“åº”æ—¶é—´: {avg_scrape*1000:.2f}ms")
        
        if self.performance_metrics['timing_success_rate']:
            avg_timing_success = sum(self.performance_metrics['timing_success_rate']) / len(self.performance_metrics['timing_success_rate'])
            print(f"âœ… æ—¶åºæ§åˆ¶æˆåŠŸç‡: {avg_timing_success:.1f}%")
        
        if self.performance_metrics['scraping_success_rate']:
            avg_scraping_success = sum(self.performance_metrics['scraping_success_rate']) / len(self.performance_metrics['scraping_success_rate'])
            print(f"âœ… æ•°æ®æŠ“å–æˆåŠŸç‡: {avg_scraping_success:.1f}%")
        
        print("="*80)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("="*80)
    
    # è¿è¡Œæµ‹è¯•
    suite = unittest.TestLoader().loadTestsFromTestCase(TestPerformanceBenchmark)
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # è¿”å›é€€å‡ºç 
    return 0 if result.wasSuccessful() else 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
