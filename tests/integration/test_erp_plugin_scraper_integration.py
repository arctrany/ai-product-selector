#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ErpPluginScraper çœŸå®é›†æˆæµ‹è¯•

ä½¿ç”¨ test_data ä¸­çš„çœŸå® URL å’ŒçœŸå®æµè§ˆå™¨æœåŠ¡è¿›è¡Œé›†æˆæµ‹è¯•ï¼Œä¸ä½¿ç”¨ Mockã€‚
åƒ xp å‘½ä»¤å¯åŠ¨æµè§ˆå™¨æœåŠ¡é‚£æ ·è¿›è¡ŒçœŸå®çš„æ•°æ®æŠ“å–æµ‹è¯•ã€‚
"""

import sys
import json
import time
import pytest
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent  # éœ€è¦ä¸Šå‡3çº§åˆ°è¾¾é¡¹ç›®æ ¹ç›®å½•
sys.path.insert(0, str(project_root))

from common.scrapers.erp_plugin_scraper import ErpPluginScraper
from common.models.scraping_result import ScrapingResult
from common.config.erp_selectors_config import get_erp_selectors_config


def load_test_cases() -> List[Dict[str, Any]]:
    """åŠ è½½æµ‹è¯•ç”¨ä¾‹æ•°æ®"""
    try:
        test_data_file = Path(__file__).parent / "test_data" / "ozon_test_cases.json"
        with open(test_data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('test_cases', [])
    except FileNotFoundError:
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤æµ‹è¯•ç”¨ä¾‹
        print("âš ï¸ test_data/ozon_test_cases.json æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•ç”¨ä¾‹")
        return [
            {
                "id": "default_test_case",
                "name": "é»˜è®¤é›†æˆæµ‹è¯•ç”¨ä¾‹",
                "url": "https://www.ozon.ru/product/1176594312",
                "description": "é»˜è®¤çš„çœŸå®URLæµ‹è¯•ç”¨ä¾‹",
                "expected": {
                    "has_data": True
                }
            }
        ]
    except Exception as e:
        print(f"âŒ åŠ è½½æµ‹è¯•æ•°æ®æ—¶å‡ºç°å¼‚å¸¸: {e}")
        return []


class TestErpPluginScraperIntegration:
    """ErpPluginScraper çœŸå®é›†æˆæµ‹è¯•ç±»
    
    ä½¿ç”¨çœŸå®æµè§ˆå™¨æœåŠ¡å’Œ test_data ä¸­çš„çœŸå® URL è¿›è¡Œæµ‹è¯•
    """

    @classmethod
    def setup_class(cls):
        """æµ‹è¯•ç±»åˆå§‹åŒ– - åŠ è½½æµ‹è¯•æ•°æ®"""
        print("\nğŸš€ å¯åŠ¨ ErpPluginScraper çœŸå®é›†æˆæµ‹è¯•")
        print("=" * 80)
        
        # åŠ è½½æµ‹è¯•ç”¨ä¾‹æ•°æ®
        cls.test_cases = load_test_cases()
        print(f"ğŸ“Š åŠ è½½äº† {len(cls.test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
        
        # åˆå§‹åŒ–é…ç½®
        cls.selectors_config = get_erp_selectors_config()
        print("âš™ï¸ é…ç½®åˆå§‹åŒ–å®Œæˆ")

    @classmethod
    def teardown_class(cls):
        """æµ‹è¯•ç±»æ¸…ç†"""
        print("\nğŸ”„ å®Œæˆ ErpPluginScraper çœŸå®é›†æˆæµ‹è¯•")
        print("=" * 80)

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•çš„åˆå§‹åŒ–"""
        self.scraper = None

    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•çš„æ¸…ç†"""
        if self.scraper:
            try:
                self.scraper.close()
                print("âœ… æŠ“å–å™¨å·²å…³é—­")
            except Exception as e:
                print(f"âš ï¸ å…³é—­æŠ“å–å™¨æ—¶å‡ºç°å¼‚å¸¸: {e}")



    @pytest.mark.parametrize("test_case", load_test_cases())
    def test_scrape_with_real_urls(self, test_case):
        """ä½¿ç”¨çœŸå®URLè¿›è¡Œæ•°æ®æŠ“å–æµ‹è¯•
        
        Args:
            test_case: æ¥è‡ª test_data/ozon_test_cases.json çš„æµ‹è¯•ç”¨ä¾‹
        """
        test_url = test_case['url']
        test_name = test_case['name']
        test_id = test_case['id']
        
        print(f"\nğŸ” æµ‹è¯•ç”¨ä¾‹: {test_name} ({test_id})")
        print(f"ğŸŒ æµ‹è¯•URL: {test_url}")
        
        # åˆå§‹åŒ–ErpPluginScraperï¼ˆä½¿ç”¨çœŸå®æµè§ˆå™¨æœåŠ¡ï¼‰
        print("ğŸ“‹ åˆå§‹åŒ– ErpPluginScraper...")
        self.scraper = ErpPluginScraper(selectors_config=self.selectors_config)
        print("âœ… ErpPluginScraper åˆå§‹åŒ–æˆåŠŸ")
        
        # æ‰§è¡ŒçœŸå®æ•°æ®æŠ“å–
        print("ğŸ”„ å¼€å§‹æŠ“å–ERPæ•°æ®...")
        start_time = time.time()
        
        try:
            # è°ƒç”¨çœŸå®çš„scrapeæ–¹æ³•
            result = self.scraper.scrape(target=test_url)
            
            execution_time = time.time() - start_time
            print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
            
            # éªŒè¯æŠ“å–ç»“æœ
            self._validate_scraping_result(result, test_case, test_url)
            
            # ğŸ” æ·»åŠ è¯¦ç»†çš„æŠ“å–ç»“æœæ¦‚è§ˆ
            self._print_detailed_scraping_summary(result)

            # ğŸ–¨ï¸ æ·»åŠ å®Œæ•´æ•°æ®æ‰“å°åŠŸèƒ½
            self._print_complete_scraped_data(result, test_case)

            print(f"âœ… æµ‹è¯•ç”¨ä¾‹ {test_id} é€šè¿‡")

        except Exception as e:
            print(f"âŒ æµ‹è¯•ç”¨ä¾‹ {test_id} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            pytest.fail(f"çœŸå®URLæŠ“å–æµ‹è¯•å¤±è´¥: {e}")

    def _validate_scraping_result(self, result: ScrapingResult, test_case: Dict[str, Any], test_url: str):
        """éªŒè¯æŠ“å–ç»“æœ

        Args:
            result: æŠ“å–ç»“æœ
            test_case: æµ‹è¯•ç”¨ä¾‹æ•°æ®
            test_url: æµ‹è¯•URL
        """
        # åŸºæœ¬éªŒè¯ï¼šæŠ“å–å¿…é¡»æˆåŠŸ
        assert result is not None, "æŠ“å–ç»“æœä¸èƒ½ä¸ºç©º"

        if not result.success:
            print(f"âš ï¸ æŠ“å–æœªæˆåŠŸ: {result.error_message}")
            # å¯¹äºçœŸå®ç½‘ç»œæµ‹è¯•ï¼Œæˆ‘ä»¬å¯ä»¥å®¹å¿æŸäº›å¤±è´¥ï¼ˆç½‘ç»œé—®é¢˜ã€é¡µé¢å˜åŒ–ç­‰ï¼‰
            pytest.skip(f"è·³è¿‡æµ‹è¯• - æŠ“å–å¤±è´¥å¯èƒ½ç”±äºç½‘ç»œæˆ–é¡µé¢å˜åŒ–: {result.error_message}")

        print("âœ… æ•°æ®æŠ“å–æˆåŠŸ")

        # éªŒè¯æ•°æ®ä¸ä¸ºç©º
        assert isinstance(result.data, dict), "æŠ“å–æ•°æ®å¿…é¡»æ˜¯å­—å…¸ç±»å‹"
        print(f"ğŸ“Š æå–å­—æ®µæ•°é‡: {len(result.data)}")

        # ğŸ” ç®€åŒ–çš„åŸºæœ¬æ•°æ®æ˜¾ç¤ºï¼ˆé¿å…é‡å¤ï¼‰
        print("ğŸ“‹ æŠ“å–æˆåŠŸ - è¯¦ç»†æ•°æ®å°†åœ¨åç»­æ­¥éª¤ä¸­æ˜¾ç¤º")

        # éªŒè¯å…³é”®å­—æ®µå­˜åœ¨æ€§
        self._validate_key_fields(result.data, test_case)

        # éªŒè¯ç‰¹æ®Šè§£æåŠŸèƒ½
        self._validate_special_parsing(result.data, test_case)

        # éªŒè¯æœŸæœ›ç»“æœï¼ˆå¦‚æœæä¾›ï¼‰
        if 'expected' in test_case:
            self._validate_expected_results(result.data, test_case['expected'])

    def _validate_key_fields(self, data: Dict[str, Any], test_case: Dict[str, Any]):
        """éªŒè¯å…³é”®å­—æ®µ"""
        print("\nğŸ” éªŒè¯å…³é”®å­—æ®µ:")

        # ERPæ•°æ®çš„æ ¸å¿ƒå­—æ®µ
        important_fields = [
            'category', 'sku', 'brand_name', 'monthly_sales_volume',
            'monthly_sales_amount', 'daily_sales_volume', 'daily_sales_amount'
        ]

        # è®¡ç®—å­˜åœ¨çš„é‡è¦å­—æ®µ
        existing_fields = [field for field in important_fields if field in data and data[field] is not None]

        print(f"  ğŸ“ˆ å­˜åœ¨çš„é‡è¦å­—æ®µ ({len(existing_fields)}/{len(important_fields)}): {existing_fields}")

        # è‡³å°‘åº”è¯¥æœ‰ä¸€äº›ERPæ•°æ®
        if len(existing_fields) == 0:
            print("  âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•é‡è¦çš„ERPå­—æ®µ")
        else:
            print(f"  âœ… æˆåŠŸæå–äº† {len(existing_fields)} ä¸ªé‡è¦å­—æ®µ")

    def _validate_special_parsing(self, data: Dict[str, Any], test_case: Dict[str, Any]):
        """éªŒè¯ç‰¹æ®Šè§£æåŠŸèƒ½"""
        print("\nğŸ” éªŒè¯ç‰¹æ®Šè§£æ:")

        # å°ºå¯¸è§£æéªŒè¯
        if all(dim in data for dim in ['length', 'width', 'height']):
            dimensions = f"{data['length']}x{data['width']}x{data['height']}"
            print(f"  âœ… å°ºå¯¸è§£æ: {dimensions}mm")
        else:
            print("  âšª å°ºå¯¸ä¿¡æ¯æœªæ‰¾åˆ°æˆ–è§£æå¤±è´¥")

        # é‡é‡è§£æéªŒè¯
        if 'weight' in data and isinstance(data['weight'], (int, float)):
            print(f"  âœ… é‡é‡è§£æ: {data['weight']}g")
        else:
            print("  âšª é‡é‡ä¿¡æ¯æœªæ‰¾åˆ°æˆ–è§£æå¤±è´¥")

        # ä½£é‡‘ç‡è§£æéªŒè¯
        if 'rfbs_commission_rates' in data and isinstance(data['rfbs_commission_rates'], list):
            print(f"  âœ… ä½£é‡‘ç‡è§£æ: {data['rfbs_commission_rates']}")
        else:
            print("  âšª ä½£é‡‘ç‡ä¿¡æ¯æœªæ‰¾åˆ°æˆ–è§£æå¤±è´¥")

        # ä¸Šæ¶æ—¶é—´è§£æéªŒè¯
        if 'listing_date_parsed' in data and 'shelf_days' in data:
            print(f"  âœ… ä¸Šæ¶æ—¶é—´è§£æ: {data['listing_date_parsed']} ({data['shelf_days']}å¤©)")
        else:
            print("  âšª ä¸Šæ¶æ—¶é—´ä¿¡æ¯æœªæ‰¾åˆ°æˆ–è§£æå¤±è´¥")

    def _validate_expected_results(self, data: Dict[str, Any], expected: Dict[str, Any]):
        """éªŒè¯æœŸæœ›ç»“æœ"""
        print("\nğŸ¯ éªŒè¯æœŸæœ›ç»“æœ:")

        for key, expected_value in expected.items():
            if key == 'has_data':
                # éªŒè¯æ˜¯å¦æœ‰æ•°æ®
                has_data = len(data) > 0
                if expected_value:
                    assert has_data, "æœŸæœ›æœ‰æ•°æ®ï¼Œä½†å®é™…æ— æ•°æ®"
                    print(f"  âœ… has_data: {has_data} (ç¬¦åˆæœŸæœ›)")
                else:
                    assert not has_data, "æœŸæœ›æ— æ•°æ®ï¼Œä½†å®é™…æœ‰æ•°æ®"
                    print(f"  âœ… has_data: {has_data} (ç¬¦åˆæœŸæœ›)")

            elif key in ['green_price', 'black_price']:
                # ä»·æ ¼å­—æ®µéªŒè¯ï¼ˆå¯èƒ½ä¸åœ¨ERPæ•°æ®ä¸­ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼‰
                if key in data:
                    print(f"  â„¹ï¸ {key}: {data[key]} (ERPæ•°æ®ä¸­åŒ…å«ä»·æ ¼ä¿¡æ¯)")
                else:
                    print(f"  âšª {key}: ä¸åœ¨ERPæ•°æ®ä¸­ (è¿™æ˜¯æ­£å¸¸çš„)")

            elif key in data:
                # å…¶ä»–å­—æ®µçš„ç›´æ¥æ¯”è¾ƒ
                actual_value = data[key]
                if actual_value == expected_value:
                    print(f"  âœ… {key}: {actual_value} (ç¬¦åˆæœŸæœ›)")
                else:
                    print(f"  âš ï¸ {key}: å®é™…={actual_value}, æœŸæœ›={expected_value} (ä¸å®Œå…¨åŒ¹é…ï¼Œå¯èƒ½ç”±äºé¡µé¢å˜åŒ–)")

    def _print_detailed_scraping_summary(self, result: ScrapingResult):
        """æ‰“å°è¯¦ç»†çš„æŠ“å–ç»“æœæ¦‚è§ˆ

        Args:
            result: æŠ“å–ç»“æœå¯¹è±¡
        """
        if not result or not result.success:
            return

        print("\n" + "="*60)
        print("ğŸ“ˆ è¯¦ç»†æŠ“å–ç»“æœæ¦‚è§ˆ")
        print("="*60)

        # åŸºæœ¬ä¿¡æ¯
        print(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
        print(f"ğŸ“Š çŠ¶æ€: {result.status.value}")
        print(f"ğŸ•’ æŠ“å–æ—¶é—´: {result.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")

        # æ•°æ®ç»Ÿè®¡
        raw_data_count = len(result.data) if result.data else 0
        formatted_data_count = len(result.data.get('formatted', {})) if result.data and 'formatted' in result.data else 0

        print(f"ğŸ“„ åŸå§‹æ•°æ®å­—æ®µæ•°: {raw_data_count}")
        print(f"ğŸ“„ æ ¼å¼åŒ–æ•°æ®å­—æ®µæ•°: {formatted_data_count}")

        # å…³é”®å­—æ®µå±•ç¤º
        key_fields = [
            'category', 'sku', 'brand_name', 'monthly_sales_volume',
            'monthly_sales_amount', 'daily_sales_volume', 'daily_sales_amount'
        ]

        print("\nğŸ”‘ å…³é”®ERPå­—æ®µ:")
        for field in key_fields:
            if result.data and field in result.data:
                value = result.data[field]
                print(f"  {field}: {value}")
            else:
                print(f"  {field}: æœªæ‰¾åˆ°")

        # ç‰¹æ®Šè§£æå­—æ®µ
        special_fields = [
            ('ğŸ“ å°ºå¯¸ä¿¡æ¯', ['length', 'width', 'height']),
            ('âš–ï¸  é‡é‡ä¿¡æ¯', ['weight']),
            ('ğŸ’° ä½£é‡‘ä¿¡æ¯', ['rfbs_commission_rates']),
            ('ğŸ“… ä¸Šæ¶æ—¶é—´', ['listing_date_parsed', 'shelf_days'])
        ]

        print("\nğŸ” ç‰¹æ®Šè§£æå­—æ®µ:")
        for label, fields in special_fields:
            found_fields = []
            for field in fields:
                if result.data and field in result.data:
                    found_fields.append(f"{field}={result.data[field]}")

            if found_fields:
                print(f"  {label}: {', '.join(found_fields)}")
            else:
                print(f"  {label}: æœªè§£æ")

        print("="*60)

    def _print_complete_scraped_data(self, result: ScrapingResult, test_case: Dict[str, Any]):
        """æ‰“å°å®Œæ•´çš„æŠ“å–æ•°æ®ï¼ŒåŒ…æ‹¬JSONæ ¼å¼è¾“å‡º

        Args:
            result: æŠ“å–ç»“æœå¯¹è±¡
            test_case: æµ‹è¯•ç”¨ä¾‹ä¿¡æ¯
        """
        if not result or not result.success or not result.data:
            print("âš ï¸ æ— æŠ“å–æ•°æ®å¯æ‰“å°")
            return

        print("\n" + "ğŸ–¨ï¸" * 20 + " å®Œæ•´æŠ“å–æ•°æ®è¾“å‡º " + "ğŸ–¨ï¸" * 20)

        # 1. åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ“‹ æµ‹è¯•ç”¨ä¾‹: {test_case.get('name', 'æœªçŸ¥')}")
        print(f"ğŸŒ URL: {test_case.get('url', 'æœªçŸ¥')}")
        print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {result.execution_time:.3f}ç§’")
        print(f"ğŸ•’ æŠ“å–æ—¶é—´: {result.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")

        # 2. æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ
        total_fields = len(result.data) if result.data else 0
        formatted_fields = len(result.data.get('formatted', {})) if 'formatted' in result.data else 0
        type_info_fields = len(result.data.get('data_types', {})) if 'data_types' in result.data else 0

        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  â€¢ æ€»å­—æ®µæ•°: {total_fields}")
        print(f"  â€¢ æ ¼å¼åŒ–å­—æ®µæ•°: {formatted_fields}")
        print(f"  â€¢ ç±»å‹ä¿¡æ¯å­—æ®µæ•°: {type_info_fields}")

        # 3. åŸå§‹æ•°æ®æ‘˜è¦ï¼ˆåªæ˜¾ç¤ºéæ ¼å¼åŒ–çš„å­—æ®µï¼‰
        raw_data = {k: v for k, v in result.data.items()
                   if k not in ['formatted', 'data_types']}

        if raw_data:
            print(f"\nğŸ“„ åŸå§‹æ•°æ®å­—æ®µ ({len(raw_data)}ä¸ª):")
            for i, (key, value) in enumerate(raw_data.items(), 1):
                # é™åˆ¶æ˜¾ç¤ºé•¿åº¦ï¼Œé¿å…è¾“å‡ºè¿‡é•¿
                str_value = str(value)
                if len(str_value) > 100:
                    display_value = str_value[:97] + "..."
                else:
                    display_value = str_value
                print(f"  {i:2d}. {key}: {display_value}")

        # 4. æ ¼å¼åŒ–æ•°æ®è¯¦ç»†è¾“å‡º
        if 'formatted' in result.data and result.data['formatted']:
            formatted_data = result.data['formatted']
            print(f"\nâœ¨ æ ¼å¼åŒ–æ•°æ®è¯¦ç»†è¾“å‡º ({len(formatted_data)}ä¸ªå­—æ®µ):")

            # æŒ‰é‡è¦æ€§åˆ†ç»„æ˜¾ç¤º
            important_fields = [
                'sku', 'brand_name', 'category', 'monthly_sales_volume',
                'monthly_sales_amount', 'daily_sales_volume', 'daily_sales_amount'
            ]

            product_fields = ['length', 'width', 'height', 'weight']
            business_fields = ['rfbs_commission_rates', 'listing_date_parsed', 'shelf_days']

            # æ˜¾ç¤ºé‡è¦å­—æ®µ
            print("  ğŸ“ˆ æ ¸å¿ƒERPå­—æ®µ:")
            for field in important_fields:
                if field in formatted_data:
                    value = formatted_data[field]
                    if isinstance(value, dict):
                        print(f"    {field}: {json.dumps(value, ensure_ascii=False, indent=6)[1:-1]}")
                    else:
                        print(f"    {field}: {value}")

            # æ˜¾ç¤ºäº§å“å­—æ®µ
            product_found = any(field in formatted_data for field in product_fields)
            if product_found:
                print("  ğŸ“¦ äº§å“å±æ€§:")
                for field in product_fields:
                    if field in formatted_data:
                        print(f"    {field}: {formatted_data[field]}")

            # æ˜¾ç¤ºä¸šåŠ¡å­—æ®µ
            business_found = any(field in formatted_data for field in business_fields)
            if business_found:
                print("  ğŸ’¼ ä¸šåŠ¡ä¿¡æ¯:")
                for field in business_fields:
                    if field in formatted_data:
                        value = formatted_data[field]
                        if isinstance(value, (list, dict)):
                            print(f"    {field}: {json.dumps(value, ensure_ascii=False)}")
                        else:
                            print(f"    {field}: {value}")

            # æ˜¾ç¤ºå…¶ä»–å­—æ®µ
            other_fields = {k: v for k, v in formatted_data.items()
                          if k not in important_fields + product_fields + business_fields}
            if other_fields:
                print(f"  ğŸ”§ å…¶ä»–å­—æ®µ ({len(other_fields)}ä¸ª):")
                for key, value in other_fields.items():
                    if isinstance(value, (dict, list)):
                        print(f"    {key}: {json.dumps(value, ensure_ascii=False)}")
                    else:
                        print(f"    {key}: {value}")

        # 5. æ•°æ®ç±»å‹ä¿¡æ¯
        if 'data_types' in result.data and result.data['data_types']:
            type_info = result.data['data_types']
            print(f"\nğŸ·ï¸ æ•°æ®ç±»å‹ä¿¡æ¯ ({len(type_info)}ä¸ª):")
            type_groups = {}
            for field, dtype in type_info.items():
                if dtype not in type_groups:
                    type_groups[dtype] = []
                type_groups[dtype].append(field)

            for dtype, fields in type_groups.items():
                print(f"  {dtype}: {', '.join(fields)}")

        # 6. JSONæ ¼å¼å®Œæ•´æ•°æ®è¾“å‡ºï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•ï¼‰
        print(f"\nğŸ’¾ å®Œæ•´JSONæ•°æ®è¾“å‡º:")
        print("â”€" * 80)
        try:
            # åˆ›å»ºä¸€ä¸ªç”¨äºJSONè¾“å‡ºçš„å¹²å‡€æ•°æ®ç»“æ„
            json_output = {
                "meta": {
                    "test_case": test_case.get('name', 'æœªçŸ¥'),
                    "url": test_case.get('url', 'æœªçŸ¥'),
                    "execution_time": round(result.execution_time, 3),
                    "timestamp": result.timestamp.isoformat(),
                    "status": result.status.value
                },
                "raw_data": raw_data,
                "formatted_data": result.data.get('formatted', {}),
                "data_types": result.data.get('data_types', {})
            }

            print(json.dumps(json_output, ensure_ascii=False, indent=2))
        except Exception as e:
            print(f"JSONåºåˆ—åŒ–å¤±è´¥: {e}")
            print("åŸå§‹æ•°æ®ç»“æ„:")
            import pprint
            pprint.pprint(result.data, width=120)

        print("â”€" * 80)
        print("ğŸ–¨ï¸" * 60 + " æ•°æ®è¾“å‡ºå®Œæˆ " + "ğŸ–¨ï¸" * 60)

    def test_erp_scraper_initialization(self):
        """æµ‹è¯•ErpPluginScraperåˆå§‹åŒ–"""
        print("\nğŸ”§ æµ‹è¯•ErpPluginScraperåˆå§‹åŒ–")

        # æµ‹è¯•åŸºæœ¬åˆå§‹åŒ–
        scraper = ErpPluginScraper()
        assert scraper is not None
        assert scraper.selectors_config is not None
        assert hasattr(scraper, 'browser_service')
        print("âœ… åŸºæœ¬åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

        # æµ‹è¯•å¸¦é…ç½®çš„åˆå§‹åŒ–
        config = get_erp_selectors_config()
        scraper_with_config = ErpPluginScraper(selectors_config=config)
        assert scraper_with_config.selectors_config == config
        print("âœ… å¸¦é…ç½®åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

        # æ¸…ç†
        scraper.close()
        scraper_with_config.close()

    def test_validate_data_method(self):
        """æµ‹è¯•æ•°æ®éªŒè¯æ–¹æ³•"""
        print("\nğŸ§ª æµ‹è¯•æ•°æ®éªŒè¯æ–¹æ³•")

        scraper = ErpPluginScraper()

        try:
            # æµ‹è¯•æœ‰æ•ˆæ•°æ®
            valid_data = {
                'category': 'ç”µå­äº§å“',
                'sku': 'TEST123',
                'monthly_sales_volume': '100'
            }
            assert scraper.validate_data(valid_data) is True
            print("âœ… æœ‰æ•ˆæ•°æ®éªŒè¯é€šè¿‡")

            # æµ‹è¯•ç©ºæ•°æ®
            assert scraper.validate_data({}) is False
            print("âœ… ç©ºæ•°æ®éªŒè¯é€šè¿‡")

            # æµ‹è¯•æ— æ•ˆæ•°æ®
            invalid_data = {
                'irrelevant_field': 'value'
            }
            assert scraper.validate_data(invalid_data) is False
            print("âœ… æ— æ•ˆæ•°æ®éªŒè¯é€šè¿‡")

        finally:
            scraper.close()

# ç‹¬ç«‹è¿è¡Œçš„ä¸»å‡½æ•°
def main():
    """ä¸»å‡½æ•° - ç”¨äºç‹¬ç«‹è¿è¡Œé›†æˆæµ‹è¯•"""
    print("ğŸš€ ç‹¬ç«‹è¿è¡Œ ErpPluginScraper çœŸå®é›†æˆæµ‹è¯•")

    try:
        # åˆ›å»ºæµ‹è¯•å®ä¾‹
        test_instance = TestErpPluginScraperIntegration()
        test_instance.setup_class()

        # åŠ è½½æµ‹è¯•ç”¨ä¾‹
        test_cases = load_test_cases()

        if not test_cases:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•ç”¨ä¾‹")
            return 1

        print(f"\nğŸ“Š å°†æµ‹è¯• {len(test_cases)} ä¸ªçœŸå®URL:")
        for case in test_cases:
            print(f"  â€¢ {case['name']}: {case['url']}")

        # æ‰§è¡Œæµ‹è¯•
        success_count = 0
        total_count = len(test_cases)

        for i, test_case in enumerate(test_cases, 1):
            print(f"\n{'='*60}")
            print(f"æµ‹è¯• {i}/{total_count}: {test_case['name']}")
            print(f"{'='*60}")

            try:
                test_instance.setup_method()
                test_instance.test_scrape_with_real_urls(test_case)
                success_count += 1
                print(f"âœ… æµ‹è¯• {i} æˆåŠŸ")
            except Exception as e:
                print(f"âŒ æµ‹è¯• {i} å¤±è´¥: {e}")
            finally:
                test_instance.teardown_method()

        # è¾“å‡ºç»“æœ
        print(f"\n{'='*80}")
        print(f"ğŸ æµ‹è¯•å®Œæˆ: {success_count}/{total_count} æˆåŠŸ")

        if success_count == total_count:
            print("ğŸ‰ æ‰€æœ‰çœŸå®URLé›†æˆæµ‹è¯•é€šè¿‡ï¼")
            return 0
        else:
            print(f"âš ï¸ {total_count - success_count} ä¸ªæµ‹è¯•å¤±è´¥")
            return 1

    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    # ç‹¬ç«‹è¿è¡Œæ¨¡å¼
    exit_code = main()
    sys.exit(exit_code)