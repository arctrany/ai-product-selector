"""
DOMåˆ†æå·¥å…·ç±»
æä¾›é€šç”¨çš„DOMå…ƒç´ æ·±åº¦åˆ†æåŠŸèƒ½
"""

import asyncio
import re
from typing import Dict, Any, List, Optional
from playwright.async_api import Page, ElementHandle
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from logger_config import get_logger


async def _analyze_link_element(element: ElementHandle, selector: str, index: int) -> Dict[str, Any]:
    """åˆ†æé“¾æ¥å…ƒç´ """
    tag_name = await element.evaluate('el => el.tagName.toLowerCase()')
    href = await element.get_attribute('href')
    onclick = await element.get_attribute('onclick')
    data_url = await element.get_attribute('data-url')
    data_link = await element.get_attribute('data-link')
    data_href = await element.get_attribute('data-href')
    text = await element.text_content()

    return {
        'selector': selector,
        'index': index,
        'tag': tag_name,
        'href': href,
        'onclick': onclick,
        'data_url': data_url,
        'data_link': data_link,
        'data_href': data_href,
        'text': text or ''
    }


async def _extract_dynamic_content(element: ElementHandle) -> Dict[str, Any]:
    """æ‰§è¡ŒJavaScriptè·å–åŠ¨æ€å†…å®¹"""
    try:
        print(f"      ğŸš€ æ‰§è¡ŒJavaScriptè·å–åŠ¨æ€å†…å®¹...")

        # æ‰§è¡ŒJavaScriptè·å–å¯èƒ½çš„åŠ¨æ€é“¾æ¥
        dynamic_data = await element.evaluate('''
            el => {
                const data = {};
                
                // æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„é“¾æ¥
                const links = el.querySelectorAll('a, [href], [onclick], [data-url], [data-link]');
                data.links = [];
                links.forEach((link, i) => {
                    const linkData = {
                        tag: link.tagName,
                        href: link.href,
                        onclick: link.onclick ? link.onclick.toString() : null,
                        text: link.textContent.trim(),
                        attributes: {}
                    };
                    
                    // è·å–æ‰€æœ‰å±æ€§
                    for (let attr of link.attributes) {
                        linkData.attributes[attr.name] = attr.value;
                    }
                    
                    data.links.push(linkData);
                });
                
                // æŸ¥æ‰¾æ‰€æœ‰æ–‡æœ¬å†…å®¹
                data.texts = [];
                const textElements = el.querySelectorAll('span, div, p, a');
                textElements.forEach(elem => {
                    const text = elem.textContent.trim();
                    if (text) {
                        data.texts.push(text);
                    }
                });
                
                // å°è¯•æŸ¥æ‰¾éšè—çš„é“¾æ¥æˆ–æ•°æ®
                data.hiddenData = {};
                const allElements = el.querySelectorAll('*');
                allElements.forEach(elem => {
                    // æ£€æŸ¥data-*å±æ€§
                    for (let attr of elem.attributes) {
                        if (attr.name.startsWith('data-') && attr.value) {
                            data.hiddenData[attr.name] = attr.value;
                        }
                    }
                });
                
                return data;
            }
        ''')

        print(f"      ğŸ“Š åŠ¨æ€æ•°æ®åˆ†æç»“æœ:")
        print(f"         é“¾æ¥æ•°é‡: {len(dynamic_data.get('links', []))}")
        print(f"         æ–‡æœ¬æ•°é‡: {len(dynamic_data.get('texts', []))}")
        print(f"         éšè—æ•°æ®: {dynamic_data.get('hiddenData', {})}")

        return dynamic_data

    except Exception as e:
        print(f"      âŒ åŠ¨æ€å†…å®¹æå–å¤±è´¥: {str(e)}")
        return {}


class DOMAnalyzer:
    """DOMåˆ†æå·¥å…·ç±» - æä¾›é€šç”¨çš„å…ƒç´ æ·±åº¦åˆ†æåŠŸèƒ½"""
    
    def __init__(self, page: Page, debug_mode: bool = False):
        """
        åˆå§‹åŒ–DOMåˆ†æå™¨

        Args:
            page: Playwrighté¡µé¢å¯¹è±¡
            debug_mode: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œå½±å“æ—¥å¿—è¾“å‡ºçº§åˆ«
        """
        self.page = page
        self.debug_mode = debug_mode
        self.logger = get_logger(debug_mode)
    
    async def analyze_element(self, element_or_xpath, context_info: str = "") -> Dict[str, Any]:
        """
        æ·±åº¦åˆ†æDOMå…ƒç´ ï¼Œå±•å¼€æ‰€æœ‰å­å…ƒç´ 
        
        Args:
            element_or_xpath: ElementHandleå¯¹è±¡æˆ–XPathå­—ç¬¦ä¸²
            context_info: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç”¨äºæ—¥å¿—è¾“å‡º
            
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        try:
            self.logger.debug(f"ğŸ“Š å¼€å§‹æ·±å…¥DOMç»“æ„åˆ†æ{context_info}...")
            
            # è·å–å…ƒç´ 
            if isinstance(element_or_xpath, str):
                # å¦‚æœæ˜¯XPathå­—ç¬¦ä¸²ï¼ŒæŸ¥æ‰¾å…ƒç´ 
                element = await self.page.query_selector(element_or_xpath)
                if not element:
                    self.logger.warning(f"æœªæ‰¾åˆ°å…ƒç´ : {element_or_xpath}")
                    return {}
            else:
                # å¦‚æœæ˜¯ElementHandleå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
                element = element_or_xpath
            
            analysis_result = {
                'html_structure': '',
                'all_elements': [],
                'links': [],
                'texts': [],
                'dynamic_data': {}
            }
            
            # 1. è·å–å…ƒç´ çš„å®Œæ•´HTMLç»“æ„
            html_content = await element.inner_html()
            analysis_result['html_structure'] = html_content
            self.logger.debug(f"HTMLç»“æ„: {html_content[:300]}...")
            
            # 2. è·å–æ‰€æœ‰å­å…ƒç´ 
            all_elements = await element.query_selector_all('*')
            self.logger.debug(f"æ‰¾åˆ° {len(all_elements)} ä¸ªå­å…ƒç´ ")
            
            # 3. åˆ†ææ¯ä¸ªå…ƒç´ çš„è¯¦ç»†ä¿¡æ¯
            for i, elem in enumerate(all_elements):
                try:
                    element_info = await self._analyze_single_element(elem, i)
                    analysis_result['all_elements'].append(element_info)
                    self.logger.debug(f"å…ƒç´ {i}: {element_info['tag']} | æ–‡æœ¬: '{element_info['text'][:50] if element_info['text'] else ''}' | å±æ€§: {element_info['attributes']}")
                except Exception as e:
                    self.logger.warning(f"åˆ†æå…ƒç´ {i}å¤±è´¥: {str(e)}")
                    continue
            
            # 4. ä¸“é—¨æå–é“¾æ¥ä¿¡æ¯
            links_info = await self._extract_all_links(element)
            analysis_result['links'] = links_info
            
            # 5. ä¸“é—¨æå–æ–‡æœ¬ä¿¡æ¯
            texts_info = await self._extract_all_texts(element)
            analysis_result['texts'] = texts_info
            
            # 6. æ‰§è¡ŒJavaScriptè·å–åŠ¨æ€å†…å®¹
            dynamic_info = await _extract_dynamic_content(element)
            analysis_result['dynamic_data'] = dynamic_info
            
            return analysis_result
            
        except Exception as e:
            self.logger.error(f"DOMç»“æ„åˆ†æå¤±è´¥: {str(e)}")
            return {}
    
    async def _analyze_single_element(self, element: ElementHandle, index: int) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªå…ƒç´ """
        tag_name = await element.evaluate('el => el.tagName.toLowerCase()')
        element_text = await element.text_content()
        
        # è·å–æ‰€æœ‰å±æ€§
        attributes = await element.evaluate('''
            el => {
                const attrs = {};
                for (let attr of el.attributes) {
                    attrs[attr.name] = attr.value;
                }
                return attrs;
            }
        ''')
        
        return {
            'index': index,
            'tag': tag_name,
            'text': element_text or '',
            'attributes': attributes
        }
    
    async def _extract_all_links(self, element: ElementHandle) -> List[Dict[str, Any]]:
        """æå–æ‰€æœ‰é“¾æ¥å…ƒç´ """
        try:
            self.logger.debug("æ·±å…¥åˆ†ææ‰€æœ‰é“¾æ¥å…ƒç´ ...")
            
            links_info = []
            link_selectors = ['a', '[href]', '[onclick]', '[data-url]', '[data-link]', '[data-href]']
            
            for selector in link_selectors:
                elements = await element.query_selector_all(selector)
                for i, elem in enumerate(elements):
                    try:
                        link_info = await _analyze_link_element(elem, selector, i)
                        links_info.append(link_info)
                        
                        # è¾“å‡ºé“¾æ¥ä¿¡æ¯
                        self.logger.debug(f"é“¾æ¥å…ƒç´ {i} ({selector}): {link_info['tag']}")
                        self.logger.debug(f"   href: {link_info['href']}")
                        self.logger.debug(f"   onclick: {link_info['onclick']}")
                        self.logger.debug(f"   text: {link_info['text'][:100] if link_info['text'] else ''}")
                        
                        # å°è¯•æå–çœŸå®é“¾æ¥
                        real_link = await self._extract_real_link(elem)
                        if real_link:
                            link_info['real_link'] = real_link
                            self.logger.debug(f"   çœŸå®é“¾æ¥: {real_link}")
                        
                    except Exception as e:
                        self.logger.warning(f"åˆ†æé“¾æ¥å…ƒç´ {i}å¤±è´¥: {str(e)}")
                        continue
            
            return links_info
            
        except Exception as e:
            self.logger.error(f"é“¾æ¥æå–å¤±è´¥: {str(e)}")
            return []

    async def _extract_real_link(self, element: ElementHandle) -> Optional[str]:
        """å°è¯•æå–å…ƒç´ çš„çœŸå®é“¾æ¥"""
        try:
            # 1. æ£€æŸ¥hrefå±æ€§
            href = await element.get_attribute('href')
            if href and href.strip() and not href.startswith('javascript:'):
                return href.strip()
            
            # 2. æ£€æŸ¥onclickäº‹ä»¶ä¸­çš„é“¾æ¥
            onclick = await element.get_attribute('onclick')
            if onclick:
                # å°è¯•ä»onclickä¸­æå–URL
                url_patterns = [
                    r"window\.open\(['\"]([^'\"]+)['\"]",
                    r"location\.href\s*=\s*['\"]([^'\"]+)['\"]",
                    r"window\.location\s*=\s*['\"]([^'\"]+)['\"]",
                    r"https?://[^\s'\"]+",
                ]
                for pattern in url_patterns:
                    match = re.search(pattern, onclick)
                    if match:
                        return match.group(1) if match.groups() else match.group(0)
            
            # 3. æ£€æŸ¥dataå±æ€§
            for attr in ['data-url', 'data-link', 'data-href', 'data-original-url', 'data-target-url']:
                value = await element.get_attribute(attr)
                if value and value.strip():
                    return value.strip()
            
            # 4. å°è¯•æ‰§è¡ŒJavaScriptè·å–åŠ¨æ€é“¾æ¥
            try:
                real_url = await element.evaluate('''
                    el => {
                        // å°è¯•è·å–å„ç§å¯èƒ½çš„é“¾æ¥å±æ€§
                        return el.dataset.url || el.dataset.link || el.dataset.href || 
                               el.getAttribute('data-original-url') || 
                               el.getAttribute('data-target-url') || 
                               el.getAttribute('data-product-url') || null;
                    }
                ''')
                if real_url:
                    return real_url
            except:
                pass
            
            return None
            
        except Exception as e:
            self.logger.warning(f"æå–çœŸå®é“¾æ¥å¤±è´¥: {str(e)}")
            return None
    
    async def _extract_all_texts(self, element: ElementHandle) -> List[Dict[str, Any]]:
        """æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹"""
        try:
            self.logger.debug("æ·±å…¥åˆ†ææ‰€æœ‰æ–‡æœ¬å†…å®¹...")
            
            texts_info = []
            text_elements = await element.query_selector_all('span, div, p, td, th, a, strong, em, b, i')
            
            for i, elem in enumerate(text_elements):
                try:
                    text = await elem.text_content()
                    if text and text.strip():
                        text = text.strip()
                        text_info = {
                            'index': i,
                            'text': text,
                            'length': len(text),
                            'is_numeric': text.isdigit(),
                            'is_potential_sku': text.isdigit() and len(text) >= 6
                        }
                        texts_info.append(text_info)
                        self.logger.debug(f"æ–‡æœ¬{i}: {text[:100]}...")
                        
                except Exception as e:
                    print(f"      âš ï¸ åˆ†ææ–‡æœ¬{i}å¤±è´¥: {str(e)}")
                    continue
            
            return texts_info
                    
        except Exception as e:
            print(f"      âŒ æ–‡æœ¬æå–å¤±è´¥: {str(e)}")
            return []

    async def open_product_link(self, target_url: str, context_info: str = ""):
        """å®é™…æ‰“å¼€äº§å“é“¾æ¥"""
        try:
            print(f"      ğŸŒ æ­£åœ¨æ‰“å¼€äº§å“é“¾æ¥{context_info}: {target_url}")
            
            # åœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€é“¾æ¥
            context = self.page.context
            new_page = await context.new_page()
            
            try:
                # æ‰“å¼€ç›®æ ‡é“¾æ¥
                await new_page.goto(target_url, wait_until='networkidle', timeout=15000)
                
                # è·å–é¡µé¢æ ‡é¢˜
                page_title = await new_page.title()
                print(f"      âœ… æˆåŠŸæ‰“å¼€äº§å“é¡µé¢: {page_title}")
                print(f"      ğŸ”— äº§å“é“¾æ¥: {target_url}")
                
                # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
                await asyncio.sleep(1)
                
                return {
                    'success': True,
                    'title': page_title,
                    'url': target_url
                }
                
            except Exception as e:
                print(f"      âš ï¸ æ‰“å¼€äº§å“é“¾æ¥å¤±è´¥: {str(e)}")
                return {
                    'success': False,
                    'error': str(e),
                    'url': target_url
                }
            finally:
                # å…³é—­æ–°æ ‡ç­¾é¡µ
                await new_page.close()
                print(f"      ğŸ”„ å·²å…³é—­äº§å“é¡µé¢ï¼Œè¿”å›å•†å“åˆ—è¡¨")
                
        except Exception as e:
            print(f"      âŒ æ‰“å¼€äº§å“é“¾æ¥è¿‡ç¨‹å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'url': target_url
            }