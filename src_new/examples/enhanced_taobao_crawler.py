#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆæ·˜å®å•†å“çˆ¬è™«
- æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
- æ›´æ–°é€‰æ‹©å™¨ç­–ç•¥
- å¢åŠ åçˆ¬è™«æ£€æµ‹
- æ”¯æŒChrome DevToolsåˆ†æ
"""

import asyncio
import json
import re
import sys
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)

from rpa.browser.browser_service import BrowserService
from rpa.browser.core.models.browser_config import BrowserConfig, BrowserType, ViewportConfig

class EnhancedTaobaoCrawler:
    """å¢å¼ºç‰ˆæ·˜å®å•†å“çˆ¬è™«"""
    
    def __init__(self, headless: bool = False, request_delay: float = 2.0):
        self.headless = headless
        self.request_delay = request_delay
        self.browser_service = None
        
        # æ›´æ–°çš„é€‰æ‹©å™¨ç­–ç•¥ - åŸºäº2024å¹´æ·˜å®é¡µé¢ç»“æ„
        self.selectors = {
            # é¦–é¡µå•†å“å®¹å™¨é€‰æ‹©å™¨ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰
            'homepage_products': [
                # æ–°ç‰ˆæ·˜å®é€‰æ‹©å™¨
                '[data-spm-anchor-id*="2013.1.0"]',
                '.recommend-content .item',
                '.grid-item',
                '.recommend-item',
                '.J_MouserOnverReq',
                '.item-box',
                # ä¼ ç»Ÿé€‰æ‹©å™¨
                '.item',
                '.product-item',
                '.goods-item'
            ],
            
            # å•†å“æ ‡é¢˜é€‰æ‹©å™¨
            'product_title': [
                '.item-title a',
                '.title a',
                '.product-title',
                '.item-name',
                'a[title]',
                '.J_ClickStat',
                'h3 a',
                'h4 a'
            ],
            
            # å•†å“ä»·æ ¼é€‰æ‹©å™¨
            'product_price': [
                '.price-current',
                '.price .num',
                '.price-box .price',
                '.item-price',
                '.price strong',
                '.price em',
                '.price span',
                '[class*="price"]'
            ],
            
            # å•†å“å›¾ç‰‡é€‰æ‹©å™¨
            'product_image': [
                '.item-pic img',
                '.pic img',
                '.product-img img',
                '.item-image img',
                'img[data-src]',
                'img[src*="jpg"]',
                'img[src*="png"]'
            ],
            
            # å•†å“é“¾æ¥é€‰æ‹©å™¨
            'product_link': [
                '.item-title a',
                '.title a',
                '.pic a',
                'a[href*="detail.tmall.com"]',
                'a[href*="item.taobao.com"]',
                'a[href*="chaoshi.detail.tmall.com"]'
            ]
        }
    
    async def initialize(self) -> bool:
        """åˆå§‹åŒ–æµè§ˆå™¨æœåŠ¡"""
        try:
            print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–å¢å¼ºç‰ˆæµè§ˆå™¨æœåŠ¡...")
            
            # åˆ›å»ºæµè§ˆå™¨é…ç½®
            self.browser_config = BrowserConfig(
                browser_type=BrowserType.PLAYWRIGHT,
                headless=self.headless,
                user_data_dir=None,
                viewport=ViewportConfig(width=1920, height=1080),
                user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            )
            
            # åˆ›å»ºæµè§ˆå™¨æœåŠ¡å®ä¾‹
            self.browser_service = BrowserService()
            
            # åˆå§‹åŒ–æµè§ˆå™¨
            success = await self.browser_service.initialize()
            if not success:
                print("âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥")
                return False
            
            print("âœ… å¢å¼ºç‰ˆæµè§ˆå™¨æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def navigate_to_taobao(self) -> bool:
        """å¯¼èˆªåˆ°æ·˜å®é¦–é¡µå¹¶æ£€æµ‹åçˆ¬è™«"""
        try:
            print("ğŸŒ æ­£åœ¨å¯¼èˆªåˆ°æ·˜å®é¦–é¡µ...")
            
            # å¯¼èˆªåˆ°æ·˜å®é¦–é¡µ
            success = await self.browser_service.open_page("https://www.taobao.com")
            if not success:
                print("âŒ å¯¼èˆªåˆ°æ·˜å®é¦–é¡µå¤±è´¥")
                return False
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            await asyncio.sleep(5)
            
            # æ£€æŸ¥é¡µé¢çŠ¶æ€
            page_title = await self.get_page_title()
            page_url = await self.get_page_url()
            
            print(f"ğŸ“„ é¡µé¢æ ‡é¢˜: {page_title}")
            print(f"ğŸ”— é¡µé¢URL: {page_url}")
            
            # æ£€æµ‹åçˆ¬è™«æœºåˆ¶
            await self.detect_anti_crawler()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
            await self.check_login_requirement()
            
            print(f"âœ… æˆåŠŸå¯¼èˆªåˆ°æ·˜å®é¦–é¡µ")
            return True
            
        except Exception as e:
            print(f"âŒ å¯¼èˆªå¤±è´¥: {e}")
            return False
    
    async def detect_anti_crawler(self):
        """æ£€æµ‹åçˆ¬è™«æœºåˆ¶"""
        try:
            page = self.browser_service.get_page()
            if not page:
                return
            
            # æ£€æŸ¥å¸¸è§çš„åçˆ¬è™«æ ‡è¯†
            anti_crawler_indicators = await page.evaluate("""
                () => {
                    const indicators = {
                        hasSlider: !!document.querySelector('.nc_wrapper'),
                        hasVerification: !!document.querySelector('[class*="verification"]'),
                        hasBlocked: document.title.includes('blocked') || document.title.includes('éªŒè¯'),
                        hasRedirect: window.location.href !== 'https://www.taobao.com/',
                        bodyText: document.body.innerText.substring(0, 200)
                    };
                    return indicators;
                }
            """)
            
            if anti_crawler_indicators['hasSlider']:
                print("âš ï¸ æ£€æµ‹åˆ°æ»‘å—éªŒè¯")
            if anti_crawler_indicators['hasVerification']:
                print("âš ï¸ æ£€æµ‹åˆ°éªŒè¯é¡µé¢")
            if anti_crawler_indicators['hasBlocked']:
                print("âš ï¸ æ£€æµ‹åˆ°å°ç¦é¡µé¢")
            if anti_crawler_indicators['hasRedirect']:
                print(f"âš ï¸ é¡µé¢è¢«é‡å®šå‘åˆ°: {anti_crawler_indicators.get('currentUrl', 'unknown')}")
            
            print(f"ğŸ“ é¡µé¢å†…å®¹é¢„è§ˆ: {anti_crawler_indicators['bodyText']}")
            
        except Exception as e:
            print(f"âš ï¸ åçˆ¬è™«æ£€æµ‹å¤±è´¥: {e}")
    
    async def check_login_requirement(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•"""
        try:
            page = self.browser_service.get_page()
            if not page:
                return
            
            login_indicators = await page.evaluate("""
                () => {
                    return {
                        hasLoginButton: !!document.querySelector('.login'),
                        hasLoginLink: !!document.querySelector('a[href*="login"]'),
                        isLoggedIn: !!document.querySelector('.site-nav-user'),
                        loginText: document.body.innerText.includes('ç™»å½•') || document.body.innerText.includes('è¯·ç™»å½•')
                    };
                }
            """)
            
            if login_indicators['hasLoginButton'] or login_indicators['hasLoginLink']:
                print("ğŸ” æ£€æµ‹åˆ°ç™»å½•æŒ‰é’®ï¼Œå¯èƒ½éœ€è¦ç™»å½•")
            if login_indicators['isLoggedIn']:
                print("âœ… ç”¨æˆ·å·²ç™»å½•")
            if login_indicators['loginText']:
                print("âš ï¸ é¡µé¢æç¤ºéœ€è¦ç™»å½•")
                
        except Exception as e:
            print(f"âš ï¸ ç™»å½•æ£€æŸ¥å¤±è´¥: {e}")
    
    async def get_page_title(self) -> str:
        """è·å–é¡µé¢æ ‡é¢˜"""
        try:
            page = self.browser_service.get_page()
            if page:
                return await page.title()
            return ""
        except:
            return ""
    
    async def get_page_url(self) -> str:
        """è·å–é¡µé¢URL"""
        try:
            page = self.browser_service.get_page()
            if page:
                return page.url
            return ""
        except:
            return ""
    
    async def debug_page_structure(self):
        """è°ƒè¯•é¡µé¢ç»“æ„ - æ¨¡æ‹ŸChrome DevToolsåˆ†æ"""
        try:
            print("\nğŸ” å¼€å§‹é¡µé¢ç»“æ„è°ƒè¯•åˆ†æ...")
            
            page = self.browser_service.get_page()
            if not page:
                return
            
            # åˆ†æé¡µé¢åŸºæœ¬ä¿¡æ¯
            page_info = await page.evaluate("""
                () => {
                    return {
                        title: document.title,
                        url: window.location.href,
                        totalElements: document.querySelectorAll('*').length,
                        bodyText: document.body.innerText.substring(0, 500),
                        hasJavaScript: !!window.jQuery || !!window.React || !!window.Vue
                    };
                }
            """)
            
            print(f"ğŸ“Š é¡µé¢åˆ†æç»“æœ:")
            print(f"   æ ‡é¢˜: {page_info['title']}")
            print(f"   URL: {page_info['url']}")
            print(f"   å…ƒç´ æ€»æ•°: {page_info['totalElements']}")
            print(f"   åŒ…å«JSæ¡†æ¶: {page_info['hasJavaScript']}")
            print(f"   é¡µé¢å†…å®¹é¢„è§ˆ: {page_info['bodyText'][:200]}...")
            
            # æµ‹è¯•å„ç§é€‰æ‹©å™¨
            print(f"\nğŸ¯ æµ‹è¯•å•†å“é€‰æ‹©å™¨:")
            for i, selector in enumerate(self.selectors['homepage_products'][:5]):
                try:
                    elements = await page.query_selector_all(selector)
                    count = len(elements)
                    print(f"   {i+1}. {selector}: {count} ä¸ªå…ƒç´ ")
                    
                    if count > 0 and count <= 3:  # åˆ†æå‰å‡ ä¸ªå…ƒç´ 
                        for j, element in enumerate(elements[:3]):
                            try:
                                element_info = await element.evaluate("""
                                    (el) => {
                                        return {
                                            tagName: el.tagName,
                                            className: el.className,
                                            innerHTML: el.innerHTML.substring(0, 200),
                                            textContent: el.textContent.substring(0, 100)
                                        };
                                    }
                                """)
                                print(f"      å…ƒç´  {j+1}: {element_info['tagName']}.{element_info['className'][:50]}")
                                print(f"      å†…å®¹: {element_info['textContent'][:80]}...")
                            except:
                                pass
                except Exception as e:
                    print(f"   {i+1}. {selector}: é”™è¯¯ - {e}")
            
            # æ£€æŸ¥ç½‘ç»œè¯·æ±‚
            print(f"\nğŸŒ ç½‘ç»œè¯·æ±‚åˆ†æ:")
            try:
                # ç›‘å¬ç½‘ç»œè¯·æ±‚
                requests_info = []
                
                def handle_request(request):
                    if 'api' in request.url or 'ajax' in request.url:
                        requests_info.append({
                            'url': request.url,
                            'method': request.method,
                            'resource_type': request.resource_type
                        })
                
                page.on('request', handle_request)
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´æ”¶é›†è¯·æ±‚
                await asyncio.sleep(3)
                
                print(f"   æ£€æµ‹åˆ° {len(requests_info)} ä¸ªAPIè¯·æ±‚")
                for req in requests_info[:5]:
                    print(f"   - {req['method']} {req['url'][:80]}...")
                    
            except Exception as e:
                print(f"   ç½‘ç»œè¯·æ±‚åˆ†æå¤±è´¥: {e}")
            
        except Exception as e:
            print(f"âŒ é¡µé¢ç»“æ„è°ƒè¯•å¤±è´¥: {e}")
    
    async def extract_products_with_debug(self, max_products: int = 10) -> List[Dict[str, Any]]:
        """æå–å•†å“ä¿¡æ¯ï¼ˆå¸¦è°ƒè¯•ï¼‰"""
        products = []
        
        try:
            print(f"\nğŸ“¦ å¼€å§‹æå–å•†å“ä¿¡æ¯ (æœ€å¤š {max_products} ä¸ª)...")
            
            page = self.browser_service.get_page()
            if not page:
                return products
            
            # å°è¯•æ¯ä¸ªé€‰æ‹©å™¨
            for selector in self.selectors['homepage_products']:
                try:
                    elements = await page.query_selector_all(selector)
                    if elements and len(elements) > 0:
                        print(f"ğŸ¯ ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                        
                        # å¤„ç†å‰å‡ ä¸ªå…ƒç´ è¿›è¡Œè°ƒè¯•
                        for i, element in enumerate(elements[:max_products]):
                            try:
                                print(f"   ğŸ” åˆ†æå…ƒç´  {i+1}/{min(len(elements), max_products)}...")
                                
                                # è¯¦ç»†æå–ä¿¡æ¯
                                product_info = await self.extract_product_info_debug(element, i+1)
                                
                                # éªŒè¯ä¿¡æ¯å®Œæ•´æ€§
                                if self.validate_product_info(product_info):
                                    products.append(product_info)
                                    print(f"   âœ… å•†å“ {i+1}: {product_info.get('title', 'N/A')[:40]}...")
                                else:
                                    print(f"   âš ï¸ å•†å“ {i+1}: ä¿¡æ¯ä¸å®Œæ•´")
                                    # æ‰“å°è°ƒè¯•ä¿¡æ¯
                                    self.print_debug_info(product_info, i+1)
                                
                                await asyncio.sleep(self.request_delay)
                                
                            except Exception as e:
                                print(f"   âŒ å¤„ç†å…ƒç´  {i+1} å¤±è´¥: {e}")
                                continue
                        
                        # å¦‚æœæ‰¾åˆ°äº†å•†å“ï¼Œå°±ä¸å†å°è¯•å…¶ä»–é€‰æ‹©å™¨
                        if products:
                            break
                            
                except Exception as e:
                    print(f"âš ï¸ é€‰æ‹©å™¨ '{selector}' å¤±è´¥: {e}")
                    continue
            
            print(f"âœ… å•†å“æå–å®Œæˆï¼Œå…±è·å– {len(products)} ä¸ªæœ‰æ•ˆå•†å“")
            return products
            
        except Exception as e:
            print(f"âŒ å•†å“æå–å¤±è´¥: {e}")
            return products
    
    async def extract_product_info_debug(self, element, index: int) -> Dict[str, Any]:
        """æå–å•ä¸ªå•†å“ä¿¡æ¯ï¼ˆå¸¦è°ƒè¯•ï¼‰"""
        product_info = {
            'index': index,
            'title': '',
            'price': '',
            'image_url': '',
            'product_url': '',
            'shop_name': '',
            'sales_count': '',
            'raw_html': '',
            'debug_info': {},
            'extraction_time': datetime.now().isoformat()
        }
        
        try:
            # è·å–å…ƒç´ çš„åŸºæœ¬ä¿¡æ¯
            element_info = await element.evaluate("""
                (el) => {
                    return {
                        tagName: el.tagName,
                        className: el.className,
                        id: el.id,
                        innerHTML: el.innerHTML,
                        textContent: el.textContent,
                        outerHTML: el.outerHTML.substring(0, 1000)
                    };
                }
            """)
            
            product_info['debug_info']['element'] = {
                'tag': element_info['tagName'],
                'class': element_info['className'],
                'id': element_info['id']
            }
            
            # æå–æ ‡é¢˜
            for selector in self.selectors['product_title']:
                try:
                    title_element = await element.query_selector(selector)
                    if title_element:
                        title = await title_element.text_content()
                        if title and title.strip():
                            product_info['title'] = title.strip()
                            product_info['debug_info']['title_selector'] = selector
                            break
                except:
                    continue
            
            # æå–ä»·æ ¼
            for selector in self.selectors['product_price']:
                try:
                    price_element = await element.query_selector(selector)
                    if price_element:
                        price_text = await price_element.text_content()
                        if price_text:
                            # æå–æ•°å­—ä»·æ ¼
                            price_match = re.search(r'[\d,]+\.?\d*', price_text.replace('ï¿¥', '').replace('Â¥', ''))
                            if price_match:
                                product_info['price'] = price_match.group(0)
                                product_info['debug_info']['price_selector'] = selector
                                break
                except:
                    continue
            
            # æå–å›¾ç‰‡
            for selector in self.selectors['product_image']:
                try:
                    img_element = await element.query_selector(selector)
                    if img_element:
                        img_src = await img_element.get_attribute('src')
                        if not img_src:
                            img_src = await img_element.get_attribute('data-src')
                        if img_src and ('http' in img_src or img_src.startswith('//')):
                            if img_src.startswith('//'):
                                img_src = 'https:' + img_src
                            product_info['image_url'] = img_src
                            product_info['debug_info']['image_selector'] = selector
                            break
                except:
                    continue
            
            # æå–é“¾æ¥
            for selector in self.selectors['product_link']:
                try:
                    link_element = await element.query_selector(selector)
                    if link_element:
                        href = await link_element.get_attribute('href')
                        if href:
                            if href.startswith('//'):
                                href = 'https:' + href
                            elif href.startswith('/'):
                                href = 'https://www.taobao.com' + href
                            product_info['product_url'] = href
                            product_info['debug_info']['link_selector'] = selector
                            break
                except:
                    continue
            
            # ä¿å­˜åŸå§‹HTMLç”¨äºè°ƒè¯•
            product_info['raw_html'] = element_info['outerHTML'][:500] + '...'
            
        except Exception as e:
            product_info['debug_info']['error'] = str(e)
        
        return product_info
    
    def validate_product_info(self, product_info: Dict[str, Any]) -> bool:
        """éªŒè¯å•†å“ä¿¡æ¯å®Œæ•´æ€§"""
        # è‡³å°‘éœ€è¦æ ‡é¢˜æˆ–ä»·æ ¼æˆ–å›¾ç‰‡ä¸­çš„ä¸€ä¸ª
        return bool(product_info.get('title') or product_info.get('price') or product_info.get('image_url'))
    
    def print_debug_info(self, product_info: Dict[str, Any], index: int):
        """æ‰“å°è°ƒè¯•ä¿¡æ¯"""
        print(f"      ğŸ› è°ƒè¯•ä¿¡æ¯ (å•†å“ {index}):")
        debug = product_info.get('debug_info', {})
        
        if 'element' in debug:
            elem = debug['element']
            print(f"         å…ƒç´ : <{elem.get('tag', 'unknown')} class='{elem.get('class', '')[:50]}'>")
        
        print(f"         æ ‡é¢˜: '{product_info.get('title', 'N/A')[:50]}'")
        print(f"         ä»·æ ¼: '{product_info.get('price', 'N/A')}'")
        print(f"         å›¾ç‰‡: '{product_info.get('image_url', 'N/A')[:50]}'")
        print(f"         é“¾æ¥: '{product_info.get('product_url', 'N/A')[:50]}'")
        
        if 'error' in debug:
            print(f"         é”™è¯¯: {debug['error']}")
    
    async def save_debug_report(self, products: List[Dict[str, Any]]):
        """ä¿å­˜è°ƒè¯•æŠ¥å‘Š"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"taobao_debug_report_{timestamp}.json"
            
            report = {
                'timestamp': datetime.now().isoformat(),
                'crawler_version': 'enhanced_v1.0',
                'total_products_found': len(products),
                'products': products,
                'selectors_used': self.selectors,
                'config': {
                    'headless': self.headless,
                    'request_delay': self.request_delay
                }
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“‹ è°ƒè¯•æŠ¥å‘Šå·²ä¿å­˜: {filename}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜è°ƒè¯•æŠ¥å‘Šå¤±è´¥: {e}")
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.browser_service:
                print("ğŸ§¹ æ­£åœ¨æ¸…ç†æµè§ˆå™¨èµ„æº...")
                await self.browser_service.shutdown()
                print("âœ… èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†èµ„æºæ—¶å‘ç”Ÿé”™è¯¯: {e}")

async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ” å¢å¼ºç‰ˆæ·˜å®å•†å“çˆ¬è™« - Chrome DevTools åˆ†ææ¨¡å¼")
    print("=" * 80)
    print()
    print("ğŸ¯ åŠŸèƒ½ç‰¹æ€§:")
    print("1. è¯¦ç»†çš„é¡µé¢ç»“æ„åˆ†æ")
    print("2. åçˆ¬è™«æœºåˆ¶æ£€æµ‹")
    print("3. å¤šé‡é€‰æ‹©å™¨ç­–ç•¥")
    print("4. å®Œæ•´çš„è°ƒè¯•ä¿¡æ¯")
    print("5. Chrome DevTools é£æ ¼åˆ†æ")
    print("6. ç½‘ç»œè¯·æ±‚ç›‘æ§")
    print()
    
    # é…ç½®å‚æ•°
    headless = False  # ä½¿ç”¨æœ‰å¤´æ¨¡å¼ä¾¿äºè§‚å¯Ÿ
    request_delay = 2.0  # å¢åŠ è¯·æ±‚é—´éš”
    max_products = 5  # é™åˆ¶å•†å“æ•°é‡ä¾¿äºè°ƒè¯•
    
    print(f"ğŸ–¥ï¸  æµè§ˆå™¨æ¨¡å¼: {'æ— å¤´æ¨¡å¼' if headless else 'æœ‰å¤´æ¨¡å¼'}")
    print(f"â±ï¸  è¯·æ±‚é—´éš”: {request_delay} ç§’")
    print(f"ğŸ“¦ æœ€å¤§å•†å“æ•°: {max_products}")
    print()
    
    # åˆ›å»ºå¢å¼ºç‰ˆçˆ¬è™«å®ä¾‹
    crawler = EnhancedTaobaoCrawler(headless=headless, request_delay=request_delay)
    
    try:
        # åˆå§‹åŒ–æµè§ˆå™¨
        success = await crawler.initialize()
        if not success:
            print("âŒ æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
            return
        
        # å¯¼èˆªåˆ°æ·˜å®é¦–é¡µ
        success = await crawler.navigate_to_taobao()
        if not success:
            print("âŒ å¯¼èˆªåˆ°æ·˜å®å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
            return
        
        # è°ƒè¯•é¡µé¢ç»“æ„
        await crawler.debug_page_structure()
        
        # æå–å•†å“ä¿¡æ¯
        products = await crawler.extract_products_with_debug(max_products=max_products)
        
        # ä¿å­˜è°ƒè¯•æŠ¥å‘Š
        await crawler.save_debug_report(products)
        
        if products:
            print(f"\nğŸ‰ åˆ†æå®Œæˆï¼å…±è·å– {len(products)} ä¸ªå•†å“æ•°æ®")
            print("ğŸ“‹ è¯¦ç»†è°ƒè¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°JSONæ–‡ä»¶")
        else:
            print("\nâŒ æœªè·å–åˆ°ä»»ä½•å•†å“æ•°æ®")
            print("ğŸ’¡ è¯·æŸ¥çœ‹è°ƒè¯•æŠ¥å‘Šäº†è§£è¯¦ç»†åŸå› ")
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­åˆ†æ")
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        # æ¸…ç†èµ„æº
        await crawler.cleanup()

if __name__ == "__main__":
    # è¿è¡Œå¢å¼ºç‰ˆçˆ¬è™«
    asyncio.run(main())