"""
Chrome DevTools é›†æˆåˆ†æå·¥å…·
ç”¨äºæ·˜å®å•†å“æŠ“å–çš„é¡µé¢åˆ†æå’Œç½‘ç»œç›‘æ§

è™½ç„¶ Chrome DevTools MCP å·¥å…·ç›®å‰è¿æ¥æœ‰é—®é¢˜ï¼Œ
ä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»£ç åˆ†æå’Œæ¨¡æ‹Ÿæ¥æä¾›è§£å†³æ–¹æ¡ˆ
"""

import asyncio
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import logging

@dataclass
class NetworkRequest:
    """ç½‘ç»œè¯·æ±‚æ•°æ®ç±»"""
    url: str
    method: str
    status: int
    response_type: str
    size: int
    timing: Dict[str, float]
    headers: Dict[str, str]

@dataclass
class PageElement:
    """é¡µé¢å…ƒç´ æ•°æ®ç±»"""
    tag_name: str
    selector: str
    text_content: str
    attributes: Dict[str, str]
    position: Dict[str, int]

@dataclass
class PageAnalysis:
    """é¡µé¢åˆ†æç»“æœ"""
    url: str
    title: str
    load_time: float
    elements_count: int
    network_requests: List[NetworkRequest]
    product_elements: List[PageElement]
    anti_crawling_indicators: List[str]
    performance_metrics: Dict[str, Any]

class ChromeDevToolsAnalyzer:
    """Chrome DevTools åˆ†æå™¨"""
    
    def __init__(self, browser_service):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            browser_service: BrowserService å®ä¾‹
        """
        self.browser_service = browser_service
        self.logger = logging.getLogger(__name__)
        
        # æ·˜å®ç‰¹å®šçš„åˆ†æè§„åˆ™
        self.taobao_selectors = {
            'product_containers': [
                '[data-spm*="product"]',
                '[data-category="auctions"]',
                '.recommend-item',
                '.item',
                '.product-item'
            ],
            'anti_crawling_elements': [
                '.captcha',
                '#nc_1_n1z',
                '.verify-code',
                '.slider-verify'
            ]
        }
    
    async def analyze_page(self, url: str) -> PageAnalysis:
        """
        åˆ†æé¡µé¢ç»“æ„å’Œæ€§èƒ½
        
        Args:
            url: è¦åˆ†æçš„é¡µé¢URL
            
        Returns:
            PageAnalysis: åˆ†æç»“æœ
        """
        try:
            self.logger.info(f"ğŸ” å¼€å§‹åˆ†æé¡µé¢: {url}")
            
            # å¯¼èˆªåˆ°é¡µé¢
            await self.browser_service.navigate_to_url(url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            await asyncio.sleep(3)
            
            # æ‰§è¡Œç»¼åˆåˆ†æè„šæœ¬
            analysis_script = """
            () => {
                const analysis = {
                    url: window.location.href,
                    title: document.title,
                    load_time: performance.timing.loadEventEnd - performance.timing.navigationStart,
                    elements_count: document.querySelectorAll('*').length,
                    network_requests: [],
                    product_elements: [],
                    anti_crawling_indicators: [],
                    performance_metrics: {}
                };
                
                // æ€§èƒ½æŒ‡æ ‡
                if (performance.getEntriesByType) {
                    const navigation = performance.getEntriesByType('navigation')[0];
                    if (navigation) {
                        analysis.performance_metrics = {
                            dns_lookup: navigation.domainLookupEnd - navigation.domainLookupStart,
                            tcp_connect: navigation.connectEnd - navigation.connectStart,
                            request_response: navigation.responseEnd - navigation.requestStart,
                            dom_loading: navigation.domContentLoadedEventEnd - navigation.domContentLoadedEventStart,
                            page_load: navigation.loadEventEnd - navigation.loadEventStart
                        };
                    }
                }
                
                // åˆ†æå•†å“å…ƒç´ 
                const productSelectors = [
                    '[data-spm*="product"]',
                    '[data-category="auctions"]',
                    '.recommend-item',
                    '.item',
                    '.product-item'
                ];
                
                productSelectors.forEach(selector => {
                    const elements = document.querySelectorAll(selector);
                    elements.forEach((el, index) => {
                        if (index < 10) { // é™åˆ¶æ•°é‡é¿å…è¿‡å¤šæ•°æ®
                            const rect = el.getBoundingClientRect();
                            analysis.product_elements.push({
                                tag_name: el.tagName.toLowerCase(),
                                selector: selector,
                                text_content: el.textContent.substring(0, 100),
                                attributes: {
                                    class: el.className,
                                    id: el.id,
                                    'data-spm': el.getAttribute('data-spm') || ''
                                },
                                position: {
                                    x: Math.round(rect.x),
                                    y: Math.round(rect.y),
                                    width: Math.round(rect.width),
                                    height: Math.round(rect.height)
                                }
                            });
                        }
                    });
                });
                
                // æ£€æµ‹åçˆ¬è™«å…ƒç´ 
                const antiCrawlingSelectors = [
                    '.captcha',
                    '#nc_1_n1z',
                    '.verify-code',
                    '.slider-verify',
                    '[class*="verify"]',
                    '[id*="captcha"]'
                ];
                
                antiCrawlingSelectors.forEach(selector => {
                    const elements = document.querySelectorAll(selector);
                    if (elements.length > 0) {
                        analysis.anti_crawling_indicators.push({
                            selector: selector,
                            count: elements.length,
                            visible: Array.from(elements).some(el => 
                                el.offsetWidth > 0 && el.offsetHeight > 0
                            )
                        });
                    }
                });
                
                // æ£€æµ‹é¡µé¢å†…å®¹ä¸­çš„åçˆ¬è™«å…³é”®è¯
                const pageText = document.body.textContent.toLowerCase();
                const antiCrawlingKeywords = [
                    'éªŒè¯ç ', 'captcha', 'è¯·è¾“å…¥éªŒè¯ç ', 'è®¿é—®è¿‡äºé¢‘ç¹',
                    'è¯·ç¨åå†è¯•', 'blocked', '403', '429'
                ];
                
                antiCrawlingKeywords.forEach(keyword => {
                    if (pageText.includes(keyword.toLowerCase())) {
                        analysis.anti_crawling_indicators.push({
                            type: 'text',
                            keyword: keyword,
                            found: true
                        });
                    }
                });
                
                return analysis;
            }
            """
            
            # æ‰§è¡Œåˆ†æè„šæœ¬
            if hasattr(self.browser_service.browser_driver, 'page') and self.browser_service.browser_driver.page:
                raw_analysis = await self.browser_service.browser_driver.page.evaluate(analysis_script)
                
                # è½¬æ¢ä¸º PageAnalysis å¯¹è±¡
                analysis = PageAnalysis(
                    url=raw_analysis.get('url', url),
                    title=raw_analysis.get('title', ''),
                    load_time=raw_analysis.get('load_time', 0) / 1000,  # è½¬æ¢ä¸ºç§’
                    elements_count=raw_analysis.get('elements_count', 0),
                    network_requests=[],  # éœ€è¦é¢å¤–çš„ç½‘ç»œç›‘æ§
                    product_elements=[
                        PageElement(
                            tag_name=elem.get('tag_name', ''),
                            selector=elem.get('selector', ''),
                            text_content=elem.get('text_content', ''),
                            attributes=elem.get('attributes', {}),
                            position=elem.get('position', {})
                        ) for elem in raw_analysis.get('product_elements', [])
                    ],
                    anti_crawling_indicators=raw_analysis.get('anti_crawling_indicators', []),
                    performance_metrics=raw_analysis.get('performance_metrics', {})
                )
                
                self.logger.info(f"âœ… é¡µé¢åˆ†æå®Œæˆ: å‘ç° {len(analysis.product_elements)} ä¸ªå•†å“å…ƒç´ ")
                
                return analysis
            
            else:
                raise Exception("æµè§ˆå™¨é¡µé¢æœªåˆå§‹åŒ–")
                
        except Exception as e:
            self.logger.error(f"âŒ é¡µé¢åˆ†æå¤±è´¥: {e}")
            return PageAnalysis(
                url=url,
                title="",
                load_time=0,
                elements_count=0,
                network_requests=[],
                product_elements=[],
                anti_crawling_indicators=[],
                performance_metrics={}
            )
    
    async def monitor_network_requests(self, duration: int = 30) -> List[NetworkRequest]:
        """
        ç›‘æ§ç½‘ç»œè¯·æ±‚ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰
        
        Args:
            duration: ç›‘æ§æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            List[NetworkRequest]: ç½‘ç»œè¯·æ±‚åˆ—è¡¨
        """
        try:
            self.logger.info(f"ğŸŒ å¼€å§‹ç›‘æ§ç½‘ç»œè¯·æ±‚ ({duration} ç§’)")
            
            # åœ¨å®é™…çš„ Chrome DevTools é›†æˆä¸­ï¼Œè¿™é‡Œä¼šç›‘å¬ç½‘ç»œäº‹ä»¶
            # ç›®å‰æä¾›æ¨¡æ‹Ÿå®ç°
            
            monitoring_script = """
            () => {
                return new Promise((resolve) => {
                    const requests = [];
                    const originalFetch = window.fetch;
                    const originalXHROpen = XMLHttpRequest.prototype.open;
                    
                    // æ‹¦æˆª fetch è¯·æ±‚
                    window.fetch = function(...args) {
                        const startTime = performance.now();
                        return originalFetch.apply(this, args).then(response => {
                            const endTime = performance.now();
                            requests.push({
                                url: args[0],
                                method: args[1]?.method || 'GET',
                                status: response.status,
                                response_type: 'fetch',
                                size: 0, // æ— æ³•ç›´æ¥è·å–
                                timing: {
                                    duration: endTime - startTime
                                },
                                headers: {}
                            });
                            return response;
                        });
                    };
                    
                    // æ‹¦æˆª XMLHttpRequest
                    XMLHttpRequest.prototype.open = function(method, url) {
                        this._startTime = performance.now();
                        this._method = method;
                        this._url = url;
                        
                        this.addEventListener('loadend', () => {
                            const endTime = performance.now();
                            requests.push({
                                url: this._url,
                                method: this._method,
                                status: this.status,
                                response_type: 'xhr',
                                size: this.responseText ? this.responseText.length : 0,
                                timing: {
                                    duration: endTime - this._startTime
                                },
                                headers: {}
                            });
                        });
                        
                        return originalXHROpen.apply(this, arguments);
                    };
                    
                    // è®¾ç½®å®šæ—¶å™¨è¿”å›ç»“æœ
                    setTimeout(() => {
                        resolve(requests);
                    }, """ + str(duration * 1000) + """);
                });
            }
            """
            
            if hasattr(self.browser_service.browser_driver, 'page') and self.browser_service.browser_driver.page:
                raw_requests = await self.browser_service.browser_driver.page.evaluate(monitoring_script)
                
                # è½¬æ¢ä¸º NetworkRequest å¯¹è±¡
                requests = [
                    NetworkRequest(
                        url=req.get('url', ''),
                        method=req.get('method', ''),
                        status=req.get('status', 0),
                        response_type=req.get('response_type', ''),
                        size=req.get('size', 0),
                        timing=req.get('timing', {}),
                        headers=req.get('headers', {})
                    ) for req in raw_requests
                ]
                
                self.logger.info(f"âœ… ç½‘ç»œç›‘æ§å®Œæˆ: æ•è· {len(requests)} ä¸ªè¯·æ±‚")
                return requests
            
            return []
            
        except Exception as e:
            self.logger.error(f"âŒ ç½‘ç»œç›‘æ§å¤±è´¥: {e}")
            return []
    
    async def detect_anti_crawling_mechanisms(self) -> Dict[str, Any]:
        """
        æ£€æµ‹åçˆ¬è™«æœºåˆ¶
        
        Returns:
            Dict[str, Any]: æ£€æµ‹ç»“æœ
        """
        try:
            self.logger.info("ğŸ›¡ï¸ æ£€æµ‹åçˆ¬è™«æœºåˆ¶")
            
            detection_script = """
            () => {
                const detection = {
                    captcha_elements: [],
                    suspicious_scripts: [],
                    rate_limiting_indicators: [],
                    fingerprinting_attempts: [],
                    bot_detection_signals: []
                };
                
                // æ£€æµ‹éªŒè¯ç å…ƒç´ 
                const captchaSelectors = [
                    '.captcha', '#nc_1_n1z', '.verify-code', '.slider-verify',
                    '[class*="verify"]', '[id*="captcha"]', '[class*="captcha"]'
                ];
                
                captchaSelectors.forEach(selector => {
                    const elements = document.querySelectorAll(selector);
                    if (elements.length > 0) {
                        detection.captcha_elements.push({
                            selector: selector,
                            count: elements.length,
                            visible: Array.from(elements).some(el => 
                                el.offsetWidth > 0 && el.offsetHeight > 0
                            )
                        });
                    }
                });
                
                // æ£€æµ‹å¯ç–‘è„šæœ¬
                const scripts = document.querySelectorAll('script');
                scripts.forEach(script => {
                    const src = script.src;
                    const content = script.textContent;
                    
                    // æ£€æµ‹åçˆ¬è™«ç›¸å…³çš„è„šæœ¬ç‰¹å¾
                    const suspiciousPatterns = [
                        'bot', 'crawler', 'spider', 'captcha', 'verify',
                        'fingerprint', 'detection', 'challenge'
                    ];
                    
                    suspiciousPatterns.forEach(pattern => {
                        if ((src && src.toLowerCase().includes(pattern)) ||
                            (content && content.toLowerCase().includes(pattern))) {
                            detection.suspicious_scripts.push({
                                type: src ? 'external' : 'inline',
                                source: src || 'inline',
                                pattern: pattern
                            });
                        }
                    });
                });
                
                // æ£€æµ‹é™æµæŒ‡ç¤ºå™¨
                const pageText = document.body.textContent.toLowerCase();
                const rateLimitingKeywords = [
                    'è®¿é—®è¿‡äºé¢‘ç¹', 'è¯·ç¨åå†è¯•', 'too many requests',
                    'rate limit', '429', 'blocked'
                ];
                
                rateLimitingKeywords.forEach(keyword => {
                    if (pageText.includes(keyword)) {
                        detection.rate_limiting_indicators.push({
                            keyword: keyword,
                            found: true
                        });
                    }
                });
                
                // æ£€æµ‹æŒ‡çº¹è¯†åˆ«å°è¯•
                if (window.navigator) {
                    const fingerprintingChecks = [
                        'webdriver' in window.navigator,
                        'plugins' in window.navigator && window.navigator.plugins.length === 0,
                        'languages' in window.navigator && window.navigator.languages.length === 0
                    ];
                    
                    fingerprintingChecks.forEach((check, index) => {
                        if (check) {
                            detection.fingerprinting_attempts.push({
                                type: ['webdriver', 'plugins', 'languages'][index],
                                detected: true
                            });
                        }
                    });
                }
                
                return detection;
            }
            """
            
            if hasattr(self.browser_service.browser_driver, 'page') and self.browser_service.browser_driver.page:
                detection_result = await self.browser_service.browser_driver.page.evaluate(detection_script)
                
                self.logger.info("âœ… åçˆ¬è™«æœºåˆ¶æ£€æµ‹å®Œæˆ")
                return detection_result
            
            return {}
            
        except Exception as e:
            self.logger.error(f"âŒ åçˆ¬è™«æ£€æµ‹å¤±è´¥: {e}")
            return {}
    
    async def generate_analysis_report(self, analysis: PageAnalysis, 
                                     network_requests: List[NetworkRequest],
                                     anti_crawling_detection: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
        
        Args:
            analysis: é¡µé¢åˆ†æç»“æœ
            network_requests: ç½‘ç»œè¯·æ±‚åˆ—è¡¨
            anti_crawling_detection: åçˆ¬è™«æ£€æµ‹ç»“æœ
            
        Returns:
            Dict[str, Any]: ç»¼åˆæŠ¥å‘Š
        """
        report = {
            'analysis_timestamp': asyncio.get_event_loop().time(),
            'page_info': {
                'url': analysis.url,
                'title': analysis.title,
                'load_time': analysis.load_time,
                'elements_count': analysis.elements_count
            },
            'performance_metrics': analysis.performance_metrics,
            'product_analysis': {
                'total_product_elements': len(analysis.product_elements),
                'selectors_effectiveness': self._analyze_selector_effectiveness(analysis.product_elements),
                'element_distribution': self._analyze_element_distribution(analysis.product_elements)
            },
            'network_analysis': {
                'total_requests': len(network_requests),
                'request_types': self._analyze_request_types(network_requests),
                'performance_summary': self._analyze_network_performance(network_requests)
            },
            'anti_crawling_assessment': {
                'risk_level': self._assess_anti_crawling_risk(anti_crawling_detection),
                'detected_mechanisms': anti_crawling_detection,
                'recommendations': self._generate_recommendations(anti_crawling_detection)
            }
        }
        
        return report
    
    def _analyze_selector_effectiveness(self, elements: List[PageElement]) -> Dict[str, int]:
        """åˆ†æé€‰æ‹©å™¨æœ‰æ•ˆæ€§"""
        selector_counts = {}
        for element in elements:
            selector = element.selector
            selector_counts[selector] = selector_counts.get(selector, 0) + 1
        return selector_counts
    
    def _analyze_element_distribution(self, elements: List[PageElement]) -> Dict[str, Any]:
        """åˆ†æå…ƒç´ åˆ†å¸ƒ"""
        if not elements:
            return {}
        
        positions = [elem.position for elem in elements if elem.position]
        if not positions:
            return {}
        
        return {
            'avg_x': sum(pos.get('x', 0) for pos in positions) / len(positions),
            'avg_y': sum(pos.get('y', 0) for pos in positions) / len(positions),
            'avg_width': sum(pos.get('width', 0) for pos in positions) / len(positions),
            'avg_height': sum(pos.get('height', 0) for pos in positions) / len(positions)
        }
    
    def _analyze_request_types(self, requests: List[NetworkRequest]) -> Dict[str, int]:
        """åˆ†æè¯·æ±‚ç±»å‹"""
        types = {}
        for request in requests:
            req_type = request.response_type
            types[req_type] = types.get(req_type, 0) + 1
        return types
    
    def _analyze_network_performance(self, requests: List[NetworkRequest]) -> Dict[str, float]:
        """åˆ†æç½‘ç»œæ€§èƒ½"""
        if not requests:
            return {}
        
        durations = [req.timing.get('duration', 0) for req in requests if req.timing]
        if not durations:
            return {}
        
        return {
            'avg_duration': sum(durations) / len(durations),
            'max_duration': max(durations),
            'min_duration': min(durations),
            'total_requests': len(requests)
        }
    
    def _assess_anti_crawling_risk(self, detection: Dict[str, Any]) -> str:
        """è¯„ä¼°åçˆ¬è™«é£é™©ç­‰çº§"""
        risk_score = 0
        
        # éªŒè¯ç å…ƒç´ 
        if detection.get('captcha_elements'):
            risk_score += 3
        
        # å¯ç–‘è„šæœ¬
        if detection.get('suspicious_scripts'):
            risk_score += 2
        
        # é™æµæŒ‡ç¤ºå™¨
        if detection.get('rate_limiting_indicators'):
            risk_score += 4
        
        # æŒ‡çº¹è¯†åˆ«
        if detection.get('fingerprinting_attempts'):
            risk_score += 2
        
        if risk_score >= 6:
            return "HIGH"
        elif risk_score >= 3:
            return "MEDIUM"
        else:
            return "LOW"
    
    def _generate_recommendations(self, detection: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        if detection.get('captcha_elements'):
            recommendations.append("æ£€æµ‹åˆ°éªŒè¯ç å…ƒç´ ï¼Œå»ºè®®é™ä½è¯·æ±‚é¢‘ç‡å¹¶ä½¿ç”¨çœŸå®æµè§ˆå™¨ç¯å¢ƒ")
        
        if detection.get('rate_limiting_indicators'):
            recommendations.append("æ£€æµ‹åˆ°é™æµæœºåˆ¶ï¼Œå»ºè®®å¢åŠ è¯·æ±‚é—´éš”æ—¶é—´")
        
        if detection.get('fingerprinting_attempts'):
            recommendations.append("æ£€æµ‹åˆ°æŒ‡çº¹è¯†åˆ«ï¼Œå»ºè®®ä½¿ç”¨çœŸå®ç”¨æˆ·ä»£ç†å’Œæµè§ˆå™¨é…ç½®")
        
        if not recommendations:
            recommendations.append("æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„åçˆ¬è™«æœºåˆ¶ï¼Œå¯ä»¥æ­£å¸¸è¿›è¡Œæ•°æ®æŠ“å–")
        
        return recommendations

# ä½¿ç”¨ç¤ºä¾‹
async def analyze_taobao_page():
    """åˆ†ææ·˜å®é¡µé¢çš„ç¤ºä¾‹"""
    from ..rpa.browser.browser_service import BrowserService
    from ..rpa.browser.core.models.browser_config import BrowserConfig, BrowserType
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    
    # åˆ›å»ºæµè§ˆå™¨æœåŠ¡
    config = BrowserConfig(
        browser_type=BrowserType.CHROME,
        headless=True,
        viewport={'width': 1920, 'height': 1080}
    )
    
    browser_service = BrowserService(config=config, debug_mode=True)
    
    try:
        # åˆå§‹åŒ–æµè§ˆå™¨
        await browser_service.initialize()
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = ChromeDevToolsAnalyzer(browser_service)
        
        # åˆ†ææ·˜å®æœç´¢é¡µé¢
        url = "https://s.taobao.com/search?q=iPhone"
        
        print("ğŸ” å¼€å§‹åˆ†ææ·˜å®é¡µé¢...")
        
        # é¡µé¢åˆ†æ
        analysis = await analyzer.analyze_page(url)
        
        # ç½‘ç»œç›‘æ§
        network_requests = await analyzer.monitor_network_requests(10)
        
        # åçˆ¬è™«æ£€æµ‹
        anti_crawling = await analyzer.detect_anti_crawling_mechanisms()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = await analyzer.generate_analysis_report(
            analysis, network_requests, anti_crawling
        )
        
        # è¾“å‡ºç»“æœ
        print(f"\nğŸ“Š åˆ†ææŠ¥å‘Š:")
        print(f"   é¡µé¢æ ‡é¢˜: {analysis.title}")
        print(f"   åŠ è½½æ—¶é—´: {analysis.load_time:.2f} ç§’")
        print(f"   å•†å“å…ƒç´ : {len(analysis.product_elements)} ä¸ª")
        print(f"   ç½‘ç»œè¯·æ±‚: {len(network_requests)} ä¸ª")
        print(f"   åçˆ¬è™«é£é™©: {report['anti_crawling_assessment']['risk_level']}")
        
        # ä¿å­˜æŠ¥å‘Š
        with open('taobao_analysis_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: taobao_analysis_report.json")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
    
    finally:
        await browser_service.close()

if __name__ == "__main__":
    asyncio.run(analyze_taobao_page())