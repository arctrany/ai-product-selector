"""
è·Ÿå–æ£€æµ‹æœåŠ¡

ç‹¬ç«‹çš„è·Ÿå–æ£€æµ‹å’Œå¤„ç†èƒ½åŠ›ï¼Œä»OzonScraperä¸­åˆ†ç¦»å‡ºæ¥ã€‚
æä¾›ç»Ÿä¸€çš„è·Ÿå–æ£€æµ‹æ¥å£ï¼Œä¾›æ‰€æœ‰éœ€è¦è·Ÿå–åŠŸèƒ½çš„Scraperä½¿ç”¨ã€‚
"""

import logging
import time
from typing import Optional, List, Dict, Any
from bs4 import BeautifulSoup

from ..models.scraping_result import CompetitorInfo, CompetitorDetectionResult
from ..utils.wait_utils import WaitUtils
from ..utils.scraping_utils import ScrapingUtils
from ..config.ozon_selectors_config import OzonSelectorsConfig, get_ozon_selectors_config


class CompetitorDetectionService:
    """
    è·Ÿå–æ£€æµ‹æœåŠ¡
    
    æä¾›ç»Ÿä¸€çš„è·Ÿå–æ£€æµ‹å’Œæ•°æ®æå–åŠŸèƒ½
    """
    
    def __init__(self, browser_service=None, 
                 selectors_config: Optional[OzonSelectorsConfig] = None,
                 logger: Optional[logging.Logger] = None):
        """
        åˆå§‹åŒ–è·Ÿå–æ£€æµ‹æœåŠ¡
        
        Args:
            browser_service: æµè§ˆå™¨æœåŠ¡å®ä¾‹
            selectors_config: é€‰æ‹©å™¨é…ç½®
            logger: æ—¥å¿—è®°å½•å™¨
        """
        self.browser_service = browser_service
        self.selectors_config = selectors_config or get_ozon_selectors_config()
        self.logger = logger or logging.getLogger(__name__)
        
        self.wait_utils = WaitUtils(browser_service, self.logger)
        self.scraping_utils = ScrapingUtils(self.logger)
    
    def detect_competitors(self, page_content: Optional[str] = None) -> CompetitorDetectionResult:
        """
        æ£€æµ‹é¡µé¢æ˜¯å¦æœ‰è·Ÿå–
        
        Args:
            page_content: é¡µé¢HTMLå†…å®¹ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä»browser_serviceè·å–ï¼‰
            
        Returns:
            CompetitorDetectionResult: è·Ÿå–æ£€æµ‹ç»“æœ
        """
        try:
            if not page_content and self.browser_service:
                page_content = self.browser_service.evaluate_sync("() => document.documentElement.outerHTML")
            
            if not page_content:
                return CompetitorDetectionResult.create_no_competitors("no_page_content")
            
            soup = BeautifulSoup(page_content, 'html.parser')
            
            competitor_element = soup.select_one(self.selectors_config.precise_competitor_selector)
            
            if not competitor_element:
                self.logger.info("âœ… æœªæ£€æµ‹åˆ°è·Ÿå–åŒºåŸŸ")
                return CompetitorDetectionResult.create_no_competitors("no_competitor_element")
            
            self.logger.info("ğŸ” æ£€æµ‹åˆ°è·Ÿå–åŒºåŸŸï¼Œå¼€å§‹æå–è·Ÿå–æ•°æ®")
            
            competitors = self._extract_competitors_from_element(competitor_element)
            
            if not competitors:
                return CompetitorDetectionResult.create_no_competitors("no_competitors_found")
            
            return CompetitorDetectionResult.create_with_competitors(
                competitors,
                detection_method="element_detection"
            )
            
        except Exception as e:
            self.logger.error(f"è·Ÿå–æ£€æµ‹å¤±è´¥: {e}")
            return CompetitorDetectionResult(
                has_competitors=False,
                competitor_count=0,
                competitors=[],
                error_message=str(e)
            )
    
    def _extract_competitors_from_element(self, element) -> List[CompetitorInfo]:
        """
        ä»è·Ÿå–åŒºåŸŸå…ƒç´ ä¸­æå–è·Ÿå–åº—é“ºä¿¡æ¯
        
        Args:
            element: BeautifulSoupå…ƒç´ 
            
        Returns:
            List[CompetitorInfo]: è·Ÿå–åº—é“ºä¿¡æ¯åˆ—è¡¨
        """
        competitors = []
        
        try:
            competitor_items = element.select('[class*="competitor"], [class*="seller"]')
            
            for item in competitor_items:
                try:
                    competitor = self._parse_competitor_item(item)
                    if competitor:
                        competitors.append(competitor)
                except Exception as e:
                    self.logger.debug(f"è§£æè·Ÿå–é¡¹å¤±è´¥: {e}")
                    continue
            
            self.logger.info(f"âœ… æå–åˆ° {len(competitors)} ä¸ªè·Ÿå–åº—é“º")
            
        except Exception as e:
            self.logger.error(f"æå–è·Ÿå–æ•°æ®å¤±è´¥: {e}")
        
        return competitors
    
    def _parse_competitor_item(self, item) -> Optional[CompetitorInfo]:
        """
        è§£æå•ä¸ªè·Ÿå–é¡¹
        
        Args:
            item: BeautifulSoupå…ƒç´ 
            
        Returns:
            CompetitorInfo: è·Ÿå–åº—é“ºä¿¡æ¯
        """
        try:
            store_name = self._extract_store_name(item)
            if not store_name:
                return None
            
            price = self._extract_competitor_price(item)
            store_url = self._extract_store_url(item)
            rating = self._extract_rating(item)
            sales_count = self._extract_sales_count(item)
            delivery_info = self._extract_delivery_info(item)
            
            return CompetitorInfo(
                store_name=store_name,
                store_url=store_url,
                price=float(price) if price else None,
                rating=rating,
                sales_count=sales_count,
                delivery_info=delivery_info
            )
            
        except Exception as e:
            self.logger.debug(f"è§£æè·Ÿå–é¡¹å¤±è´¥: {e}")
            return None
    
    def _extract_store_name(self, element) -> Optional[str]:
        """æå–åº—é“ºåç§°"""
        selectors = [
            '.store-name',
            '[class*="seller-name"]',
            '[class*="store"]',
            'span:first-child'
        ]
        
        for selector in selectors:
            elem = element.select_one(selector)
            if elem:
                text = self.scraping_utils.clean_text(elem.get_text())
                if text:
                    return text
        
        return None
    
    def _extract_competitor_price(self, element) -> Optional[float]:
        """æå–è·Ÿå–ä»·æ ¼"""
        price_selectors = [
            '.price',
            '[class*="price"]',
            'span:contains("â‚½")'
        ]
        
        for selector in price_selectors:
            try:
                elem = element.select_one(selector)
                if elem:
                    price = self.scraping_utils.extract_price(elem.get_text())
                    if price:
                        return float(price)
            except Exception:
                continue
        
        return None
    
    def _extract_store_url(self, element) -> Optional[str]:
        """æå–åº—é“ºURL"""
        link = element.select_one('a[href]')
        if link:
            url = link.get('href', '')
            return self.scraping_utils.normalize_url(url, 'https://www.ozon.ru')
        return None
    
    def _extract_rating(self, element) -> Optional[float]:
        """æå–è¯„åˆ†"""
        rating_elem = element.select_one('[class*="rating"]')
        if rating_elem:
            try:
                rating_text = self.scraping_utils.clean_text(rating_elem.get_text())
                rating = float(rating_text.replace(',', '.'))
                return rating
            except ValueError:
                pass
        return None
    
    def _extract_sales_count(self, element) -> Optional[int]:
        """æå–é”€é‡"""
        sales_elem = element.select_one('[class*="sales"], [class*="sold"]')
        if sales_elem:
            return self.scraping_utils.extract_number(sales_elem.get_text())
        return None
    
    def _extract_delivery_info(self, element) -> Optional[str]:
        """æå–é…é€ä¿¡æ¯"""
        delivery_elem = element.select_one('[class*="delivery"]')
        if delivery_elem:
            return self.scraping_utils.clean_text(delivery_elem.get_text())
        return None
    
    def open_competitor_popup(self) -> bool:
        """
        æ‰“å¼€è·Ÿå–æµ®å±‚
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ‰“å¼€
        """
        try:
            if not self.browser_service:
                self.logger.error("browser_serviceæœªåˆå§‹åŒ–")
                return False
            
            competitor_area_visible = self.wait_utils.wait_for_element_visible(
                self.selectors_config.precise_competitor_selector,
                timeout=5000
            )
            
            if not competitor_area_visible:
                self.logger.info("æœªæ‰¾åˆ°è·Ÿå–åŒºåŸŸ")
                return False
            
            success = self.browser_service.click_sync(
                self.selectors_config.precise_competitor_selector,
                timeout=5000
            )
            
            if success:
                self.wait_utils.smart_wait(1.0)
                self.logger.info("âœ… è·Ÿå–æµ®å±‚å·²æ‰“å¼€")
                return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"æ‰“å¼€è·Ÿå–æµ®å±‚å¤±è´¥: {e}")
            return False
    
    def filter_competitors_by_price(self, competitors: List[CompetitorInfo],
                                   max_price: float) -> List[CompetitorInfo]:
        """
        æŒ‰ä»·æ ¼è¿‡æ»¤è·Ÿå–åº—é“º
        
        Args:
            competitors: è·Ÿå–åº—é“ºåˆ—è¡¨
            max_price: æœ€é«˜ä»·æ ¼
            
        Returns:
            List[CompetitorInfo]: è¿‡æ»¤åçš„è·Ÿå–åº—é“ºåˆ—è¡¨
        """
        filtered = []
        
        for competitor in competitors:
            if competitor.price and competitor.price <= max_price:
                filtered.append(competitor)
        
        self.logger.info(f"ä»·æ ¼è¿‡æ»¤: {len(competitors)} -> {len(filtered)} (â‰¤{max_price})")
        
        return filtered
    
    def sort_competitors_by_price(self, competitors: List[CompetitorInfo],
                                 ascending: bool = True) -> List[CompetitorInfo]:
        """
        æŒ‰ä»·æ ¼æ’åºè·Ÿå–åº—é“º
        
        Args:
            competitors: è·Ÿå–åº—é“ºåˆ—è¡¨
            ascending: æ˜¯å¦å‡åº
            
        Returns:
            List[CompetitorInfo]: æ’åºåçš„è·Ÿå–åº—é“ºåˆ—è¡¨
        """
        return sorted(
            competitors,
            key=lambda x: x.price if x.price else float('inf'),
            reverse=not ascending
        )