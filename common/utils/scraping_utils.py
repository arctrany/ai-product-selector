"""
ç»Ÿä¸€æŠ“å–å·¥å…·ç±»

æä¾›æ ‡å‡†åŒ–çš„æ•°æ®æå–å’Œæ¸…ç†åŠŸèƒ½ï¼Œç”¨äºæ‰€æœ‰Scraperçš„æ•°æ®å¤„ç†ã€‚
"""

import re
import logging
from typing import Optional, Dict, Any, List
from decimal import Decimal, InvalidOperation


class ScrapingUtils:
    """
    ç»Ÿä¸€æŠ“å–å·¥å…·ç±»
    
    æä¾›æ ‡å‡†åŒ–çš„æ•°æ®æå–å’Œæ¸…ç†åŠŸèƒ½
    """
    
    def __init__(self, logger: Optional[logging.Logger] = None):
        """
        åˆå§‹åŒ–æŠ“å–å·¥å…·
        
        Args:
            logger: æ—¥å¿—è®°å½•å™¨
        """
        self.logger = logger or logging.getLogger(__name__)
    
    def clean_text(self, text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬å†…å®¹
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            str: æ¸…ç†åçš„æ–‡æœ¬
        """
        if not text:
            return ""
        
        # å»é™¤é¦–å°¾ç©ºç™½å­—ç¬¦
        text = text.strip()
        
        # å»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)
        
        return text
    
    def extract_price(self, text: str) -> Optional[float]:
        """
        æå–ä»·æ ¼ä¿¡æ¯
        
        Args:
            text: åŒ…å«ä»·æ ¼çš„æ–‡æœ¬
            
        Returns:
            Optional[float]: æå–çš„ä»·æ ¼ï¼Œå¤±è´¥è¿”å›None
        """
        if not text:
            return None
        
        try:
            # æ¸…ç†æ–‡æœ¬
            cleaned_text = self.clean_text(text)
            
            # åŒ¹é…ä»·æ ¼æ¨¡å¼ (æ”¯æŒå¤šç§è´§å¸ç¬¦å·)
            price_pattern = r'[\d\s,.]+(?:\s*(?:â‚½|â‚¬|\$|USD|EUR|RUB|Ñ€ÑƒĞ±))|(?:\d+(?:[.,]\d{2})?)'
            matches = re.findall(price_pattern, cleaned_text)
            
            if matches:
                # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„ä»·æ ¼
                price_str = matches[0]
                # ç§»é™¤è´§å¸ç¬¦å·å’Œç©ºæ ¼
                price_str = re.sub(r'[^\d.,]', '', price_str)
                # æ ‡å‡†åŒ–å°æ•°ç‚¹
                price_str = price_str.replace(',', '.')
                
                # è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                return float(price_str)
            
            return None
        except Exception as e:
            self.logger.warning(f"ä»·æ ¼æå–å¤±è´¥: {e}")
            return None
    
    def validate_price(self, price: float) -> bool:
        """
        éªŒè¯ä»·æ ¼æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            price: ä»·æ ¼å€¼
            
        Returns:
            bool: ä»·æ ¼æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # ä»·æ ¼åº”è¯¥å¤§äº0ä¸”å°äºä¸€ä¸ªåˆç†çš„ä¸Šé™
            return 0 < price < 10000000  # 1000ä¸‡ä»¥ä¸‹è®¤ä¸ºæ˜¯åˆç†ä»·æ ¼
        except Exception:
            return False
    
    def extract_number(self, text: str) -> Optional[int]:
        """
        æå–æ•°å­—ä¿¡æ¯
        
        Args:
            text: åŒ…å«æ•°å­—çš„æ–‡æœ¬
            
        Returns:
            Optional[int]: æå–çš„æ•°å­—ï¼Œå¤±è´¥è¿”å›None
        """
        if not text:
            return None
        
        try:
            # æ¸…ç†æ–‡æœ¬
            cleaned_text = self.clean_text(text)
            
            # åŒ¹é…æ•°å­—æ¨¡å¼
            number_pattern = r'\d+'
            matches = re.findall(number_pattern, cleaned_text)
            
            if matches:
                # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ•°å­—
                return int(matches[0])
            
            return None
        except Exception as e:
            self.logger.warning(f"æ•°å­—æå–å¤±è´¥: {e}")
            return None
    
    def extract_data_with_selector(self, browser_service, selector: str, 
                                 attribute: str = "text", timeout: int = 5000) -> Optional[str]:
        """
        ä½¿ç”¨é€‰æ‹©å™¨æå–æ•°æ®
        
        Args:
            browser_service: æµè§ˆå™¨æœåŠ¡
            selector: å…ƒç´ é€‰æ‹©å™¨
            attribute: è¦è·å–çš„å±æ€§ï¼ˆtext, innerHTML, valueç­‰ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
            
        Returns:
            Optional[str]: æå–çš„æ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            if not browser_service:
                self.logger.error("Browser service not initialized")
                return None
            
            if attribute == "text":
                result = browser_service.text_content_sync(selector, timeout)
            elif attribute == "value":
                result = browser_service.get_attribute_sync(selector, "value", timeout)
            else:
                result = browser_service.get_attribute_sync(selector, attribute, timeout)
            
            if result:
                return self.clean_text(result)
            
            return None
        except Exception as e:
            self.logger.warning(f"é€‰æ‹©å™¨æ•°æ®æå–å¤±è´¥: {e}")
            return None
    
    def extract_data_with_js(self, browser_service, script: str, 
                           description: str = "æ•°æ®", *args) -> Any:
        """
        ä½¿ç”¨JavaScriptæå–æ•°æ®
        
        Args:
            browser_service: æµè§ˆå™¨æœåŠ¡
            script: JavaScriptè„šæœ¬
            description: æ•°æ®æè¿°
            
        Returns:
            Any: æå–çš„æ•°æ®
        """
        try:
            if not browser_service:
                self.logger.error("Browser service not initialized")
                return None
            
            # ğŸ”§ æ”¯æŒå‚æ•°ä¼ é€’ï¼šå¦‚æœæœ‰å‚æ•°ï¼Œåˆ›å»ºå‡½æ•°è°ƒç”¨æ ¼å¼
            if args:
                # å°†å‚æ•°è½¬ä¸ºJSONå­—ç¬¦ä¸²æ•°ç»„
                args_json = [f"'{arg}'" if isinstance(arg, str) else str(arg) for arg in args]
                script_with_args = f"(function() {{ {script} }})({', '.join(args_json)})"
                result = browser_service.evaluate_sync(script_with_args)
            else:
                result = browser_service.evaluate_sync(script)
            self.logger.debug(f"âœ… JavaScriptæå–{description}æˆåŠŸ")
            return result
        except Exception as e:
            self.logger.warning(f"JavaScriptæå–{description}å¤±è´¥: {e}")
            return None
    
    def create_js_product_extractor(self, column_indexes: Dict[str, int]) -> str:
        """
        åˆ›å»ºJavaScriptäº§å“æ•°æ®æå–å™¨
        
        Args:
            column_indexes: åˆ—ç´¢å¼•æ˜ å°„
            
        Returns:
            str: JavaScriptè„šæœ¬
        """
        # æ„å»ºJavaScriptè„šæœ¬
        js_script = f"""
        (() => {{
            const columnIndexes = {column_indexes};
            const products = [];
            const rows = document.querySelectorAll('table tbody tr');
            
            for (let i = 0; i < rows.length; i++) {{
                const row = rows[i];
                const cells = row.querySelectorAll('td');
                if (cells.length === 0) continue;
                
                const product = {{
                    row_index: i + 1
                }};
                
                // æ ¹æ®åˆ—ç´¢å¼•æå–æ•°æ®
                for (const [key, index] of Object.entries(columnIndexes)) {{
                    if (index < cells.length) {{
                        const cell = cells[index];
                        product[key] = cell.textContent.trim();
                    }}
                }}
                
                products.push(product);
            }}
            
            return products;
        }})()
        """
        
        return js_script
    
    def normalize_url(self, url: str, base_url: str) -> str:
        """
        æ ‡å‡†åŒ–URL
        
        Args:
            url: åŸå§‹URL
            base_url: åŸºç¡€URL
            
        Returns:
            str: æ ‡å‡†åŒ–åçš„URL
        """
        if not url:
            return ""
        
        # å¦‚æœå·²ç»æ˜¯å®Œæ•´URLï¼Œç›´æ¥è¿”å›
        if url.startswith(('http://', 'https://')):
            return url
        
        # å¦‚æœæ˜¯ç›¸å¯¹URLï¼Œæ‹¼æ¥åŸºç¡€URL
        if url.startswith('/'):
            from urllib.parse import urljoin
            return urljoin(base_url, url)
        
        return url


# å…¨å±€å®ä¾‹ç®¡ç†
_scraping_utils_instance = None


def get_global_scraping_utils(logger=None) -> ScrapingUtils:
    """
    è·å–å…¨å±€ScrapingUtilså®ä¾‹
    
    Args:
        logger: æ—¥å¿—è®°å½•å™¨
        
    Returns:
        ScrapingUtils: å…¨å±€ScrapingUtilså®ä¾‹
    """
    global _scraping_utils_instance
    
    if _scraping_utils_instance is None:
        _scraping_utils_instance = ScrapingUtils(logger)
    
    return _scraping_utils_instance


def reset_global_scraping_utils():
    """é‡ç½®å…¨å±€ScrapingUtilså®ä¾‹"""
    global _scraping_utils_instance
    _scraping_utils_instance = None


def clean_price_string(price_str: str, selectors_config=None) -> Optional[float]:
    """
    æ¸…ç†ä»·æ ¼å­—ç¬¦ä¸²ï¼Œæå–æ•°å€¼

    Args:
        price_str: ä»·æ ¼å­—ç¬¦ä¸²
        selectors_config: é€‰æ‹©å™¨é…ç½®å¯¹è±¡ï¼ŒåŒ…å«è´§å¸ç¬¦å·ç­‰é…ç½®

    Returns:
        Optional[float]: æå–çš„ä»·æ ¼æ•°å€¼ï¼Œå¤±è´¥è¿”å›None
    """
    if not price_str or not isinstance(price_str, str):
        return None

    # ğŸ”§ ä¿®å¤ï¼šæ”¯æŒé…ç½®åŒ–çš„è´§å¸åŒ¹é…
    import re

    # è·å–é…ç½®ï¼Œå¦‚æœæ²¡æœ‰æä¾›åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    if selectors_config is None:
        try:
            from common.config.ozon_selectors_config import get_ozon_selectors_config
            selectors_config = get_ozon_selectors_config()
        except ImportError:
            # å¦‚æœé…ç½®ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºæœ¬çš„æ¸…ç†é€»è¾‘
            cleaned = re.sub(r'[^\d.,]', '', price_str)
            cleaned = cleaned.replace(',', '.')
            number_match = re.search(r'(\d+(?:\.\d+)?)', cleaned)
            if number_match:
                try:
                    return float(number_match.group(1))
                except (ValueError, TypeError):
                    return None
            return None

    # å¤„ç†ä»·æ ¼å‰ç¼€è¯ï¼Œç§»é™¤å‰ç¼€è¯
    prefix_pattern = '|'.join(re.escape(prefix) for prefix in selectors_config.price_prefix_words)
    if prefix_pattern:
        text = re.sub(f'^({prefix_pattern})\\s+', '', price_str, flags=re.IGNORECASE)
    else:
        text = price_str

    # ç§»é™¤è´§å¸ç¬¦å·å’Œç‰¹æ®Šç©ºæ ¼å­—ç¬¦
    # æ„å»ºè´§å¸ç¬¦å·æ¨¡å¼
    currency_pattern = '|'.join(re.escape(symbol) for symbol in selectors_config.currency_symbols)

    # æ„å»ºç‰¹æ®Šç©ºæ ¼å­—ç¬¦æ¨¡å¼
    space_chars = ''.join(selectors_config.special_space_chars)

    # ç§»é™¤è´§å¸ç¬¦å·ã€ç‰¹æ®Šç©ºæ ¼å­—ç¬¦å’Œæ™®é€šç©ºæ ¼
    if currency_pattern:
        cleaned = re.sub(f'[{re.escape(space_chars)}\\s]|({currency_pattern})', '', text, flags=re.IGNORECASE)
    else:
        cleaned = re.sub(f'[{re.escape(space_chars)}\\s]', '', text)

    # å¤„ç†åƒä½åˆ†éš”ç¬¦ï¼ˆä¿„è¯­ä¸­ä½¿ç”¨çª„ç©ºæ ¼ä½œä¸ºåƒä½åˆ†éš”ç¬¦ï¼‰
    cleaned = cleaned.replace(',', '.').replace(' ', '').replace(' ', '')

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ•°å­—
    # åŒ¹é…æ•°å­—æ¨¡å¼ï¼šå¯èƒ½åŒ…å«å°æ•°ç‚¹
    number_match = re.search(r'(\d+(?:[.,]\d+)?)', cleaned)
    if number_match:
        number_str = number_match.group(1).replace(',', '.')
        try:
            return float(number_str)
        except (ValueError, TypeError):
            return None

    return None