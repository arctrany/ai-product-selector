"""
æ¯›å­ERPæ’ä»¶æŠ“å–å™¨

è´Ÿè´£ä»æ¯›å­ERPæ’ä»¶æ¸²æŸ“åŒºåŸŸæŠ“å–å•†å“çš„ç»“æ„åŒ–æ•°æ®ã€‚
æ”¯æŒå…±äº«browser_serviceå®ä¾‹ï¼Œä¾¿äºç‹¬ç«‹æµ‹è¯•ã€‚
"""

import logging
import time
import re
from typing import Dict, Any, Optional, List, Callable

from bs4 import BeautifulSoup

from .base_scraper import BaseScraper
from .global_browser_singleton import get_global_browser_service
from common.models.scraping_result import ScrapingResult
from common.utils.wait_utils import WaitUtils, wait_for_content_smart
from common.utils.scraping_utils import ScrapingUtils
from common.config.erp_selectors_config import ERPSelectorsConfig, get_erp_selectors_config
from ..services.scraping_orchestrator import ScrapingMode


# å¼‚å¸¸ç±»å¯¼å…¥å·²ç§»é™¤ï¼Œä½¿ç”¨é€šç”¨å¼‚å¸¸å¤„ç†

class ErpPluginScraper(BaseScraper):
    """
    æ¯›å­ERPæ’ä»¶æŠ“å–å™¨ - ä½¿ç”¨å…¨å±€æµè§ˆå™¨å•ä¾‹

    å®ç°IERPScraperæ¥å£ï¼Œæä¾›æ ‡å‡†åŒ–çš„ERPæ•°æ®æŠ“å–åŠŸèƒ½
    """

    def __init__(self, selectors_config: Optional[ERPSelectorsConfig] = None, browser_service=None):
        """
        åˆå§‹åŒ–ERPæ’ä»¶æŠ“å–å™¨

        Args:
            selectors_config: ERPé€‰æ‹©å™¨é…ç½®å¯¹è±¡
            browser_service: å¯é€‰çš„å…±äº«æµè§ˆå™¨æœåŠ¡å®ä¾‹ï¼ˆå‘åå…¼å®¹ï¼Œæ¨èä½¿ç”¨å…¨å±€å•ä¾‹ï¼‰
        """
        super().__init__()
        self.selectors_config = selectors_config or get_erp_selectors_config()
        # ä¸ºäº†å…¼å®¹æµ‹è¯•ï¼Œæ·»åŠ configå±æ€§ï¼ˆæŒ‡å‘selectors_configï¼‰
        self.config = self.selectors_config
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")

        # ä½¿ç”¨å…¨å±€æµè§ˆå™¨å•ä¾‹
        if browser_service:
            self.browser_service = browser_service
            self._owns_browser_service = False  # ä¸æ‹¥æœ‰æµè§ˆå™¨æœåŠ¡ï¼Œä¸è´Ÿè´£å…³é—­
        else:
            self.browser_service = get_global_browser_service()
            self._owns_browser_service = False  # ä½¿ç”¨å…¨å±€å•ä¾‹ï¼Œä¸è´Ÿè´£å…³é—­

        # ğŸ”§ é‡æ„ï¼šåˆå§‹åŒ–ç»Ÿä¸€å·¥å…·ç±»
        self.wait_utils = WaitUtils(self.browser_service, self.logger)
        self.scraping_utils = ScrapingUtils(self.logger)

        # ERPåŒºåŸŸæ•°æ®å­—æ®µæ˜ å°„
        self.field_mappings = {
            'ç±»ç›®': 'category',
            'rFBSä½£é‡‘': 'rfbs_commission',
            'SKU': 'sku',
            'å“ç‰Œ': 'brand_name',
            'æœˆé”€é‡': 'monthly_sales_volume',
            'æœˆé”€å”®é¢': 'monthly_sales_amount',
            'æœˆå‘¨è½¬åŠ¨æ€': 'monthly_turnover_trend',
            'æ—¥é”€é‡': 'daily_sales_volume',
            'æ—¥é”€å”®é¢': 'daily_sales_amount',
            'å¹¿å‘Šè´¹å æ¯”': 'ad_cost_ratio',
            'å‚ä¸ä¿ƒé”€å¤©æ•°': 'promotion_days',
            'å‚ä¸ä¿ƒé”€çš„æŠ˜æ‰£': 'promotion_discount',
            'ä¿ƒé”€æ´»åŠ¨çš„è½¬åŒ–ç‡': 'promotion_conversion_rate',
            'ä»˜è´¹æ¨å¹¿å¤©æ•°': 'paid_promotion_days',
            'å•†å“å¡æµè§ˆé‡': 'product_card_views',
            'å•†å“å¡åŠ è´­ç‡': 'product_card_add_rate',
            'æœç´¢ç›®å½•æµè§ˆé‡': 'search_catalog_views',
            'æœç´¢ç›®å½•åŠ è´­ç‡': 'search_catalog_add_rate',
            'å±•ç¤ºè½¬åŒ–ç‡': 'display_conversion_rate',
            'å•†å“ç‚¹å‡»ç‡': 'product_click_rate',
            'å‘è´§æ¨¡å¼': 'shipping_mode',
            'é€€è´§å–æ¶ˆç‡': 'return_cancel_rate',
            'é•¿ å®½ é«˜': 'dimensions',
            'é‡ é‡': 'weight',
            'ä¸Šæ¶æ—¶é—´': 'listing_date',
            'è·Ÿå–åˆ—è¡¨': 'competitor_list',
            'è·Ÿå–æœ€ä½ä»·': 'competitor_min_price',
            'è·Ÿå–æœ€é«˜ä»·': 'competitor_max_price'
        }

    # æ ‡å‡†scrapeæ¥å£å®ç°
    def scrape(self,
               target: Optional[str] = None,
               mode: Optional[ScrapingMode] = None,
               context: Optional[Dict[str, Any]] = None,
               **kwargs) -> ScrapingResult:
        """
        ç»Ÿä¸€çš„æŠ“å–æ¥å£ï¼ˆæ ‡å‡†æ¥å£å®ç°ï¼‰

        Args:
            target: æŠ“å–ç›®æ ‡ï¼ˆå•†å“URLï¼‰
            mode: æŠ“å–æ¨¡å¼
            options: æŠ“å–é€‰é¡¹é…ç½®
            **kwargs: é¢å¤–å‚æ•°

        Returns:
            ScrapingResult: æ ‡å‡†åŒ–æŠ“å–ç»“æœ

        Raises:
            ScrapingException: æŠ“å–å¼‚å¸¸
            :param target:
            :param mode:
            :param context:
        """
        try:
            static_soup = kwargs.get('soup')

            # ä½¿ç”¨åŸºç±»çš„æ™ºèƒ½æ£€æŸ¥å¹¶å¯¼èˆªæ–¹æ³•
            if target:
                self.check_and_navi(target)

            return self._scrape(
                product_url=target,
                soup=static_soup,
                **kwargs
            )
        except Exception as e:
            self.logger.error(f"æŠ“å–å¤±è´¥: {str(e)}", exc_info=True)
            raise RuntimeError(f"æŠ“å–å¤±è´¥: {str(e)}") from e

    def _scrape(self,
                product_url: Optional[str] = None,
                soup: Optional[BeautifulSoup] = None,
                **kwargs) -> ScrapingResult:
        """
        ç»¼åˆERPæ•°æ®æŠ“å–ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰

        Args:
            product_url: å¯é€‰çš„å•†å“URLï¼Œå¦‚æœæä¾›åˆ™å¯¼èˆªåˆ°è¯¥é¡µé¢ï¼Œå¦åˆ™ä»å½“å‰é¡µé¢æŠ“å–
            include_attributes: æ˜¯å¦åŒ…å«å•†å“å±æ€§
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            ScrapingResult: æŠ“å–ç»“æœï¼ŒåŒ…å«ç»“æ„åŒ–çš„ERPæ•°æ®
        """
        start_time = time.time()
        try:
            # è·å–soupå¯¹è±¡ï¼šç›´æ¥ä½¿ç”¨æä¾›çš„æˆ–é€šè¿‡URLå¯¼èˆªè·å–
            # soup = self.scraping_utils.get_or_navigate_soup(soup, product_url, self.browser_service)

            # ç­‰å¾…ERPæ’ä»¶åŠ è½½å®Œæˆ
            self.logger.info(f"ğŸ” å°è¯•åŒ¹é…ERPå®¹å™¨é€‰æ‹©å™¨: {self.selectors_config.erp_container_selectors}")

            # ä½¿ç”¨ wait_for_content_smart è·å– ERP æ’ä»¶åŒºåŸŸçš„ soup å’Œ content
            # å¢åŠ ç­‰å¾…æ—¶é—´åˆ°30ç§’ï¼Œå¹¶æ·»åŠ å†…å®¹éªŒè¯å™¨ç¡®ä¿è·å–åˆ°æœ‰æ•ˆå†…å®¹
            def content_validator(elements):
                """éªŒè¯ERPå†…å®¹æ˜¯å¦æœ‰æ•ˆ"""
                if not elements:
                    return False

                # æ£€æŸ¥å…ƒç´ æ˜¯å¦åŒ…å«è¶³å¤Ÿçš„æ–‡æœ¬å†…å®¹
                for element in elements:
                    if hasattr(element, 'get_text'):
                        text = element.get_text(strip=True)
                        # å¦‚æœå…ƒç´ åŒ…å«è¶³å¤Ÿçš„æ–‡æœ¬å†…å®¹ï¼Œåˆ™è®¤ä¸ºæœ‰æ•ˆ
                        if len(text) > 50:  # è‡³å°‘50ä¸ªå­—ç¬¦
                            return True

                    # æ£€æŸ¥å…ƒç´ çš„å­å…ƒç´ 
                    if hasattr(element, 'find_all'):
                        children = element.find_all('span')
                        # å¦‚æœæœ‰å¤šä¸ªspanå­å…ƒç´ ï¼Œå¯èƒ½åŒ…å«ERPæ•°æ®
                        if len(children) > 3:
                            return True

                return False

            result = wait_for_content_smart(soup=soup,
                                            browser_service=self.browser_service,
                                            selectors=self.selectors_config.erp_container_selectors,
                                            max_wait_seconds=30,  # å¢åŠ ç­‰å¾…æ—¶é—´åˆ°30ç§’
                                            content_validator=content_validator)

            # æ£€æŸ¥ç»“æœå¹¶è·å– soup å’Œ content
            if result:
                # æˆåŠŸè·å–åˆ°å†…å®¹ï¼Œæå– soup å’Œ content
                soup = result['soup']
                erp_content = result['content']
                self.logger.info(f"âœ… ERPæ’ä»¶åŒºåŸŸå·²åŠ è½½å®Œæˆï¼Œæ‰¾åˆ° {len(erp_content)} ä¸ªåŒ¹é…å…ƒç´ ")

                # è®°å½•æ‰¾åˆ°çš„å…ƒç´ ä¿¡æ¯
                for i, element in enumerate(erp_content):
                    element_info = f"{element.name if hasattr(element, 'name') else 'text'}"
                    if hasattr(element, 'get') and element.get('class'):
                        element_info += f" - {element.get('class')}"
                    self.logger.debug(f"   å…ƒç´  {i + 1}: {element_info}")

                # ä½¿ç”¨æ›´æ–°åçš„ soup è¿›è¡Œæ•°æ®æå–
                erp_data = self._extract_erp_data_from_content(erp_content)
            else:
                # æœªèƒ½è·å–åˆ°å†…å®¹ï¼Œä½¿ç”¨åŸå§‹å†…å®¹ç»§ç»­å°è¯•æŠ“å–
                self.logger.warning("âš ï¸ ERPæ’ä»¶åŒºåŸŸç­‰å¾…è¶…æ—¶ï¼Œä½¿ç”¨åŸå§‹å†…å®¹ç»§ç»­å°è¯•æŠ“å–")
                self.logger.debug("ä½¿ç”¨çš„soupå†…å®¹é¢„è§ˆ: " + (str(soup)[:200] if soup else "soupä¸ºç©º"))

                # ç»§ç»­ä½¿ç”¨åŸå§‹soupå°è¯•æå–æ•°æ®
                if soup:
                    # å°è¯•ä»åŸå§‹soupä¸­æŸ¥æ‰¾ä»»ä½•å¯èƒ½çš„ERPå†…å®¹
                    fallback_content = []
                    for selector in self.selectors_config.erp_container_selectors:
                        try:
                            elements = soup.select(selector)
                            if elements:
                                fallback_content.extend(elements)
                                self.logger.debug(f"ä»åŸå§‹soupä¸­æ‰¾åˆ° {len(elements)} ä¸ª {selector} å…ƒç´ ")
                        except Exception as selector_e:
                            self.logger.debug(f"é€‰æ‹©å™¨ {selector} åŒ¹é…å¤±è´¥: {selector_e}")

                    if fallback_content:
                        self.logger.info(f"ğŸ’¡ ä»åŸå§‹å†…å®¹ä¸­æ‰¾åˆ° {len(fallback_content)} ä¸ªæ½œåœ¨ERPå…ƒç´ ")
                        erp_data = self._extract_erp_data_from_content(fallback_content)
                    else:
                        self.logger.warning("æœªæ‰¾åˆ°ERPæ’ä»¶åŒºåŸŸ")
                        erp_data = {}
                else:
                    self.logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„soupå†…å®¹è¿›è¡Œæ•°æ®æå–")
                    erp_data = {}

            return ScrapingResult(
                success=True,
                data=erp_data,
                execution_time=time.time() - start_time
            )

        except Exception as e:
            self.logger.error(f"æŠ“å–ERPä¿¡æ¯å¤±è´¥: {e}")
            return ScrapingResult(
                success=False,
                data={},
                error_message=str(e),
                execution_time=time.time() - start_time
            )

    def _extract_erp_data_from_content(self, content) -> Dict[str, Any]:
        """
        ä»é¡µé¢å†…å®¹ä¸­æå–ERPæ•°æ®
        
        Args:
            content: ERPæ’ä»¶å†…å®¹å…ƒç´ åˆ—è¡¨æˆ–å•ä¸ªå…ƒç´ 

        Returns:
            Dict[str, Any]: æå–çš„ERPæ•°æ®
        """
        try:
            erp_data = {}
            # æŸ¥æ‰¾ERPæ’ä»¶åŒºåŸŸ
            if not content:
                self.logger.warning("æœªæ‰¾åˆ°ERPæ’ä»¶åŒºåŸŸ")
                return {}

            # å¤„ç†contentå‚æ•° - å¦‚æœæ˜¯åˆ—è¡¨åˆ™å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œå¦‚æœæ˜¯å•ä¸ªå…ƒç´ åˆ™ç›´æ¥ä½¿ç”¨
            if isinstance(content, list):
                if len(content) == 0:
                    self.logger.warning("ERPå†…å®¹åˆ—è¡¨ä¸ºç©º")
                    return {}
                # å–ç¬¬ä¸€ä¸ªæœ‰æ•ˆå…ƒç´ 
                container = content[0]
                self.logger.debug(f"ä½¿ç”¨ERPå†…å®¹åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªå…ƒç´ : {getattr(container, 'name', 'unknown')}")
            else:
                # å•ä¸ªå…ƒç´ ç›´æ¥ä½¿ç”¨
                container = content
                self.logger.debug(f"ä½¿ç”¨å•ä¸ªERPå†…å®¹å…ƒç´ : {getattr(container, 'name', 'unknown')}")

            # æå–æ‰€æœ‰æ•°æ®å­—æ®µ
            for label_text, field_key in self.field_mappings.items():
                value = self._extract_field_value(container, label_text)
                if value is not None:
                    erp_data[field_key] = value

            # ç‰¹æ®Šå¤„ç†ï¼šè§£æå°ºå¯¸ä¿¡æ¯
            if 'dimensions' in erp_data:
                dimensions = self._parse_dimensions(erp_data['dimensions'])
                erp_data.update(dimensions)

            # ç‰¹æ®Šå¤„ç†ï¼šè§£æä¸Šæ¶æ—¶é—´
            if 'listing_date' in erp_data:
                parsed_date = self._parse_listing_date(erp_data['listing_date'])
                erp_data.update(parsed_date)

            # ç‰¹æ®Šå¤„ç†ï¼šè§£æé‡é‡
            if 'weight' in erp_data:
                weight_value = self._parse_weight(erp_data['weight'])
                if weight_value is not None:
                    erp_data['weight'] = weight_value

            # ç‰¹æ®Šå¤„ç†ï¼šè§£ærFBSä½£é‡‘
            if 'rfbs_commission' in erp_data:
                commission_rates = self._parse_rfbs_commission(erp_data['rfbs_commission'])
                erp_data['rfbs_commission_rates'] = commission_rates

            return erp_data

        except Exception as e:
            self.logger.error(f"è§£æERPæ•°æ®å¤±è´¥: {e}")
            return {}

    def _extract_field_value(self, container: Any, label_text: str) -> Optional[str]:
        """
        ä»ERPæ’ä»¶å®¹å™¨ä¸­æå–æŒ‡å®šæ ‡ç­¾çš„å€¼

        åŸºäºçœŸå®DOMç»“æ„ä¼˜åŒ–ï¼š
        <div><span><span>æ ‡ç­¾ï¼š </span><span>å€¼</span></span></div>

        Args:
            container: BeautifulSoupå®¹å™¨å¯¹è±¡
            label_text: æ ‡ç­¾æ–‡æœ¬ï¼ˆå¦‚"ç±»ç›®"ï¼‰

        Returns:
            Optional[str]: æå–çš„å€¼ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›None
        """
        try:
            # å¯¼å…¥æ‰€éœ€æ¨¡å—
            import re

            # æ ‡å‡†åŒ–æ ‡ç­¾æ–‡æœ¬ - ç¡®ä¿åŒ…å«å†’å·
            search_label = label_text if label_text.endswith('ï¼š') else f"{label_text}ï¼š"

            # æ–¹æ³•1ï¼šåŸºäºçœŸå®DOMç»“æ„ - æŸ¥æ‰¾åŒ…å«æ ‡ç­¾çš„spanï¼Œç„¶åæ‰¾åŒçº§çš„å€¼span
            # çœŸå®ç»“æ„ï¼š<div><span><span>æ ‡ç­¾ï¼š </span><span>å€¼</span></span></div>
            label_spans = container.find_all('span', string=lambda text: text and search_label.strip() in text.strip())

            for label_span in label_spans:
                # æŸ¥æ‰¾åŒçº§çš„ä¸‹ä¸€ä¸ªspanï¼ˆå€¼spanï¼‰
                value_span = label_span.find_next_sibling('span')
                if value_span:
                    value_text = value_span.get_text(strip=True)
                    if self._is_valid_value(value_text):
                        self.logger.debug(f"âœ… æ–¹æ³•1æˆåŠŸ: æ ‡ç­¾'{label_text}' -> å€¼'{value_text}'")
                        return value_text

            # æ–¹æ³•2ï¼šæŸ¥æ‰¾åŒ…å«å®Œæ•´æ ‡ç­¾æ–‡æœ¬çš„spanï¼Œå¤„ç†åµŒå¥—ç»“æ„
            for element in container.find_all('span'):
                element_text = element.get_text(strip=True) if element else ""
                if search_label in element_text:
                    # æ‰¾åˆ°æ ‡ç­¾spanï¼ŒæŸ¥æ‰¾åŒçº§çš„å€¼span
                    next_span = element.find_next_sibling('span')
                    if next_span:
                        value_text = next_span.get_text(strip=True)
                        if self._is_valid_value(value_text):
                            self.logger.debug(f"âœ… æ–¹æ³•2æˆåŠŸ: æ ‡ç­¾'{label_text}' -> å€¼'{value_text}'")
                            return value_text

            # æ–¹æ³•3ï¼šåœ¨çˆ¶çº§spanä¸­æŸ¥æ‰¾ï¼Œå¤„ç†åµŒå¥—ç»“æ„
            # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«æ ‡ç­¾æ–‡æœ¬çš„å…ƒç´ 
            for element in container.find_all(string=lambda text: text and search_label in text):
                parent_span = element.parent
                if parent_span and parent_span.name == 'span':
                    # æŸ¥æ‰¾çˆ¶çº§spançš„ä¸‹ä¸€ä¸ªå…„å¼Ÿspan
                    next_span = parent_span.find_next_sibling('span')
                    if next_span:
                        value_text = next_span.get_text(strip=True)
                        if self._is_valid_value(value_text):
                            self.logger.debug(f"âœ… æ–¹æ³•3æˆåŠŸ: æ ‡ç­¾'{label_text}' -> å€¼'{value_text}'")
                            return value_text

            # æ–¹æ³•4ï¼šåœ¨divçº§åˆ«æŸ¥æ‰¾
            for div in container.find_all('div'):
                div_text = div.get_text()
                if search_label in div_text:
                    # åœ¨è¿™ä¸ªdivä¸­æŸ¥æ‰¾æ‰€æœ‰span
                    spans = div.find_all('span')
                    for i, span in enumerate(spans):
                        span_text = span.get_text(strip=True)
                        if search_label in span_text and i + 1 < len(spans):
                            # æ‰¾åˆ°æ ‡ç­¾spanï¼Œè·å–ä¸‹ä¸€ä¸ªspançš„å€¼
                            next_span = spans[i + 1]
                            value_text = next_span.get_text(strip=True)
                            if self._is_valid_value(value_text):
                                self.logger.debug(f"âœ… æ–¹æ³•4æˆåŠŸ: æ ‡ç­¾'{label_text}' -> å€¼'{value_text}'")
                                return value_text

            # æ–¹æ³•5ï¼šç‰¹æ®Šå¤„ç†å¤æ‚å€¼ï¼ˆå¦‚rFBSä½£é‡‘çš„å¤šä¸ªæ ‡ç­¾ï¼‰
            if 'rFBSä½£é‡‘' in label_text or 'rfbs' in label_text.lower():
                commission_values = []
                # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«ç™¾åˆ†å·çš„spanæ ‡ç­¾
                for span in container.find_all('span', class_=lambda x: x and 'ant-tag' in ' '.join(x)):
                    span_text = span.get_text(strip=True)
                    if '%' in span_text and span_text.replace('%', '').replace('.', '').isdigit():
                        commission_values.append(span_text)

                if commission_values:
                    result = ', '.join(commission_values)
                    self.logger.debug(f"âœ… æ–¹æ³•5æˆåŠŸ: æ ‡ç­¾'{label_text}' -> å€¼'{result}'")
                    return result

            # æ–¹æ³•6ï¼šå¢å¼ºçš„æ­£åˆ™è¡¨è¾¾å¼å…¨æ–‡æœç´¢ - æ”¹è¿›ç‰ˆ
            all_text = container.get_text()
            if search_label in all_text:
                # ä½¿ç”¨æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼æå–æ ‡ç­¾åçš„å€¼
                # åŒ¹é…æ ‡ç­¾åçš„éç©ºç™½å­—ç¬¦ï¼Œç›´åˆ°é‡åˆ°ä¸‹ä¸€ä¸ªæ ‡ç­¾æˆ–æ–‡æœ¬æœ«å°¾
                pattern = rf'{re.escape(search_label)}\s*([^\n\r\t]+?)(?=\s*(?:[a-zA-Z\u4e00-\u9fa5]+[ï¼š:]|$))'
                matches = re.findall(pattern, all_text)
                if matches:
                    # å–ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹å¹¶æ¸…ç†
                    value = matches[0].strip()
                    # è¿›ä¸€æ­¥æ¸…ç†å¯èƒ½çš„å¤šä½™å­—ç¬¦
                    value = re.sub(r'[\s\u00a0]+', ' ', value)  # æ›¿æ¢ä¸é—´æ–­ç©ºæ ¼å’Œå…¶ä»–ç©ºç™½å­—ç¬¦
                    value = value.strip('ï¼š:')  # ç§»é™¤å¯èƒ½çš„å†’å·
                    if self._is_valid_value(value):
                        self.logger.debug(f"âœ… æ–¹æ³•6æˆåŠŸ: æ ‡ç­¾'{label_text}' -> å€¼'{value}'")
                        return value

            # æ–¹æ³•7ï¼šé’ˆå¯¹å•†å“2369901364çš„ç‰¹æ®Šå¤„ç† - æ›´å®½æ¾çš„åŒ¹é…
            # å°è¯•åœ¨æ‰€æœ‰æ–‡æœ¬èŠ‚ç‚¹ä¸­æŸ¥æ‰¾æ ‡ç­¾å’Œå€¼çš„ç»„åˆ
            text_nodes = container.find_all(string=True)
            for i, text_node in enumerate(text_nodes):
                if search_label in str(text_node).strip():
                    # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªæ–‡æœ¬èŠ‚ç‚¹ä½œä¸ºå¯èƒ½çš„å€¼
                    if i + 1 < len(text_nodes):
                        next_text = str(text_nodes[i + 1]).strip()
                        if next_text and self._is_valid_value(next_text):
                            self.logger.debug(f"âœ… æ–¹æ³•7æˆåŠŸ: æ ‡ç­¾'{label_text}' -> å€¼'{next_text}'")
                            return next_text

            self.logger.debug(f"âŒ æœªæ‰¾åˆ°æ ‡ç­¾'{label_text}'çš„å€¼")
            return None

        except Exception as e:
            self.logger.error(f"æå–å­—æ®µ'{label_text}'å¤±è´¥: {e}")
            return None

    def _is_valid_value(self, value: str) -> bool:
        """
        æ£€æŸ¥å€¼æ˜¯å¦æœ‰æ•ˆ

        Args:
            value: è¦æ£€æŸ¥çš„å€¼

        Returns:
            bool: å€¼æ˜¯å¦æœ‰æ•ˆ
        """
        if not value:
            return False

        # è¿‡æ»¤æ— æ•ˆå€¼
        invalid_values = ['-', '--', 'æ— æ•°æ®', 'N/A', '', 'æ— ', 'æš‚æ— ', 'null', 'undefined']
        return value.strip() not in invalid_values

    def _parse_dimensions(self, dimensions_str: str) -> Dict[str, Optional[float]]:
        """
        è§£æå°ºå¯¸å­—ç¬¦ä¸²ï¼Œé’ˆå¯¹çœŸå®DOMç»“æ„ä¼˜åŒ–

        Args:
            dimensions_str: å°ºå¯¸å­—ç¬¦ä¸²ï¼Œå¦‚ "550 x 500 x 100mm"

        Returns:
            Dict[str, Optional[float]]: åŒ…å«length, width, heightçš„å­—å…¸
        """
        result: Dict[str, Optional[float]] = {'length': None, 'width': None, 'height': None}

        try:
            # æ£€æŸ¥è¾“å…¥å‚æ•°
            if not dimensions_str or dimensions_str is None:
                return result

            # ç§»é™¤å•ä½å¹¶æ¸…ç†ç©ºç™½å­—ç¬¦
            clean_str = dimensions_str.lower().replace('mm', '').replace('cm', '').strip()

            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ•°å­—
            import re
            numbers = re.findall(r'\d+(?:\.\d+)?', clean_str)

            if len(numbers) >= 3:
                result['length'] = float(numbers[0])
                result['width'] = float(numbers[1])
                result['height'] = float(numbers[2])
            elif len(numbers) == 2:
                result['length'] = float(numbers[0])
                result['width'] = float(numbers[1])
            elif len(numbers) == 1:
                result['length'] = float(numbers[0])

        except (ValueError, IndexError) as e:
            self.logger.warning(f"è§£æå°ºå¯¸å¤±è´¥: {dimensions_str}, é”™è¯¯: {e}")

        return result

    def _parse_listing_date(self, date_str: str) -> Dict[str, Optional[Any]]:
        """
        è§£æä¸Šæ¶æ—¶é—´
        
        Args:
            date_str: æ—¶é—´å­—ç¬¦ä¸²ï¼Œå¦‚ "2024-09-23(415å¤©)"
            
        Returns:
            Dict[str, Optional[Any]]: åŒ…å«listing_date_parsedå’Œshelf_daysçš„å­—å…¸
        """
        result = {'listing_date_parsed': None, 'shelf_days': None}

        try:
            if not date_str:
                return result

            # æå–æ—¥æœŸéƒ¨åˆ†
            date_match = re.search(r'(\d{4}-\d{2}-\d{2})', date_str)
            if date_match:
                date_part = date_match.group(1)
                result['listing_date_parsed'] = date_part  # ç›´æ¥è¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯dateå¯¹è±¡

            # æå–å¤©æ•°éƒ¨åˆ†
            days_match = re.search(r'\((\d+)å¤©\)', date_str)
            if days_match:
                result['shelf_days'] = int(days_match.group(1))

        except (ValueError, AttributeError) as e:
            self.logger.warning(f"è§£æä¸Šæ¶æ—¶é—´å¤±è´¥: {date_str}, é”™è¯¯: {e}")

        return result

    def _parse_weight(self, weight_str: str) -> Optional[float]:
        """
        è§£æé‡é‡å­—ç¬¦ä¸²
        
        Args:
            weight_str: é‡é‡å­—ç¬¦ä¸²ï¼Œå¦‚ "40g"
            
        Returns:
            Optional[float]: é‡é‡å€¼ï¼ˆå…‹ï¼‰ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            if not weight_str:
                return None

            # æå–æ•°å­—éƒ¨åˆ†
            weight_match = re.search(r'(\d+(?:\.\d+)?)', weight_str)
            if weight_match:
                return float(weight_match.group(1))

        except (ValueError, AttributeError) as e:
            self.logger.warning(f"è§£æé‡é‡å¤±è´¥: {weight_str}, é”™è¯¯: {e}")

        return None

    def _parse_rfbs_commission(self, commission_str: str) -> Optional[List[float]]:
        """
        è§£ærFBSä½£é‡‘å­—ç¬¦ä¸²

        Args:
            commission_str: ä½£é‡‘å­—ç¬¦ä¸²

        Returns:
            Optional[List[float]]: ä½£é‡‘ç‡åˆ—è¡¨ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
        """
        try:
            if not commission_str:
                return None

            # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
            rates = re.findall(r'(\d+(?:\.\d+)?)%?', commission_str)
            if rates:
                return [float(rate) for rate in rates]

            # å¦‚æœæ— æ³•æå–åˆ°æ•°å­—ï¼Œè¿”å›Noneè€Œä¸æ˜¯é»˜è®¤å€¼
            return None

        except Exception as e:
            self.logger.warning(f"è§£æä½£é‡‘ç‡å¤±è´¥: {commission_str}, é”™è¯¯: {e}")
            return None

    def _calculate_commission_rate_by_price(self, price: float) -> float:
        """
        æ ¹æ®ä»·æ ¼è®¡ç®—ä½£é‡‘ç‡

        Args:
            price: å•†å“ä»·æ ¼ï¼ˆå¢å¸ƒï¼‰

        Returns:
            float: ä½£é‡‘ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
        """
        try:
            # ğŸ”§ é‡æ„ï¼šä½¿ç”¨ç¡¬ç¼–ç é˜ˆå€¼ï¼Œç¬¦åˆæ¶æ„åˆ†ç¦»åŸåˆ™
            if price <= 500:  # ä½ä»·å•†å“é˜ˆå€¼500å¢å¸ƒ
                return 15.0  # ä½ä»·å•†å“ä½£é‡‘ç‡15%
            elif price >= 2000:  # é«˜ä»·å•†å“é˜ˆå€¼2000å¢å¸ƒ
                return 8.0  # é«˜ä»·å•†å“ä½£é‡‘ç‡8%
            else:
                return 12.0  # ä¸­ç­‰ä»·æ ¼å•†å“ä½£é‡‘ç‡12%
        except Exception as e:
            self.logger.warning(f"è®¡ç®—ä½£é‡‘ç‡å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
            return 12.0

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()

    # ========== æŠ½è±¡æ–¹æ³•å®ç° ==========
    def validate_data(self, data: Dict[str, Any],
                      filters: Optional[List[Callable]] = None) -> bool:
        """
        éªŒè¯æå–çš„æ•°æ®ï¼ˆæŠ½è±¡æ–¹æ³•å®ç°ï¼‰

        Args:
            data: å¾…éªŒè¯çš„æ•°æ®
            filters: éªŒè¯è¿‡æ»¤å™¨åˆ—è¡¨

        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # åŸºæœ¬éªŒè¯ï¼šæ•°æ®ä¸ä¸ºç©º
            if not data:
                return False

            # éªŒè¯ERPæ•°æ®çš„å…³é”®å­—æ®µ
            erp_fields = ['category', 'sku', 'brand_name', 'monthly_sales_volume', 'monthly_sales_amount']
            has_valid_field = False

            for field in erp_fields:
                if field in data and data[field] is not None:
                    has_valid_field = True
                    break

            if not has_valid_field:
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ERPæ•°æ®å­—æ®µ")
                return False

            # éªŒè¯æ•°å€¼å­—æ®µçš„åˆç†æ€§
            numeric_fields = ['monthly_sales_volume', 'monthly_sales_amount', 'daily_sales_volume',
                              'daily_sales_amount']
            for field in numeric_fields:
                if field in data:
                    try:
                        value = float(data[field]) if data[field] is not None else 0
                        if value < 0:
                            self.logger.warning(f"å­—æ®µ {field} å€¼ä¸ºè´Ÿæ•°: {value}")
                            return False
                    except (ValueError, TypeError):
                        self.logger.warning(f"å­—æ®µ {field} å€¼æ— æ³•è½¬æ¢ä¸ºæ•°å­—: {data[field]}")

            # åº”ç”¨è‡ªå®šä¹‰è¿‡æ»¤å™¨
            if filters:
                for filter_func in filters:
                    if not filter_func(data):
                        return False

            return True

        except Exception as e:
            self.logger.error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
            return False
